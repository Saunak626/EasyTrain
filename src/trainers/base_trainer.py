"""
åŸºç¡€è®­ç»ƒå™¨æ¨¡å—

æä¾›ç»Ÿä¸€çš„è®­ç»ƒæ¥å£ï¼Œæ”¯æŒå›¾åƒå’Œè§†é¢‘åˆ†ç±»ä»»åŠ¡ã€‚
é›†æˆAccelerateåº“å®ç°å¤šGPUè®­ç»ƒå’ŒSwanLabå®éªŒè¿½è¸ªã€‚
"""

import os
import sys
import json
import torch
import torch.nn as nn

from tqdm import tqdm
from accelerate import Accelerator

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

# å¯¼å…¥é¡¹ç›®å†…éƒ¨æ¨¡å—
from src.models.image_net import get_model                     # å›¾åƒæ¨¡å‹å·¥å‚å‡½æ•°
from src.models.video_net import get_video_model               # è§†é¢‘æ¨¡å‹å·¥å‚å‡½æ•°
from src.losses.loss_factory import get_loss_function         # æŸå¤±å‡½æ•°å·¥å‚å‡½æ•°
from src.optimizers.optimizer_factory import get_optimizer    # ä¼˜åŒ–å™¨å·¥å‚å‡½æ•°
from src.schedules.scheduler_factory import get_scheduler     # å­¦ä¹ ç‡è°ƒåº¦å™¨å·¥å‚å‡½æ•°
from src.datasets import create_dataloaders, get_dataset_info  # ç»Ÿä¸€æ•°æ®åŠ è½½å™¨å·¥å‚
from src.utils.data_utils import set_seed
# GPUç›‘æ§åŠŸèƒ½å·²ç§»é™¤
# å·¥å‚å‡½æ•°å†…éƒ¨å¤„ç†é…ç½®è§£æ


def is_main_process():
    """æ£€æŸ¥æ˜¯å¦ä¸ºä¸»è¿›ç¨‹ï¼ˆç”¨äºé¿å…é‡å¤è¾“å‡ºï¼‰"""
    return int(os.environ.get("LOCAL_RANK", 0)) == 0


# æ”¯æŒçš„ä»»åŠ¡ç±»å‹é…ç½®
SUPPORTED_TASKS = {
    'image_classification': {
        'description': 'å›¾åƒåˆ†ç±»ä»»åŠ¡',
        'supported_datasets': ['cifar10', 'custom'],
        'model_factory': 'get_model',
        'default_model': 'resnet18'
    },
    'video_classification': {
        'description': 'è§†é¢‘åˆ†ç±»ä»»åŠ¡',
        'supported_datasets': ['ucf101', 'ucf101_video'],
        'model_factory': 'get_video_model',
        'default_model': 'r3d_18'
    }
}


def get_learning_rate_info(optimizer, lr_scheduler, scheduler_config, initial_lr):
    """è·å–å­¦ä¹ ç‡ç›‘æ§ä¿¡æ¯

    Args:
        optimizer: ä¼˜åŒ–å™¨
        lr_scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler_config: è°ƒåº¦å™¨é…ç½®
        initial_lr: åˆå§‹å­¦ä¹ ç‡

    Returns:
        dict: åŒ…å«å­¦ä¹ ç‡ä¿¡æ¯çš„å­—å…¸
    """
    current_lr = optimizer.param_groups[0]['lr']
    scheduler_name = scheduler_config.get('name', 'default')

    return {
        'initial_lr': initial_lr,
        'current_lr': current_lr,
        'scheduler_name': scheduler_name
    }


def print_learning_rate_info(lr_info, epoch, total_epochs, phase="å¼€å§‹"):
    """æ‰“å°å­¦ä¹ ç‡ä¿¡æ¯

    Args:
        lr_info: å­¦ä¹ ç‡ä¿¡æ¯å­—å…¸
        epoch: å½“å‰epoch
        total_epochs: æ€»epochæ•°
        phase: é˜¶æ®µæè¿°ï¼ˆ"å¼€å§‹" æˆ– "ç»“æŸ"ï¼‰
    """
    print(f"ğŸ“Š Epoch {epoch}/{total_epochs} {phase} | "
          f"è°ƒåº¦ç­–ç•¥: {lr_info['scheduler_name']} | "
          f"åˆå§‹LR: {lr_info['initial_lr']:.6f} | "
          f"å½“å‰LR: {lr_info['current_lr']:.6f}")


def train_epoch(dataloader, model, loss_fn, optimizer, lr_scheduler, accelerator, epoch):
    """æ‰§è¡Œå•ä¸ªè®­ç»ƒè½®æ¬¡

    Args:
        dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        model: ç¥ç»ç½‘ç»œæ¨¡å‹
        loss_fn: æŸå¤±å‡½æ•°
        optimizer: ä¼˜åŒ–å™¨
        lr_scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        accelerator: Acceleratorå®ä¾‹
        epoch: å½“å‰è½®æ¬¡ç¼–å·

    Returns:
        float: å¹³å‡è®­ç»ƒæŸå¤±
    """
    model.train()
    total_loss = 0.0
    num_batches = 0

    if accelerator.is_main_process:
        progress_bar = tqdm(
            total=len(dataloader),
            desc=f"Epoch {epoch} Training",
            unit="batch",
            dynamic_ncols=True,
            leave=False,
        )

    for batch_idx, (inputs, targets) in enumerate(dataloader):
        outputs = model(inputs)
        loss = loss_fn(outputs, targets)

        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()
        lr_scheduler.step()

        total_loss += loss.item()
        num_batches += 1

        accelerator.log({"train/loss": loss.item(), "epoch_num": epoch})

        # GPUç›‘æ§åŠŸèƒ½å·²ç§»é™¤

        # æ›´æ–°è¿›åº¦æ¡
        if accelerator.is_main_process and batch_idx % 10 == 0:
            current_lr = optimizer.param_groups[0]['lr']
            avg_loss = total_loss / num_batches
            progress_bar.set_postfix(
                loss=f"{avg_loss:.4f}",
                lr=f"{current_lr:.2e}"
            )

        if accelerator.is_main_process:
            progress_bar.update(1)

    # å…³é—­è¿›åº¦æ¡
    if accelerator.is_main_process:
        progress_bar.close()

    # GPUç›‘æ§åŠŸèƒ½å·²ç§»é™¤

    # è¿”å›å¹³å‡è®­ç»ƒæŸå¤±
    avg_train_loss = total_loss / num_batches if num_batches > 0 else 0.0
    return avg_train_loss


def test_epoch(dataloader, model, loss_fn, accelerator, epoch, train_batches=None):
    """
    æ‰§è¡Œå•ä¸ªæµ‹è¯•è½®æ¬¡
    
    è¯¥å‡½æ•°åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œè®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡ã€‚
    æ”¯æŒå¤šGPUç¯å¢ƒä¸‹çš„æŒ‡æ ‡èšåˆï¼Œç¡®ä¿ç»“æœçš„å‡†ç¡®æ€§ã€‚

    Args:
        dataloader (torch.utils.data.DataLoader): æµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼Œæä¾›æµ‹è¯•æ‰¹æ¬¡æ•°æ®
        model (torch.nn.Module): ç¥ç»ç½‘ç»œæ¨¡å‹
        loss_fn (torch.nn.Module): æŸå¤±å‡½æ•°ï¼Œç”¨äºè®¡ç®—æµ‹è¯•æŸå¤±
        accelerator (accelerate.Accelerator): Acceleratorå®ä¾‹ï¼Œå¤„ç†å¤šGPUæŒ‡æ ‡èšåˆ
        epoch (int): å½“å‰æµ‹è¯•è½®æ¬¡ç¼–å·

    Returns:
        tuple: (å¹³å‡æŸå¤±, å‡†ç¡®ç‡ç™¾åˆ†æ¯”) æˆ– (None, None) å¦‚æœä¸æ˜¯ä¸»è¿›ç¨‹
    """
    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œç¦ç”¨dropoutå’Œbatch normalizationçš„è®­ç»ƒè¡Œä¸º
    model.eval()
    device = accelerator.device

    # åˆå§‹åŒ–ç´¯è®¡æŒ‡æ ‡å¼ é‡ï¼Œç”¨äºè·¨GPUèšåˆ
    local_loss_sum = torch.tensor(0.0, device=device)  # å½“å‰GPUçš„æ€»æŸå¤±
    local_correct = torch.tensor(0, device=device)     # å½“å‰GPUçš„æ­£ç¡®é¢„æµ‹æ•°
    local_samples = torch.tensor(0, device=device)     # å½“å‰GPUçš„æ ·æœ¬æ€»æ•°

    # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
    if accelerator.is_main_process:
        progress_bar = tqdm(
            total=len(dataloader),
            desc=f"Epoch {epoch} Testing",
            unit="batch",
            dynamic_ncols=True,
            leave=False,
        )

    # ç¦ç”¨æ¢¯åº¦è®¡ç®—ä»¥èŠ‚çœå†…å­˜å’ŒåŠ é€Ÿæ¨ç†
    with torch.no_grad():
        for inputs, targets in dataloader:
            # å‰å‘ä¼ æ’­è·å–é¢„æµ‹ç»“æœ
            outputs = model(inputs)
            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„æŸå¤±
            loss = loss_fn(outputs, targets)

            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„ç»Ÿè®¡ä¿¡æ¯
            batch_size = targets.size(0)
            # è·å–é¢„æµ‹ç±»åˆ«å¹¶è®¡ç®—æ­£ç¡®é¢„æµ‹æ•°é‡
            correct = outputs.argmax(dim=1).eq(targets).sum()

            # ç´¯åŠ åˆ°æœ¬åœ°ç»Ÿè®¡é‡ï¼ˆè€ƒè™‘æ‰¹æ¬¡å¤§å°æƒé‡ï¼‰
            local_loss_sum += loss * batch_size
            local_correct += correct
            local_samples += batch_size

            # æ›´æ–°è¿›åº¦æ¡
            if accelerator.is_main_process:
                progress_bar.update(1)

    # å…³é—­è¿›åº¦æ¡
    if accelerator.is_main_process:
        progress_bar.close()

    # è·¨æ‰€æœ‰GPUè¿›ç¨‹èšåˆç»Ÿè®¡æŒ‡æ ‡
    total_loss = accelerator.reduce(local_loss_sum, reduction="sum")
    total_correct = accelerator.reduce(local_correct, reduction="sum")
    total_samples = accelerator.reduce(local_samples, reduction="sum")

    # åªåœ¨ä¸»è¿›ç¨‹è®¡ç®—æœ€ç»ˆæŒ‡æ ‡å¹¶è®°å½•
    if accelerator.is_main_process:
        # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
        avg_loss = (total_loss / total_samples).item()
        accuracy = 100. * total_correct.item() / total_samples.item()

        # ä½¿ç”¨tqdm.write()è¾“å‡ºæ‘˜è¦ï¼Œä¸ç ´åè¿›åº¦æ¡æ˜¾ç¤º
        log_msg = f'Epoch {epoch:03d} | val_loss={avg_loss:.4f} | val_acc={accuracy:.2f}%'
        if train_batches is not None:
            log_msg += f' | train_batches={train_batches}'
        tqdm.write(log_msg)

        # è®°å½•æµ‹è¯•æŒ‡æ ‡åˆ°å®éªŒè¿½è¸ªç³»ç»Ÿ
        accelerator.log({"test/loss": avg_loss, "test/accuracy": accuracy}, step=epoch)

        # GPUç›‘æ§åŠŸèƒ½å·²ç§»é™¤

        return avg_loss, accuracy

    # éä¸»è¿›ç¨‹è¿”å›None
    return None, None


def run_training(config, exp_name=None):
    """
    è®­ç»ƒçš„ä¸»å…¥å£å‡½æ•°ï¼Œè´Ÿè´£æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„åè°ƒï¼ŒåŒ…æ‹¬ï¼š
    - ç¯å¢ƒåˆå§‹åŒ–ï¼ˆéšæœºç§å­ã€å®éªŒè¿½è¸ªï¼‰
    - æ•°æ®åŠ è½½å™¨åˆ›å»º
    - æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨åˆå§‹åŒ–
    - å¤šGPUç¯å¢ƒé…ç½®
    - è®­ç»ƒå¾ªç¯æ‰§è¡Œ
    - ç»“æœè®°å½•å’Œè¿”å›

    Args:
        config (dict): åŒ…å«æ‰€æœ‰è®­ç»ƒé…ç½®çš„å­—å…¸ï¼ŒåŒ…æ‹¬æ¨¡å‹ã€æ•°æ®ã€è¶…å‚æ•°ç­‰è®¾ç½®
        exp_name (str, optional): å®éªŒåç§°ï¼Œç”¨äºè¿½è¸ªå’Œæ—¥å¿—è®°å½•

    Returns:
        dict: è®­ç»ƒç»“æœå­—å…¸ï¼ŒåŒ…å«å®éªŒåç§°ã€æœ€ä½³å‡†ç¡®ç‡å’Œé…ç½®ä¿¡æ¯
    """
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å®éªŒå¯é‡ç°æ€§
    set_seed(42)

    # å®éªŒåç§°ï¼Œä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‡½æ•°çš„å‚æ•°
    if exp_name is None:
        exp_name = config['training']['exp_name']

    # === ç¬¬1æ­¥ï¼šè§£æä»»åŠ¡é…ç½® ===
    task_config = config.get('task', {})
    task_tag = task_config.get('tag')

    # éªŒè¯ä»»åŠ¡ç±»å‹å¿…é¡»æ˜ç¡®æŒ‡å®š
    if not task_tag:
        raise ValueError(f"å¿…é¡»åœ¨é…ç½®æ–‡ä»¶ä¸­æ˜ç¡®æŒ‡å®štask.tagã€‚æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {list(SUPPORTED_TASKS.keys())}")

    if task_tag not in SUPPORTED_TASKS:
        raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_tag}ã€‚æ”¯æŒçš„ä»»åŠ¡: {list(SUPPORTED_TASKS.keys())}")

    task_info = SUPPORTED_TASKS[task_tag]

    # === ç¬¬2æ­¥ï¼šè§£æå’ŒéªŒè¯æ•°æ®é…ç½® ===
    data_config = config.get('data', {})
    dataset_type = data_config.get('type', 'cifar10')

    # éªŒè¯æ•°æ®é›†ä¸ä»»åŠ¡çš„å…¼å®¹æ€§
    if dataset_type not in task_info['supported_datasets']:
        raise ValueError(f"ä»»åŠ¡ '{task_tag}' ä¸æ”¯æŒæ•°æ®é›† '{dataset_type}'ã€‚"
                        f"æ”¯æŒçš„æ•°æ®é›†: {task_info['supported_datasets']}")

    # åˆå§‹åŒ–Acceleratorï¼ŒæŒ‡å®šswanlabä¸ºæ—¥å¿—è®°å½•å·¥å…·
    accelerator = Accelerator(log_with="swanlab")

    # GPUç›‘æ§åŠŸèƒ½å·²ç§»é™¤

    # è®°å½•åˆ°SwanLabçš„è¶…å‚æ•°
    hyperparams = config['hp']
    tracker_config = {**hyperparams, "exp_name": exp_name, "task_tag": task_tag}

    # åˆå§‹åŒ–SwanLabå®éªŒè¿½è¸ªå™¨
    accelerator.init_trackers(
        project_name=config['swanlab']['project_name'], # SwanLab UIä¸­é¡¹ç›®åç§°
        config=tracker_config,    # è¦è®°å½•çš„è¶…å‚æ•°
        init_kwargs={             # é¢å¤–åˆå§‹åŒ–å‚æ•°
            "swanlab": {
                "exp_name": exp_name,
                "description": config['swanlab']['description']
            }
        }
    )

    # === ç¬¬3æ­¥ï¼šè·å–æ¨¡å‹é…ç½®ï¼ˆç”¨äºæ•°æ®é¢„å¤„ç†ï¼‰ ===
    model_config = config.get('model', {})
    model_name = model_config.get('type',
                                 model_config.get('name', task_info['default_model']))

    # ä½¿ç”¨ç®€åŒ–çš„æ•°æ®åŠ è½½å™¨åˆ›å»ºå‡½æ•°
    train_dataloader, test_dataloader, num_classes = create_dataloaders(
        dataset_name=dataset_type,
        data_dir=data_config.get('root', './data'),
        batch_size=hyperparams['batch_size'],
        num_workers=data_config.get('num_workers', 8),
        model_type=model_name,  # ä¼ é€’æ¨¡å‹ç±»å‹ç”¨äºåŠ¨æ€transforms
        data_percentage=hyperparams.get('data_percentage', 1.0),
        **data_config.get('params', {})
    )

    # === ç¬¬4æ­¥ï¼šè·å–æ•°æ®é›†ä¿¡æ¯ ===
    dataset_info = get_dataset_info(dataset_type)
    dataset_info['num_classes'] = num_classes or dataset_info['num_classes']

    # === ç¬¬5æ­¥ï¼šåŸºäºä»»åŠ¡ç±»å‹åˆ›å»ºæ¨¡å‹ ===

    # ä½¿ç”¨ä»»åŠ¡é©±åŠ¨çš„æ¨¡å‹å·¥å‚é€‰æ‹©
    model_factory_name = task_info['model_factory']
    model_factory = globals()[model_factory_name]

    # ç»Ÿä¸€çš„æ¨¡å‹åˆ›å»ºé€»è¾‘
    model_params = model_config.get('params', {}).copy()
    model_params['num_classes'] = dataset_info['num_classes']

    model = model_factory(
        model_type=model_name,
        **model_params
    )

    # åˆ›å»ºæŸå¤±å‡½æ•° - ä½¿ç”¨å·¥å‚å‡½æ•°
    loss_fn = get_loss_function(config.get('loss', {}))

    # åˆ›å»ºä¼˜åŒ–å™¨ - ä½¿ç”¨å·¥å‚å‡½æ•°
    optimizer = get_optimizer(model, config.get('optimizer', {}), hyperparams['learning_rate'])

    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½¿ç”¨å·¥å‚å‡½æ•°
    # éœ€è¦ä¼ é€’steps_per_epochç»™è°ƒåº¦å™¨
    scheduler_config = config.get('scheduler', {}).copy()
    if 'steps_per_epoch' not in scheduler_config:
        scheduler_config['steps_per_epoch'] = len(train_dataloader)

    lr_scheduler = get_scheduler(optimizer, scheduler_config, hyperparams)

    # ä½¿ç”¨AcceleratoråŒ…è£…æ‰€æœ‰è®­ç»ƒç»„ä»¶ï¼Œè‡ªåŠ¨å¤„ç†å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ
    
    # # æ¸…ç†GPUç¼“å­˜ï¼Œé‡Šæ”¾æœªä½¿ç”¨çš„å†…å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # ä½¿ç”¨AcceleratoråŒ…è£…è®­ç»ƒç»„ä»¶ï¼Œè‡ªåŠ¨å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒ
    model, optimizer, lr_scheduler, train_dataloader, test_dataloader = accelerator.prepare(
        model, optimizer, lr_scheduler, train_dataloader, test_dataloader
    )

    # æ‰“å°è®­ç»ƒé…ç½®ä¿¡æ¯ï¼ˆä»…åœ¨ä¸»è¿›ç¨‹ï¼‰
    if accelerator.is_main_process:
        # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°è®­ç»ƒä¿¡æ¯ï¼Œé¿å…é‡å¤è¾“å‡º
        if is_main_process():
            print(f"========== è®­ç»ƒå®éªŒ: {exp_name} ==========")
            print(f"  ä»»åŠ¡ç±»å‹: {task_tag} ({task_info['description']})")
            print(f"  æ•°æ®é›†: {dataset_type}")
            print(f"  æ¨¡å‹: {model_name}")
            print(f"  è¶…å‚æ•°: {hyperparams}")
            
            # æ˜¾ç¤ºå…³é”®å‚æ•°çš„æ¥æºå’Œå€¼
            data_pct = hyperparams.get('data_percentage', 1.0)
            if data_pct < 1.0:
                print(f"  ğŸ¯ æ•°æ®é‡‡æ ·æ¯”ä¾‹: {data_pct:.1%} (æ¥è‡ªå‘½ä»¤è¡Œè¦†ç›–)")
            else:
                print(f"  ğŸ“Š ä½¿ç”¨å®Œæ•´æ•°æ®é›† (data_percentage: {data_pct})")
            
            print("=" * 80)

    # è®¾ç½®ç»“æœç›®å½•
    result_dir = os.path.join("runs", exp_name) if exp_name else None

    # åˆå§‹åŒ–æœ€ä½³å‡†ç¡®ç‡è¿½è¸ª
    best_accuracy = 0.0

    # è·å–åˆå§‹å­¦ä¹ ç‡ç”¨äºç›‘æ§
    initial_lr = hyperparams['learning_rate']

    # ä¸»è®­ç»ƒå¾ªç¯ï¼šæ‰§è¡ŒæŒ‡å®šè½®æ•°çš„è®­ç»ƒ
    for epoch in range(1, hyperparams['epochs'] + 1):
        if accelerator.is_main_process:
            # tqdm.write(f"Epoch {epoch}/{hyperparams['epochs']}")

            # æ‰“å°epochå¼€å§‹æ—¶çš„å­¦ä¹ ç‡ä¿¡æ¯
            lr_info = get_learning_rate_info(optimizer, lr_scheduler, scheduler_config, initial_lr)
            print_learning_rate_info(lr_info, epoch, hyperparams['epochs'], "å¼€å§‹")

        # è®­ç»ƒepoch
        train_loss = train_epoch(train_dataloader, model, loss_fn, optimizer, lr_scheduler, accelerator, epoch)
        # æµ‹è¯•epoch
        val_loss, val_accuracy = test_epoch(test_dataloader, model, loss_fn, accelerator, epoch, train_batches=len(train_dataloader))

        # æ‰“å°epochç»“æŸæ—¶çš„å­¦ä¹ ç‡ä¿¡æ¯
        if accelerator.is_main_process:
            lr_info = get_learning_rate_info(optimizer, lr_scheduler, scheduler_config, initial_lr)
            print_learning_rate_info(lr_info, epoch, hyperparams['epochs'], "ç»“æŸ")

        # æ›´æ–°å¹¶è®°å½•æœ€ä½³å‡†ç¡®ç‡
        if accelerator.is_main_process and val_accuracy > best_accuracy:
            best_accuracy = val_accuracy
            tqdm.write(f"æ–°æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")

    # ç»“æŸå®éªŒè¿½è¸ªï¼Œä¿å­˜æ—¥å¿—å’Œç»“æœ
    accelerator.end_training()

    # è¾“å‡ºè®­ç»ƒå®Œæˆä¿¡æ¯
    if accelerator.is_main_process:
        tqdm.write(f"è®­ç»ƒå®Œæˆ! æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")

    # æ¸…ç†GPUç¼“å­˜ï¼Œä¸ºä¸‹ä¸€ä¸ªå®éªŒé‡Šæ”¾èµ„æº
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # è¿”å›è®­ç»ƒç»“æœæ‘˜è¦ï¼ˆç›´æ¥è¿”å›ï¼Œä¸å†™å…¥æ–‡ä»¶ï¼‰
    return {
        "success": True,                       # è®­ç»ƒæˆåŠŸæ ‡å¿—
        "exp_name": exp_name,                  # å®éªŒåç§°
        "best_accuracy": best_accuracy,        # æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡
        "final_accuracy": val_accuracy,        # æœ€ç»ˆå‡†ç¡®ç‡
        "config": tracker_config               # å®Œæ•´çš„è®­ç»ƒé…ç½®
    }