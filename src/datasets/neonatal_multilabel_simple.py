"""æ–°ç”Ÿå„¿å¤šæ ‡ç­¾æ•°æ®é›†

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä»å¸§å›¾åƒç›®å½•åŠ è½½è§†é¢‘æ•°æ®
2. ä»Excelæ–‡ä»¶åŠ è½½å¤šæ ‡ç­¾æ ‡æ³¨
3. ç®€å•çš„train/teståˆ’åˆ†
4. åŸºç¡€çš„è§†é¢‘é¢„å¤„ç†ï¼ˆresizeã€normalizeã€to_tensorï¼‰

ç§»é™¤çš„é«˜çº§åŠŸèƒ½ï¼š
- åŠ æƒé‡‡æ ·ã€åˆ†å±‚é‡‡æ ·
- FPSé‡‡æ ·ã€æ ·æœ¬æƒé‡è®¡ç®—
- pos_weightè®¡ç®—
- æ¨¡å‹ç‰¹å®šçš„transforms
- è¯¦ç»†çš„éªŒè¯ç»Ÿè®¡
- ç±»åˆ«ç­›é€‰ï¼ˆtop_n_classesï¼‰
- æ ‡ç­¾ç¼“å­˜ä¼˜åŒ–

"""

import os
import cv2
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from torch.utils.data import DataLoader

from PIL import Image  # ğŸ”§ æ–°å¢ï¼šä½¿ç”¨PILæ›¿ä»£cv2ï¼Œæå‡I/Oæ€§èƒ½


class NeonatalMultilabelSimple(Dataset):
    """æ–°ç”Ÿå„¿å¤šæ ‡ç­¾æ•°æ®é›† - ç®€åŒ–ç‰ˆ
    
    æœ€å°åŒ–å®ç°ï¼Œå±•ç¤ºå¤šæ ‡ç­¾è§†é¢‘æ•°æ®é›†çš„æ ¸å¿ƒæ„é€ æ–¹å¼ã€‚
    
    æ•°æ®ç»“æ„:
        frames_dir/
            session_001/
                clip_001/
                    00000.jpg
                    00001.jpg
                    ...
            session_002/
                ...
        
        labels.xlsx:
            æ–‡ä»¶å | æ–‡ä»¶å†…åŠ¨ä½œåºå· | æ ‡ç­¾1 | æ ‡ç­¾2 | ...
    
    Args:
        frames_dir (str): å¸§å›¾åƒæ ¹ç›®å½•
        labels_file (str): Excelæ ‡ç­¾æ–‡ä»¶è·¯å¾„
        split (str): 'train' æˆ– 'test'
        clip_len (int): æ¯ä¸ªè§†é¢‘ç‰‡æ®µçš„å¸§æ•°ï¼Œé»˜è®¤16
        train_ratio (float): è®­ç»ƒé›†æ¯”ä¾‹ï¼Œé»˜è®¤0.8
    """
    
    def __init__(self, frames_dir, labels_file, split='train', clip_len=16,
                 train_ratio=0.8, target_size=(224, 224)):
        self.frames_dir = frames_dir
        self.labels_file = labels_file
        self.split = split
        self.clip_len = clip_len
        self.train_ratio = train_ratio
        self.target_size = target_size  # å¸§resizeå°ºå¯¸ï¼Œä¿æŒå¯é…ç½®
        
        # å®šä¹‰è¡Œä¸ºæ ‡ç­¾ï¼ˆ24ä¸ªåŸå§‹æ ‡ç­¾ï¼‰
        self.behavior_labels = [
            'å–‚å…»å¼€å§‹', 'å–‚å…»ç»“æŸ', 'æ˜“å“­é—¹', 'å¼ å˜´é—­å˜´', 'å¸å®è¡Œä¸º', 'åƒæ‰‹æŒ‡',
            'åƒè„šæŒ‡', 'çš±çœ‰', 'å“­æ³£', 'å‘è„¾æ°”', 'æ¥å›æ‘‡å¤´', 'æ‰‹è„šæ´»åŠ¨åŠ å¿«',
            'å¯»æ‰¾å¥¶ç“¶', 'æ³¨è§†å¥¶ç“¶', 'å£°è°ƒå˜é«˜', 'æ‰“å“ˆæ¬ ', 'ç¡ç€äº†', 'é—´æ­‡å–å¥¶',
            'å”‡éƒ¨è§¦é£Ÿååº”', 'å–‚å…»æœŸé¬¼è„¸', 'å£è…”å™¨å…·å’¬åˆ', 'å¤´é¢ˆä¾§å‘å›é¿',
            'è‚¢ä½“å¼ åŠ›å‡é€€', 'è¿œç¦»å¥¶ç“¶'
        ]
        self.num_classes = len(self.behavior_labels)
        
        # åŠ è½½æ•°æ®
        self.samples = self._load_data()
        
        print(f"åŠ è½½ {split} æ•°æ®é›†: {len(self.samples)} ä¸ªæ ·æœ¬ï¼Œ{self.num_classes} ä¸ªç±»åˆ«")
    
    def _load_data(self):
        """åŠ è½½æ•°æ®å¹¶åˆ’åˆ†train/test"""
        # 1. è¯»å–Excelæ ‡ç­¾æ–‡ä»¶
        df = pd.read_excel(self.labels_file)
        
        # 2. æ¸…ç†æ–‡ä»¶åï¼Œæ„å»ºæ ·æœ¬åˆ—è¡¨
        samples = []
        for _, row in df.iterrows():
            # æå–session_nameå’Œclip_id
            session_name = row['æ–‡ä»¶å'].replace('.mov', '').replace('.mp4', '').strip()
            clip_id = str(row['æ–‡ä»¶å†…åŠ¨ä½œåºå·'])
            
            # æ£€æŸ¥å¸§ç›®å½•æ˜¯å¦å­˜åœ¨
            clip_dir = os.path.join(self.frames_dir, session_name, clip_id)
            if not os.path.exists(clip_dir):
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¸§å›¾åƒ
            frame_files = [f for f in os.listdir(clip_dir) if f.endswith('.jpg')]
            if len(frame_files) == 0:
                continue
            
            # æå–å¤šæ ‡ç­¾å‘é‡
            label_vector = []
            for label_name in self.behavior_labels:
                if label_name in row:
                    label_vector.append(float(row[label_name]))
                else:
                    label_vector.append(0.0)
            
            # è·³è¿‡å…¨é›¶æ ‡ç­¾
            if sum(label_vector) == 0:
                continue
            
            # ğŸ”§ ä¼˜åŒ–ï¼šé¢„å…ˆè½¬æ¢ä¸ºtensorï¼Œé¿å…æ¯æ¬¡__getitem__æ—¶é‡å¤è½¬æ¢
            samples.append({
                'session_name': session_name,
                'clip_id': clip_id,
                'frames_dir': clip_dir,
                'labels': torch.tensor(label_vector, dtype=torch.float32)
            })
        
        # 3. ç®€å•çš„train/teståˆ’åˆ†ï¼ˆæŒ‰8:2æ¯”ä¾‹ï¼‰
        split_idx = int(len(samples) * self.train_ratio)
        if self.split == 'train':
            return samples[:split_idx]
        else:
            return samples[split_idx:]
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, index):
        """è·å–å•ä¸ªæ ·æœ¬"""
        sample = self.samples[index]

        # 1. è·å–å¸§è·¯å¾„å¹¶é‡‡æ ·ç´¢å¼•
        frame_paths = self._get_frame_paths(sample['frames_dir'])
        indices = self._sample_indices(len(frame_paths), self.clip_len)

        # 2. æŒ‰ç´¢å¼•è¯»å–æ‰€éœ€å¸§å¹¶é‡‡æ ·åˆ°å›ºå®šå¸§æ•°
        frames = self._load_selected_frames(frame_paths, indices)

        # 3. é¢„å¤„ç†ï¼šnormalize + to_tensor
        frames = self._preprocess(frames) # TODO: æ›´æ¢å®˜æ–¹çš„æ¥å£

        # 4. è·å–æ ‡ç­¾ï¼ˆå·²åœ¨åˆå§‹åŒ–æ—¶è½¬æ¢ä¸ºtensorï¼‰
        labels = sample['labels']

        return frames, labels

    def _get_frame_paths(self, frames_dir):
        """è·å–ç›®å½•ä¸‹æ‰€æœ‰å¸§è·¯å¾„"""
        frame_paths = sorted([
            os.path.join(frames_dir, f)
            for f in os.listdir(frames_dir)
            if f.endswith('.jpg')
        ])

        if len(frame_paths) == 0:
            raise ValueError(f"æ²¡æœ‰æ‰¾åˆ°å¸§å›¾åƒ: {frames_dir}")

        return frame_paths

    def _sample_indices(self, total_frames, clip_len):
        """åœ¨ä¸è¯»å–å›¾åƒçš„æƒ…å†µä¸‹ç”Ÿæˆé‡‡æ ·ç´¢å¼•"""
        if total_frames >= clip_len:
            start_idx = np.random.randint(0, total_frames - clip_len + 1)
            return list(range(start_idx, start_idx + clip_len))

        # å¸§æ•°ä¸è¶³æ—¶ï¼Œè¡¥é½æœ€åä¸€å¸§
        return list(range(total_frames)) + [total_frames - 1] * (clip_len - total_frames)

    def _read_frame(self, frame_path):
        """è¯»å–å•å¸§å¹¶resizeï¼ˆOpenCVå®ç°ï¼‰"""
        img = cv2.imread(frame_path, cv2.IMREAD_COLOR)
        if img is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ {frame_path}")

        # BGR -> RGB
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        if self.target_size:
            target_w, target_h = self.target_size
            img = cv2.resize(img, (target_w, target_h), interpolation=cv2.INTER_LINEAR)

        return img.astype(np.float32)

    def _load_selected_frames(self, frame_paths, indices):
        """ä»…æŒ‰é‡‡æ ·ç´¢å¼•åŠ è½½æ‰€éœ€å¸§ï¼Œé¿å…è¯»å–æ•´æ®µè§†é¢‘"""
        # å…ˆè¯»å–ä¸€å¸§ä»¥ç¡®å®šshapeå¹¶å®Œæˆé¢„åˆ†é…
        first_frame = self._read_frame(frame_paths[indices[0]])
        h, w, c = first_frame.shape
        buffer = np.empty((len(indices), h, w, c), dtype=np.float32)
        buffer[0] = first_frame

        for i, idx in enumerate(indices[1:], start=1):
            buffer[i] = self._read_frame(frame_paths[idx])

        return buffer

    def _preprocess(self, frames):
        """é¢„å¤„ç†ï¼šå½’ä¸€åŒ– + è½¬æ¢ä¸ºtensor

        Args:
            frames (np.ndarray): è¾“å…¥å¸§ï¼Œå½¢çŠ¶ (T, H, W, C)

        Returns:
            torch.Tensor: å½¢çŠ¶ (C, T, H, W)
        """
        # å½’ä¸€åŒ–ï¼ˆå‡å»å‡å€¼ï¼‰ï¼Œä¿æŒ float32ï¼Œé¿å…å˜æˆ float64
        mean = np.array([[[90.0, 98.0, 102.0]]], dtype=np.float32)
        frames = frames - mean

        # è½¬æ¢ç»´åº¦ï¼š(T, H, W, C) -> (C, T, H, W)
        frames = frames.transpose(3, 0, 1, 2)

        # è½¬æ¢ä¸º float32 tensorï¼ˆä¸æ¨¡å‹æƒé‡ dtype ä¸€è‡´ï¼‰
        return torch.from_numpy(frames).float()

    def get_num_classes(self):
        """è·å–ç±»åˆ«æ•°"""
        return self.num_classes

    def get_class_names(self):
        """è·å–ç±»åˆ«åç§°åˆ—è¡¨"""
        return self.behavior_labels


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""

    # 1. åˆ›å»ºæ•°æ®é›†
    train_dataset = NeonatalMultilabelSimple(
        frames_dir='../Neonate-Feeding-Assessment/data/cpu_processed_627/frames_segments',
        labels_file='../Neonate-Feeding-Assessment/result_xlsx/shanghai/multi_hot_labels.xlsx',
        split='train',
        clip_len=16
    )

    test_dataset = NeonatalMultilabelSimple(
        frames_dir='../Neonate-Feeding-Assessment/data/cpu_processed_627/frames_segments',
        labels_file='../Neonate-Feeding-Assessment/result_xlsx/shanghai/multi_hot_labels.xlsx',
        split='test',
        clip_len=16
    )

    # 2. åˆ›å»ºDataLoader

    train_loader = DataLoader(
        train_dataset,
        batch_size=8,
        shuffle=True,
        num_workers=4
    )

    # 3. è¿­ä»£æ•°æ®
    for frames, labels in train_loader:
        print(f"Frames shape: {frames.shape}")  # (B, C, T, H, W)
        print(f"Labels shape: {labels.shape}")  # (B, num_classes)
        break

    print(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
    print(f"ç±»åˆ«æ•°: {train_dataset.get_num_classes()}")

    frames, labels = train_dataset[0]
    print(f"æµ‹è¯•æ ·æœ¬: {labels} æ ·æœ¬")
    print(f"æµ‹è¯•æ ·æœ¬å°ºå¯¸: {frames.shape[0]} æ ·æœ¬")

if __name__ == '__main__':
    example_usage()
