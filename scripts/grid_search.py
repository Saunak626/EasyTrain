"""ç½‘æ ¼æœç´¢å¯åŠ¨è„šæœ¬

å®ç°è¶…å‚æ•°ç½‘æ ¼æœç´¢ï¼Œæ”¯æŒè¿›ç¨‹å†…è°ƒç”¨å’Œå¤šç§å‚æ•°ç»„åˆç­–ç•¥ã€‚
ä¸»è¦åŠŸèƒ½ï¼šå‚æ•°ç»„åˆç”Ÿæˆã€å®éªŒæ‰§è¡Œã€ç»“æœæ”¶é›†å’ŒCSVæŠ¥å‘Šç”Ÿæˆã€‚
"""
import itertools
import subprocess
import yaml
import os
import sys
import csv
import json
import random
import fcntl
import hashlib
from typing import Dict, List, Any, Optional, Tuple

from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.utils.config_parser import parse_arguments

# ============================================================================
# æ¨¡å—çº§å¸¸é‡é…ç½®
# ============================================================================

# ç½‘æ ¼æœç´¢ç›¸å…³å¸¸é‡
GRID_SEARCH_CONSTANTS = {
    'model_type_key': 'model.type',
    'batch_size_key': 'hp.batch_size',
    'group_key': 'group',
    'excluded_params': ['model.type', 'hp.batch_size'],
    'csv_base_columns': [
        'exp_name', 'model.type', 'group', 'success', 'trained_epochs',
        # ğŸ¯ å¤šæ ‡ç­¾åˆ†ç±»å…³é”®æŒ‡æ ‡ï¼ˆä¼˜å…ˆæ˜¾ç¤ºï¼‰
        'best_weighted_f1', 'best_weighted_accuracy', 'best_macro_accuracy', 'best_micro_accuracy',
        'best_macro_f1', 'best_micro_f1', 'best_macro_precision', 'best_macro_recall',
        'final_weighted_f1', 'final_weighted_accuracy', 'final_macro_accuracy', 'final_micro_accuracy',
        'final_macro_f1', 'final_micro_f1',
        # ä¼ ç»Ÿå­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
        'best_accuracy', 'final_accuracy'
    ],
    'common_runtime_params': [
        'data_percentage',
        'optimizer.name', 'scheduler.name', 'loss.name'
    ],
    'excluded_csv_params': ['epochs', 'batch_size', 'learning_rate']
}

# ============================================================================
# å‚æ•°ç»„åˆç”Ÿæˆå™¨ç±»
# ============================================================================

class ParameterCombinationGenerator:
    """å‚æ•°ç»„åˆç”Ÿæˆå™¨

    è´Ÿè´£å¤„ç†ç½‘æ ¼æœç´¢çš„å‚æ•°ç»„åˆç”Ÿæˆé€»è¾‘ï¼Œæ”¯æŒåˆ†ç»„å¼é…ç½®å’Œæ¨¡å‹-batch_sizeæ™ºèƒ½é…å¯¹ã€‚
    """

    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–å‚æ•°ç»„åˆç”Ÿæˆå™¨

        Args:
            config: ç½‘æ ¼æœç´¢é…ç½®å­—å…¸
        """
        self.config = config
        self.constants = GRID_SEARCH_CONSTANTS

    def generate_combinations(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå‚æ•°ç»„åˆçš„ä¸»å…¥å£å‡½æ•°

        Returns:
            å‚æ•°ç»„åˆåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€ç»„å®éªŒå‚æ•°
        """
        gs = (self.config or {}).get("grid_search", {}) or {}
        fixed = gs.get("fixed", {}) or {}
        models_to_train = self.config.get("models_to_train", [])

        # åˆ†ç»„å¼é…ç½®å¤„ç†
        if "groups" in gs and gs["groups"]:
            print(f"ğŸ“‹ ä½¿ç”¨åˆ†ç»„å¼ç½‘æ ¼æœç´¢é…ç½®")
            return self._generate_combinations_by_groups(gs["groups"], fixed, models_to_train)

        # è¾¹ç•Œæƒ…å†µï¼šæ— æœç´¢å‚æ•°ï¼Œä»åŸºç¡€é…ç½®ä¸­æå–ä¿¡æ¯
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°groupsé…ç½®ï¼Œä»åŸºç¡€é…ç½®ä¸­æå–å‚æ•°")
            base_params = {}

            # ä»åŸºç¡€é…ç½®ä¸­æå–æ¨¡å‹ç±»å‹
            if 'model' in self.config and 'type' in self.config['model']:
                base_params[self.constants['model_type_key']] = self.config['model']['type']

            # ä»åŸºç¡€é…ç½®ä¸­æå–å…¶ä»–å‚æ•°
            if 'optimizer' in self.config and 'name' in self.config['optimizer']:
                base_params['optimizer.name'] = self.config['optimizer']['name']

            if 'scheduler' in self.config and 'name' in self.config['scheduler']:
                base_params['scheduler.name'] = self.config['scheduler']['name']

            if 'loss' in self.config and 'name' in self.config['loss']:
                base_params['loss.name'] = self.config['loss']['name']

            # è®¾ç½®é»˜è®¤ç»„å
            base_params[self.constants['group_key']] = 'default'

            # åˆå¹¶å›ºå®šå‚æ•°
            result_params = {**fixed, **base_params}
            return [result_params] if result_params else [{}]

    def _generate_combinations_by_groups(self, groups_config: Dict[str, Any],
                                       fixed: Dict[str, Any],
                                       models_to_train: List[str]) -> List[Dict[str, Any]]:
        """åˆ†ç»„å¼å‚æ•°ç»„åˆç”Ÿæˆå™¨ - æ”¯æŒç»„å†…æ¨¡å‹-batch_sizeæ™ºèƒ½é…å¯¹

        Args:
            groups_config: åˆ†ç»„é…ç½®å­—å…¸
            fixed: å›ºå®šå‚æ•°å­—å…¸
            models_to_train: è¦è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨

        Returns:
            æ‰€æœ‰ç»„åˆçš„å‚æ•°åˆ—è¡¨
        """
        all_combinations = []
        total_groups = len(groups_config)

        print(f"ğŸ¯ å‘ç° {total_groups} ä¸ªæ¨¡å‹ç»„:")
        for group_name in groups_config.keys():
            group_models = _as_list(groups_config[group_name].get(self.constants['model_type_key'], []))
            print(f"   - {group_name}: {group_models}")

        for group_name, group_params in groups_config.items():
            print(f"\nğŸ”§ å¤„ç†æ¨¡å‹ç»„: {group_name}")

            # ç¬¬1æ­¥ï¼šè§£æç»„é…ç½®
            group_models, group_batch_sizes = self._parse_group_config(group_params)

            # ç¬¬2æ­¥ï¼šå¤„ç†æ¨¡å‹-batch_sizeé…å¯¹é€»è¾‘
            model_batch_dict = self._handle_model_batch_pairing(group_models, group_batch_sizes, group_name)

            # ç¬¬3æ­¥ï¼šè¿‡æ»¤å¯ç”¨çš„æ¨¡å‹
            enabled_models = self._filter_enabled_models(group_models, models_to_train, group_name)
            if not enabled_models:
                continue

            # ç¬¬4æ­¥ï¼šç”Ÿæˆå‚æ•°ç»„åˆ
            group_combinations = self._generate_parameter_combinations(
                enabled_models, group_params, fixed, group_name, model_batch_dict
            )
            all_combinations.extend(group_combinations)

            # ç¬¬5æ­¥ï¼šæ‰“å°ç»„åˆç»Ÿè®¡ä¿¡æ¯
            self._print_group_statistics(group_name, group_combinations, group_params,
                                       enabled_models, model_batch_dict)

        print(f"\nğŸ‰ åˆ†ç»„å¼æœç´¢æ€»è®¡ç”Ÿæˆ {len(all_combinations)} ä¸ªç»„åˆ")
        return all_combinations

    def _parse_group_config(self, group_params: Dict[str, Any]) -> Tuple[List[str], List[Any]]:
        """è§£æç»„é…ç½®

        ä»ç»„å‚æ•°ä¸­æå–æ¨¡å‹åˆ—è¡¨å’Œbatch_sizeåˆ—è¡¨ã€‚

        Args:
            group_params: ç»„å‚æ•°å­—å…¸

        Returns:
            Tuple[æ¨¡å‹åˆ—è¡¨, batch_sizeåˆ—è¡¨]
        """
        group_models = _as_list(group_params.get(self.constants['model_type_key'], []))
        group_batch_sizes = _as_list(group_params.get(self.constants['batch_size_key'], []))

        print(f"   ğŸ“‹ ç»„å†…é…ç½®:")
        print(f"      {self.constants['model_type_key']}: {group_models} (é•¿åº¦: {len(group_models)})")
        print(f"      {self.constants['batch_size_key']}: {group_batch_sizes} (é•¿åº¦: {len(group_batch_sizes)})")

        return group_models, group_batch_sizes

    def _handle_model_batch_pairing(self, group_models: List[str], group_batch_sizes: List[Any],
                                   group_name: str) -> Optional[Dict[str, Any]]:
        """å¤„ç†æ¨¡å‹-batch_sizeé…å¯¹é€»è¾‘

        æ ¹æ®æ¨¡å‹å’Œbatch_sizeçš„æ•°é‡å…³ç³»ï¼Œå†³å®šé…å¯¹ç­–ç•¥ã€‚

        Args:
            group_models: æ¨¡å‹åˆ—è¡¨
            group_batch_sizes: batch_sizeåˆ—è¡¨
            group_name: ç»„åç§°

        Returns:
            æ¨¡å‹-batch_sizeé…å¯¹å­—å…¸ï¼Œå¦‚æœéœ€è¦ç‹¬ç«‹å¤„ç†åˆ™è¿”å›None
        """
        if group_batch_sizes:
            if len(group_batch_sizes) == 1:
                # æƒ…å†µ1ï¼šbatch_sizeé•¿åº¦=1ï¼Œæ‰©å……åˆ°ä¸model.typeä¸€è‡´
                group_batch_sizes = group_batch_sizes * len(group_models)
                print(f"   ğŸ”„ æ‰©å……batch_size: {group_batch_sizes} (æ‰©å……åˆ°ä¸model.typeé•¿åº¦ä¸€è‡´)")
                # åˆ›å»ºä¸€å¯¹ä¸€é…å¯¹å­—å…¸
                model_batch_dict = dict(zip(group_models, group_batch_sizes))
            elif len(group_batch_sizes) == len(group_models):
                # æƒ…å†µ2ï¼šbatch_sizeé•¿åº¦=model.typeé•¿åº¦ï¼ŒæŒ‰é¡ºåºé…å¯¹
                print(f"   âœ… é•¿åº¦åŒ¹é…ï¼Œå°†æŒ‰é¡ºåºé…å¯¹")
                model_batch_dict = dict(zip(group_models, group_batch_sizes))
            else:
                # æƒ…å†µ3ï¼šbatch_sizeé•¿åº¦â‰ 1ä¸”â‰ model.typeé•¿åº¦ï¼Œä½œä¸ºç‹¬ç«‹å‚æ•°å¤„ç†
                print(f"   ğŸ”„ batch_sizeä½œä¸ºç‹¬ç«‹å‚æ•°å¤„ç†ï¼Œå°†ä¸æ¨¡å‹è¿›è¡Œç¬›å¡å°”ç§¯ç»„åˆ")
                model_batch_dict = None  # æ ‡è®°ä¸ºç‹¬ç«‹å‚æ•°å¤„ç†
        else:
            # æ²¡æœ‰batch_sizeé…ç½®ï¼Œæ‰€æœ‰æ¨¡å‹ä½¿ç”¨é»˜è®¤å€¼
            model_batch_dict = {model: None for model in group_models}
            print(f"   ğŸ“Š æ— batch_sizeé…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼")

        return model_batch_dict

    def _filter_enabled_models(self, group_models: List[str], models_to_train: List[str],
                              group_name: str) -> List[str]:
        """è¿‡æ»¤å¯ç”¨çš„æ¨¡å‹

        æ ¹æ®models_to_trainé…ç½®è¿‡æ»¤å‡ºéœ€è¦è®­ç»ƒçš„æ¨¡å‹ã€‚

        Args:
            group_models: ç»„å†…æ‰€æœ‰æ¨¡å‹
            models_to_train: è¦è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨
            group_name: ç»„åç§°

        Returns:
            å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
        """
        if models_to_train:
            enabled_models = [model for model in group_models if model in models_to_train]
            if not enabled_models:
                print(f"   â­ï¸  è·³è¿‡ç»„ {group_name}ï¼šæ— å¯ç”¨çš„æ¨¡å‹")
                return []
        else:
            enabled_models = group_models

        return enabled_models

    def _generate_parameter_combinations(self, enabled_models: List[str], group_params: Dict[str, Any],
                                       fixed: Dict[str, Any], group_name: str,
                                       model_batch_dict: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå‚æ•°ç»„åˆ

        æ ¹æ®æ¨¡å‹-batch_sizeé…å¯¹ç­–ç•¥ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆã€‚

        Args:
            enabled_models: å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
            group_params: ç»„å‚æ•°å­—å…¸
            fixed: å›ºå®šå‚æ•°å­—å…¸
            group_name: ç»„åç§°
            model_batch_dict: æ¨¡å‹-batch_sizeé…å¯¹å­—å…¸ï¼ŒNoneè¡¨ç¤ºç‹¬ç«‹å¤„ç†

        Returns:
            å‚æ•°ç»„åˆåˆ—è¡¨
        """
        combinations = []

        if model_batch_dict is not None:
            # æœ‰æ¨¡å‹-batch_sizeé…å¯¹çš„æƒ…å†µ
            enabled_pairs = {model: batch_size for model, batch_size in model_batch_dict.items()
                            if model in enabled_models}
            print(f"   ğŸ¯ å¯ç”¨çš„æ¨¡å‹é…å¯¹: {enabled_pairs}")

            # è·å–å…¶ä»–å‚æ•°ï¼ˆæ’é™¤model.typeå’Œhp.batch_sizeï¼‰
            other_params = {k: v for k, v in group_params.items()
                           if k not in self.constants['excluded_params']}

            # ç”Ÿæˆç»„åˆ
            if not other_params:
                # åªæœ‰æ¨¡å‹-batch_sizeé…å¯¹ï¼Œæ— å…¶ä»–å‚æ•°
                for model, batch_size in enabled_pairs.items():
                    combo = {**fixed, self.constants['model_type_key']: model, self.constants['group_key']: group_name}
                    if batch_size is not None:
                        combo[self.constants['batch_size_key']] = batch_size
                    combinations.append(combo)
            else:
                # æœ‰å…¶ä»–å‚æ•°ï¼Œè¿›è¡Œç¬›å¡å°”ç§¯ç»„åˆ
                param_items = [(k, _as_list(v)) for k, v in other_params.items() if _as_list(v)]
                if param_items:
                    param_keys, param_values_lists = zip(*param_items)
                    for model, batch_size in enabled_pairs.items():
                        for param_combo in itertools.product(*param_values_lists):
                            combo = {
                                **fixed,
                                self.constants['model_type_key']: model,
                                self.constants['group_key']: group_name
                            }
                            if batch_size is not None:
                                combo[self.constants['batch_size_key']] = batch_size
                            combo.update(dict(zip(param_keys, param_combo)))
                            combinations.append(combo)
                else:
                    # å…¶ä»–å‚æ•°éƒ½ä¸ºç©º
                    for model, batch_size in enabled_pairs.items():
                        combo = {**fixed, self.constants['model_type_key']: model, self.constants['group_key']: group_name}
                        if batch_size is not None:
                            combo[self.constants['batch_size_key']] = batch_size
                        combinations.append(combo)
        else:
            # batch_sizeä½œä¸ºç‹¬ç«‹å‚æ•°ï¼Œä¸æ¨¡å‹è¿›è¡Œç¬›å¡å°”ç§¯ç»„åˆ
            all_params = {k: v for k, v in group_params.items() if k != self.constants['model_type_key']}
            param_items = [(k, _as_list(v)) for k, v in all_params.items() if _as_list(v)]

            if param_items:
                param_keys, param_values_lists = zip(*param_items)
                for model in enabled_models:
                    for param_combo in itertools.product(*param_values_lists):
                        combo = {
                            **fixed,
                            self.constants['model_type_key']: model,
                            self.constants['group_key']: group_name
                        }
                        combo.update(dict(zip(param_keys, param_combo)))
                        combinations.append(combo)
            else:
                # æ— å…¶ä»–å‚æ•°
                for model in enabled_models:
                    combo = {**fixed, self.constants['model_type_key']: model, self.constants['group_key']: group_name}
                    combinations.append(combo)

        return combinations

    def _print_group_statistics(self, group_name: str, group_combinations: List[Dict[str, Any]],
                               group_params: Dict[str, Any], enabled_models: List[str],
                               model_batch_dict: Optional[Dict[str, Any]]) -> None:
        """æ‰“å°ç»„åˆç»Ÿè®¡ä¿¡æ¯

        Args:
            group_name: ç»„åç§°
            group_combinations: ç»„åˆåˆ—è¡¨
            group_params: ç»„å‚æ•°å­—å…¸
            enabled_models: å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
            model_batch_dict: æ¨¡å‹-batch_sizeé…å¯¹å­—å…¸
        """
        group_count = len(group_combinations)

        # è®¡ç®—ç»„åˆæ•°é‡çš„åˆ†è§£
        if model_batch_dict is not None:
            # æœ‰æ¨¡å‹-batch_sizeé…å¯¹çš„æƒ…å†µ
            enabled_pairs = {model: batch_size for model, batch_size in model_batch_dict.items()
                            if model in enabled_models}
            model_count = len(enabled_pairs)
            other_params = {k: v for k, v in group_params.items()
                           if k not in self.constants['excluded_params']}
            param_items = [(k, _as_list(v)) for k, v in other_params.items() if _as_list(v)]
            if param_items:
                param_counts = [len(_as_list(v)) for _, v in other_params.items() if _as_list(v)]
                other_count = 1
                for count in param_counts:
                    other_count *= count
                print(f"   âœ… ç»„ {group_name} ç”Ÿæˆ {group_count} ä¸ªç»„åˆ ({model_count}æ¨¡å‹ Ã— {other_count}å‚æ•°ç»„åˆ)")
            else:
                print(f"   âœ… ç»„ {group_name} ç”Ÿæˆ {group_count} ä¸ªç»„åˆ ({model_count}æ¨¡å‹)")
        else:
            # batch_sizeä½œä¸ºç‹¬ç«‹å‚æ•°çš„æƒ…å†µ
            model_count = len(enabled_models)
            all_params = {k: v for k, v in group_params.items() if k != self.constants['model_type_key']}
            param_items = [(k, _as_list(v)) for k, v in all_params.items() if _as_list(v)]
            if param_items:
                param_counts = [len(_as_list(v)) for _, v in all_params.items() if _as_list(v)]
                other_count = 1
                for count in param_counts:
                    other_count *= count
                print(f"   âœ… ç»„ {group_name} ç”Ÿæˆ {group_count} ä¸ªç»„åˆ ({model_count}æ¨¡å‹ Ã— {other_count}å‚æ•°ç»„åˆ)")
            else:
                print(f"   âœ… ç»„ {group_name} ç”Ÿæˆ {group_count} ä¸ªç»„åˆ ({model_count}æ¨¡å‹)")


# ============================================================================
# å®éªŒç»“æœç®¡ç†å™¨ç±»
# ============================================================================

class ExperimentResultsManager:
    """å®éªŒç»“æœç®¡ç†å™¨

    è´Ÿè´£ç®¡ç†CSVæ–‡ä»¶çš„åˆ›å»ºã€å†™å…¥å’Œå­—æ®µåç”Ÿæˆç­‰æ“ä½œã€‚
    """

    def __init__(self, csv_filepath: str, details_filepath: str = None, grid_search_dir: str = None):
        """åˆå§‹åŒ–å¢å¼ºçš„å®éªŒç»“æœç®¡ç†å™¨

        Args:
            csv_filepath: ä¸»ç»“æœCSVæ–‡ä»¶è·¯å¾„
            details_filepath: è¯¦æƒ…CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            grid_search_dir: ç½‘æ ¼æœç´¢æ ¹ç›®å½•è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.csv_filepath = csv_filepath
        self.details_filepath = details_filepath
        self.grid_search_dir = grid_search_dir
        self.fieldnames = None
        self.details_fieldnames = None
        self.constants = GRID_SEARCH_CONSTANTS

        # åˆ›å»ºå¢å¼ºçš„æ–‡ä»¶å¤¹ç»“æ„
        if self.grid_search_dir:
            self.experiments_dir = os.path.join(self.grid_search_dir, "experiments")
            os.makedirs(self.experiments_dir, exist_ok=True)
            print(f"ğŸ“ åˆ›å»ºå®éªŒæ–‡ä»¶å¤¹ç»“æ„: {self.experiments_dir}")

    def get_csv_fieldnames(self, all_params: List[Dict[str, Any]]) -> List[str]:
        """è·å–CSVæ–‡ä»¶çš„å­—æ®µååˆ—è¡¨

        Args:
            all_params: æ‰€æœ‰å‚æ•°ç»„åˆåˆ—è¡¨

        Returns:
            CSVå­—æ®µååˆ—è¡¨
        """
        param_keys = sorted({k for params in all_params for k in params.keys()})

        # åˆå¹¶æ‰€æœ‰å‚æ•°é”®ï¼Œå»é‡å¹¶æ’åºï¼Œæ’é™¤å†—ä½™å‚æ•°
        all_param_keys = sorted(set(param_keys + self.constants['common_runtime_params']) - set(self.constants['excluded_csv_params']))

        # å°†model.typeç§»åˆ°ç¬¬3åˆ—ï¼Œgroupç§»åˆ°ç¬¬4åˆ—ï¼Œå…¶ä»–å‚æ•°æŒ‰åŸé¡ºåºæ’åˆ—
        other_param_keys = [k for k in all_param_keys if k not in [self.constants['model_type_key'], self.constants['group_key']]]

        fieldnames = self.constants['csv_base_columns'] + other_param_keys
        self.fieldnames = fieldnames
        return fieldnames

    def initialize_csv_file(self, fieldnames: List[str]) -> None:
        """åˆå§‹åŒ–CSVæ–‡ä»¶ï¼Œå†™å…¥è¡¨å¤´

        Args:
            fieldnames: CSVå­—æ®µååˆ—è¡¨
        """
        results_dir = os.path.dirname(self.csv_filepath)
        os.makedirs(results_dir, exist_ok=True)

        with open(self.csv_filepath, "w", newline="", encoding="utf-8") as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()

        self.fieldnames = fieldnames

        # å¦‚æœæŒ‡å®šäº†è¯¦æƒ…æ–‡ä»¶ï¼Œä¹Ÿåˆå§‹åŒ–è¯¦æƒ…è¡¨
        if self.details_filepath:
            self.initialize_details_csv()

    def initialize_details_csv(self) -> None:
        """åˆå§‹åŒ–è¯¦æƒ…CSVæ–‡ä»¶"""
        if not self.details_filepath:
            return

        # å¢å¼ºçš„è¯¦æƒ…è¡¨å­—æ®µå
        self.details_fieldnames = [
            'exp_name', 'config_hash', 'epoch', 'ç±»åˆ«åç§°', 'ç²¾ç¡®ç‡', 'å¬å›ç‡',
            'F1åˆ†æ•°', 'å‡†ç¡®ç‡', 'æ­£æ ·æœ¬', 'è´Ÿæ ·æœ¬', 'gamma', 'alpha', 'pos_weight',
            'learning_rate', 'loss_name', 'model_type', 'batch_size'
        ]

        details_dir = os.path.dirname(self.details_filepath)
        os.makedirs(details_dir, exist_ok=True)

        with open(self.details_filepath, "w", newline="", encoding="utf-8") as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=self.details_fieldnames)
            writer.writeheader()

        print(f"ğŸ“‹ åˆå§‹åŒ–è¯¦æƒ…è¡¨: {self.details_filepath}")

    def append_result_to_csv(self, result: Dict[str, Any]) -> None:
        """å®æ—¶è¿½åŠ å•ä¸ªç»“æœåˆ°CSVæ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        Args:
            result: å®éªŒç»“æœ
        """
        if not self.fieldnames:
            raise ValueError("CSVå­—æ®µåæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨initialize_csv_file")

        try:
            # å‡†å¤‡è¡Œæ•°æ®
            row = {
                "exp_name": result.get("exp_name"),
                "success": result.get("success"),
                "trained_epochs": result.get("trained_epochs", 0),
            }

            # æ·»åŠ å¤šæ ‡ç­¾åˆ†ç±»æŒ‡æ ‡
            multilabel_metrics = result.get("multilabel_metrics", {})
            if multilabel_metrics:
                # æœ€ä½³æŒ‡æ ‡
                best_metrics = multilabel_metrics.get("best", {})
                row.update({
                    "best_macro_accuracy": best_metrics.get("macro_accuracy"),
                    "best_micro_accuracy": best_metrics.get("micro_accuracy"),
                    "best_weighted_accuracy": best_metrics.get("weighted_accuracy"),
                    "best_macro_f1": best_metrics.get("macro_f1"),
                    "best_micro_f1": best_metrics.get("micro_f1"),
                    "best_weighted_f1": best_metrics.get("weighted_f1"),
                    "best_macro_precision": best_metrics.get("macro_precision"),
                    "best_macro_recall": best_metrics.get("macro_recall"),
                })

                # æœ€ç»ˆæŒ‡æ ‡
                final_metrics = multilabel_metrics.get("final", {})
                row.update({
                    "final_macro_accuracy": final_metrics.get("macro_accuracy"),
                    "final_micro_accuracy": final_metrics.get("micro_accuracy"),
                    "final_weighted_accuracy": final_metrics.get("weighted_accuracy"),
                    "final_macro_f1": final_metrics.get("macro_f1"),
                    "final_micro_f1": final_metrics.get("micro_f1"),
                    "final_weighted_f1": final_metrics.get("weighted_f1"),
                })

            # ä¼ ç»Ÿå­—æ®µï¼ˆå‘åå…¼å®¹ï¼‰
            row.update({
                "best_accuracy": result.get("best_accuracy"),
                "final_accuracy": result.get("final_accuracy"),
            })

            row.update(result.get("params", {}))

            # åªå†™å…¥fieldnamesä¸­å­˜åœ¨çš„å­—æ®µï¼Œå¿½ç•¥é¢å¤–å­—æ®µ
            filtered_row = {k: v for k, v in row.items() if k in self.fieldnames}

            # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„å¿…éœ€å­—æ®µ
            missing_fields = [k for k in self.fieldnames if k not in row]
            if missing_fields:
                print(f"âš ï¸  ç¼ºå¤±å­—æ®µ: {missing_fields}ï¼Œå°†ä½¿ç”¨ç©ºå€¼å¡«å……")
                for field in missing_fields:
                    filtered_row[field] = ""

            # ä½¿ç”¨æ–‡ä»¶é”ç¡®ä¿çº¿ç¨‹å®‰å…¨
            with open(self.csv_filepath, "a", newline="", encoding="utf-8") as csvfile:
                # è·å–æ–‡ä»¶é”
                fcntl.flock(csvfile.fileno(), fcntl.LOCK_EX)

                writer = csv.DictWriter(csvfile, fieldnames=self.fieldnames)
                writer.writerow(filtered_row)
                csvfile.flush()  # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº

                # é‡Šæ”¾æ–‡ä»¶é”
                fcntl.flock(csvfile.fileno(), fcntl.LOCK_UN)

            print(f"âœ… CSVå†™å…¥æˆåŠŸ: {result.get('exp_name', 'unknown')}")

            # å¦‚æœæœ‰é¢å¤–å­—æ®µï¼Œç»™å‡ºæç¤º
            extra_fields = [k for k in row.keys() if k not in self.fieldnames]
            if extra_fields:
                print(f"â„¹ï¸  å¿½ç•¥é¢å¤–å­—æ®µ: {extra_fields}")

            # å¢å¼ºåŠŸèƒ½ï¼šä¿å­˜è¯¦æƒ…è¡¨å’Œå•å®éªŒæ–‡ä»¶
            if result.get('success', False):
                self._save_enhanced_experiment_data(result)

        except Exception as e:
            print(f"âš ï¸  å†™å…¥CSVå¤±è´¥: {e}")
            print(f"   æ–‡ä»¶è·¯å¾„: {self.csv_filepath}")
            print(f"   å½“å‰å­—æ®µå: {self.fieldnames}")
            print(f"   è¡Œæ•°æ®é”®: {list(row.keys()) if 'row' in locals() else 'N/A'}")
            print(f"   ç»“æœæ•°æ®: {result}")

    def _save_enhanced_experiment_data(self, result: Dict[str, Any]) -> None:
        """ä¿å­˜å¢å¼ºçš„å®éªŒæ•°æ®ï¼ˆè¯¦æƒ…è¡¨ + å•å®éªŒæ–‡ä»¶ï¼‰

        Args:
            result: å®éªŒç»“æœæ•°æ®
        """
        exp_name = result.get('exp_name', 'unknown')

        try:
            # 1. ä¿å­˜åˆ°è¯¦æƒ…è¡¨
            if self.details_filepath and self.details_fieldnames:
                self._append_to_details_csv(result)

            # 2. ä¿å­˜å•å®éªŒæ–‡ä»¶
            if self.experiments_dir:
                self._save_individual_experiment_files(result)

        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¢å¼ºå®éªŒæ•°æ®å¤±è´¥ ({exp_name}): {e}")

    def _append_to_details_csv(self, result: Dict[str, Any]) -> None:
        """è¿½åŠ è¯¦ç»†æŒ‡æ ‡åˆ°è¯¦æƒ…CSVæ–‡ä»¶

        Args:
            result: åŒ…å«detailed_metricsçš„å®éªŒç»“æœ
        """
        try:
            # è·å–è¯¦ç»†æŒ‡æ ‡
            detailed_metrics = result.get('detailed_metrics', {})
            if not detailed_metrics:
                print(f"âš ï¸ å®éªŒ {result.get('exp_name')} ç¼ºå°‘è¯¦ç»†æŒ‡æ ‡æ•°æ®")
                return

            exp_name = result.get('exp_name', '')
            params = result.get('params', {})

            # ç”Ÿæˆé…ç½®å“ˆå¸Œ
            config_hash = self._generate_config_hash(params)

            # è·å–è®­ç»ƒå‚æ•°
            gamma = params.get('loss.params.gamma', params.get('gamma', ''))
            alpha = params.get('loss.params.alpha', params.get('alpha', ''))
            pos_weight = params.get('loss.params.pos_weight', params.get('pos_weight', ''))
            learning_rate = params.get('hp.learning_rate', params.get('learning_rate', ''))
            loss_name = params.get('loss.name', '')
            model_type = params.get('model.type', '')
            batch_size = params.get('hp.batch_size', params.get('batch_size', ''))

            # è·å–æœ€ä½³epoch
            best_epoch = detailed_metrics.get('epoch', result.get('trained_epochs', 0))

            # å‡†å¤‡è¯¦æƒ…è¡¨æ•°æ®è¡Œ
            rows = []

            # 1. æ·»åŠ å„ä¸ªç±»åˆ«çš„æŒ‡æ ‡
            class_metrics = detailed_metrics.get('class_metrics', {})
            for class_name, metrics in class_metrics.items():
                row = {
                    'exp_name': exp_name,
                    'config_hash': config_hash,
                    'epoch': best_epoch,
                    'ç±»åˆ«åç§°': class_name,
                    'ç²¾ç¡®ç‡': round(metrics.get('precision', 0), 4),
                    'å¬å›ç‡': round(metrics.get('recall', 0), 4),
                    'F1åˆ†æ•°': round(metrics.get('f1', 0), 4),
                    'å‡†ç¡®ç‡': round(metrics.get('accuracy', 0), 4),
                    'æ­£æ ·æœ¬': metrics.get('pos_samples', 0),
                    'è´Ÿæ ·æœ¬': metrics.get('neg_samples', 0),
                    'gamma': gamma,
                    'alpha': alpha,
                    'pos_weight': pos_weight,
                    'learning_rate': learning_rate,
                    'loss_name': loss_name,
                    'model_type': model_type,
                    'batch_size': batch_size
                }
                rows.append(row)

            # 2. æ·»åŠ å¹³å‡æŒ‡æ ‡ï¼ˆä½œä¸ºç‰¹æ®Šç±»åˆ«ï¼‰
            avg_metrics = [
                ('ğŸ¯åŠ æƒå¹³å‡', detailed_metrics.get('weighted_avg', {})),
                ('ğŸ“Šå®å¹³å‡', detailed_metrics.get('macro_avg', {})),
                ('ğŸ“ˆå¾®å¹³å‡', detailed_metrics.get('micro_avg', {}))
            ]

            for avg_name, avg_data in avg_metrics:
                if avg_data:
                    row = {
                        'exp_name': exp_name,
                        'config_hash': config_hash,
                        'epoch': best_epoch,
                        'ç±»åˆ«åç§°': avg_name,
                        'ç²¾ç¡®ç‡': round(avg_data.get('precision', 0), 4),
                        'å¬å›ç‡': round(avg_data.get('recall', 0), 4),
                        'F1åˆ†æ•°': round(avg_data.get('f1', 0), 4),
                        'å‡†ç¡®ç‡': round(avg_data.get('accuracy', 0), 4),
                        'æ­£æ ·æœ¬': '',  # å¹³å‡æŒ‡æ ‡ä¸æ˜¾ç¤ºæ ·æœ¬æ•°
                        'è´Ÿæ ·æœ¬': '',
                        'gamma': gamma,
                        'alpha': alpha,
                        'pos_weight': pos_weight,
                        'learning_rate': learning_rate,
                        'loss_name': loss_name,
                        'model_type': model_type,
                        'batch_size': batch_size
                    }
                    rows.append(row)

            # æ‰¹é‡å†™å…¥è¯¦æƒ…è¡¨
            if rows:
                with open(self.details_filepath, "a", newline="", encoding="utf-8") as csvfile:
                    fcntl.flock(csvfile.fileno(), fcntl.LOCK_EX)
                    writer = csv.DictWriter(csvfile, fieldnames=self.details_fieldnames)
                    writer.writerows(rows)
                    csvfile.flush()
                    fcntl.flock(csvfile.fileno(), fcntl.LOCK_UN)

                print(f"ğŸ“Š å·²ä¿å­˜ {len(rows)} æ¡è¯¦ç»†æŒ‡æ ‡åˆ°è¯¦æƒ…è¡¨ ({exp_name})")

        except Exception as e:
            print(f"âš ï¸ å†™å…¥è¯¦æƒ…è¡¨å¤±è´¥: {e}")

    def _save_individual_experiment_files(self, result: Dict[str, Any]) -> None:
        """ä¿å­˜å•ä¸ªå®éªŒçš„æ–‡ä»¶

        Args:
            result: å®éªŒç»“æœæ•°æ®
        """
        exp_name = result.get('exp_name', 'unknown')

        try:
            # åˆ›å»ºå•å®éªŒæ–‡ä»¶å¤¹
            exp_dir = os.path.join(self.experiments_dir, exp_name)
            os.makedirs(exp_dir, exist_ok=True)

            # 1. ä¿å­˜å®éªŒé…ç½®
            config_file = os.path.join(exp_dir, "config.yaml")
            config_data = {
                'exp_name': exp_name,
                'parameters': result.get('params', {}),
                'success': result.get('success', False),
                'trained_epochs': result.get('trained_epochs', 0),
                'timestamp': datetime.now().isoformat()
            }

            with open(config_file, 'w', encoding='utf-8') as f:
                yaml.dump(config_data, f, default_flow_style=False, allow_unicode=True)

            # 2. å¤åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„é€epochæŒ‡æ ‡æ–‡ä»¶
            self._copy_epoch_metrics_files(exp_dir, result)

            # 3. ä¿å­˜ç±»åˆ«æŒ‡æ ‡å†å²ï¼ˆå¦‚æœæœ‰è¯¦ç»†æŒ‡æ ‡ï¼‰
            detailed_metrics = result.get('detailed_metrics', {})
            if detailed_metrics and 'class_metrics' in detailed_metrics:
                self._save_class_metrics_history(exp_dir, detailed_metrics)

            # 4. ä¿å­˜æœ€ä½³æŒ‡æ ‡æ±‡æ€»
            if detailed_metrics:
                self._save_best_metrics_summary(exp_dir, detailed_metrics)

            print(f"ğŸ“ å·²ä¿å­˜å•å®éªŒæ–‡ä»¶: {exp_dir}")

        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å•å®éªŒæ–‡ä»¶å¤±è´¥ ({exp_name}): {e}")

    def _save_class_metrics_history(self, exp_dir: str, detailed_metrics: Dict[str, Any]) -> None:
        """ä¿å­˜ç±»åˆ«æŒ‡æ ‡å†å²æ–‡ä»¶ï¼ˆç°åœ¨åªä¿å­˜æœ€ä½³epochçš„æŒ‡æ ‡ï¼Œä¸best_metrics_summary.csvåŠŸèƒ½ç±»ä¼¼ï¼‰

        æ³¨æ„ï¼šæ­¤æ–¹æ³•ç°åœ¨ä¸»è¦ç”¨äºå‘åå…¼å®¹ï¼Œå®é™…çš„é€epochæŒ‡æ ‡è®°å½•ç”±è®­ç»ƒå™¨ä¸­çš„
        train_metrics_history.csvå’Œtest_metrics_history.csvæ–‡ä»¶å¤„ç†
        """
        import pandas as pd

        class_metrics = detailed_metrics.get('class_metrics', {})
        epoch = detailed_metrics.get('epoch', 0)

        rows = []
        for class_name, metrics in class_metrics.items():
            row = {
                'epoch': epoch,
                'class_name': class_name,
                'precision': metrics.get('precision', 0),
                'recall': metrics.get('recall', 0),
                'f1': metrics.get('f1', 0),
                'accuracy': metrics.get('accuracy', 0),
                'pos_samples': metrics.get('pos_samples', 0),
                'neg_samples': metrics.get('neg_samples', 0)
            }
            rows.append(row)

        if rows:
            df = pd.DataFrame(rows)
            csv_file = os.path.join(exp_dir, "class_metrics_history.csv")
            df.to_csv(csv_file, index=False, encoding='utf-8')

    def _copy_epoch_metrics_files(self, exp_dir: str, result: Dict[str, Any]) -> None:
        """å¤åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„é€epochæŒ‡æ ‡æ–‡ä»¶åˆ°å•å®éªŒæ–‡ä»¶å¤¹

        Args:
            exp_dir: å•å®éªŒæ–‡ä»¶å¤¹è·¯å¾„
            result: å®éªŒç»“æœæ•°æ®
        """
        import shutil

        # è·å–åŸå§‹æŒ‡æ ‡æ–‡ä»¶çš„è·¯å¾„ï¼ˆä»è®­ç»ƒå™¨çš„è¾“å‡ºç›®å½•ï¼‰
        detailed_metrics = result.get('detailed_metrics', {})
        if not detailed_metrics:
            return

        # å°è¯•ä»configä¸­è·å–ä»»åŠ¡è¾“å‡ºç›®å½•
        config = result.get('config', {})
        task_config = config.get('task', {})
        task_tag = task_config.get('tag', '')
        dataset_type = config.get('data', {}).get('type', '')

        # æ„å»ºåŸå§‹è¾“å‡ºç›®å½•è·¯å¾„
        if 'multilabel' in dataset_type.lower() or 'multilabel' in task_tag.lower():
            from src.trainers.base_trainer import get_task_output_dir
            source_dir = get_task_output_dir(task_tag, dataset_type)

            # éœ€è¦å¤åˆ¶çš„æ–‡ä»¶åˆ—è¡¨
            files_to_copy = [
                'train_metrics_history.csv',  # è®­ç»ƒé›†é€epochæŒ‡æ ‡
                'test_metrics_history.csv',   # æµ‹è¯•é›†é€epochæŒ‡æ ‡
                'class_metrics_history.csv'   # åŸæœ‰çš„ç±»åˆ«æŒ‡æ ‡å†å²ï¼ˆç°åœ¨è®°å½•æ¯ä¸ªepochï¼‰
            ]

            for filename in files_to_copy:
                source_file = os.path.join(source_dir, filename)
                target_file = os.path.join(exp_dir, filename)

                if os.path.exists(source_file):
                    try:
                        shutil.copy2(source_file, target_file)
                        print(f"ğŸ“‹ å·²å¤åˆ¶æŒ‡æ ‡æ–‡ä»¶: {filename}")
                    except Exception as e:
                        print(f"âš ï¸ å¤åˆ¶æŒ‡æ ‡æ–‡ä»¶å¤±è´¥ ({filename}): {e}")
                else:
                    print(f"âš ï¸ æŒ‡æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {source_file}")

    def _save_best_metrics_summary(self, exp_dir: str, detailed_metrics: Dict[str, Any]) -> None:
        """ä¿å­˜æœ€ä½³æŒ‡æ ‡æ±‡æ€»æ–‡ä»¶"""
        import pandas as pd

        # å‡†å¤‡æ±‡æ€»æ•°æ®
        summary_data = []

        # æ·»åŠ å„ç±»åˆ«æŒ‡æ ‡
        class_metrics = detailed_metrics.get('class_metrics', {})
        for class_name, metrics in class_metrics.items():
            summary_data.append({
                'ç±»åˆ«åç§°': class_name,
                'ç²¾ç¡®ç‡': f"{metrics.get('precision', 0):.4f}",
                'å¬å›ç‡': f"{metrics.get('recall', 0):.4f}",
                'F1åˆ†æ•°': f"{metrics.get('f1', 0):.4f}",
                'å‡†ç¡®ç‡': f"{metrics.get('accuracy', 0):.4f}",
                'æ­£æ ·æœ¬æ•°': metrics.get('pos_samples', 0),
                'è´Ÿæ ·æœ¬æ•°': metrics.get('neg_samples', 0)
            })

        # æ·»åŠ å¹³å‡æŒ‡æ ‡
        avg_metrics = [
            ('ğŸ¯åŠ æƒå¹³å‡', detailed_metrics.get('weighted_avg', {})),
            ('ğŸ“Šå®å¹³å‡', detailed_metrics.get('macro_avg', {})),
            ('ğŸ“ˆå¾®å¹³å‡', detailed_metrics.get('micro_avg', {}))
        ]

        for avg_name, avg_data in avg_metrics:
            if avg_data:
                summary_data.append({
                    'ç±»åˆ«åç§°': avg_name,
                    'ç²¾ç¡®ç‡': f"{avg_data.get('precision', 0):.4f}",
                    'å¬å›ç‡': f"{avg_data.get('recall', 0):.4f}",
                    'F1åˆ†æ•°': f"{avg_data.get('f1', 0):.4f}",
                    'å‡†ç¡®ç‡': f"{avg_data.get('accuracy', 0):.4f}",
                    'æ­£æ ·æœ¬æ•°': '',
                    'è´Ÿæ ·æœ¬æ•°': ''
                })

        if summary_data:
            df = pd.DataFrame(summary_data)
            csv_file = os.path.join(exp_dir, "best_metrics_summary.csv")
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')

    def _generate_config_hash(self, params: Dict[str, Any]) -> str:
        """ç”Ÿæˆå‚æ•°é…ç½®çš„å“ˆå¸Œå€¼"""
        # æå–å…³é”®å‚æ•°ç”¨äºç”Ÿæˆå“ˆå¸Œ
        key_params = {
            'model_type': params.get('model.type', ''),
            'loss_name': params.get('loss.name', ''),
            'gamma': params.get('loss.params.gamma', params.get('gamma', '')),
            'alpha': params.get('loss.params.alpha', params.get('alpha', '')),
            'pos_weight': params.get('loss.params.pos_weight', params.get('pos_weight', '')),
            'learning_rate': params.get('hp.learning_rate', params.get('learning_rate', '')),
            'batch_size': params.get('hp.batch_size', params.get('batch_size', ''))
        }

        # ç”Ÿæˆå“ˆå¸Œ
        config_str = json.dumps(key_params, sort_keys=True)
        return hashlib.md5(config_str.encode()).hexdigest()[:8]


def load_grid_config(path: str = "config/grid.yaml") -> Dict[str, Any]:
    """åŠ è½½ç½‘æ ¼æœç´¢é…ç½®"""
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def _as_list(v: Any) -> List[Any]:
    """å°†è¾“å…¥è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼

    Args:
        v: ä»»æ„ç±»å‹çš„å‚æ•°å€¼

    Returns:
        ç»Ÿä¸€æ ¼å¼åŒ–åçš„åˆ—è¡¨
    """
    if v is None:
        return []
    return v if isinstance(v, (list, tuple)) else [v]

def generate_combinations(config: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    åˆ†ç»„å¼å‚æ•°ç»„åˆç”Ÿæˆå™¨

    è®¾è®¡é€»è¾‘ï¼š
    1. ä»YAMLä¸­è·å–groupsé…ç½®ï¼Œæ¯ç»„æœ‰è‡ªå·±çš„æ¨¡å‹å’Œè¶…å‚æ•°èŒƒå›´
    2. ä¸ºæ¯ç»„å†…çš„å‚æ•°è¿›è¡Œç¬›å¡å°”ç§¯ç»„åˆ
    3. æ ¹æ®models_to_trainè¿‡æ»¤å¯ç”¨çš„æ¨¡å‹
    4. é¿å…æ— æ„ä¹‰çš„æ¨¡å‹-å‚æ•°ç»„åˆï¼ŒèŠ‚çœç®—åŠ›

    Args:
        config: ç½‘æ ¼æœç´¢é…ç½®

    Returns:
        å‚æ•°ç»„åˆåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€ç»„å®éªŒå‚æ•°
    """
    generator = ParameterCombinationGenerator(config)
    return generator.generate_combinations()



# ============================================================================
# å‘åå…¼å®¹çš„å‡½æ•°æ¥å£
# ============================================================================

def get_csv_fieldnames(all_params: List[Dict[str, Any]]) -> List[str]:
    """è·å–CSVæ–‡ä»¶çš„å­—æ®µååˆ—è¡¨ï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰"""
    # åˆ›å»ºä¸´æ—¶çš„ç»“æœç®¡ç†å™¨æ¥ç”Ÿæˆå­—æ®µå
    temp_manager = ExperimentResultsManager("")
    return temp_manager.get_csv_fieldnames(all_params)


def initialize_csv_file(filepath: str, fieldnames: List[str]) -> None:
    """åˆå§‹åŒ–CSVæ–‡ä»¶ï¼Œå†™å…¥è¡¨å¤´ï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰"""
    manager = ExperimentResultsManager(filepath)
    manager.initialize_csv_file(fieldnames)


def append_result_to_csv(result: Dict[str, Any], filepath: str, fieldnames: List[str], experiment_id: int = None) -> None:
    """å®æ—¶è¿½åŠ å•ä¸ªç»“æœåˆ°CSVæ–‡ä»¶ï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰"""
    manager = ExperimentResultsManager(filepath)
    manager.fieldnames = fieldnames  # è®¾ç½®å­—æ®µå
    manager.append_result_to_csv(result)





def save_results_to_csv(results: List[Dict[str, Any]], filename: str) -> Optional[str]:
    """ä¿å­˜å®éªŒç»“æœåˆ°CSVæ–‡ä»¶ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰

    Args:
        results: å®éªŒç»“æœåˆ—è¡¨
        filename: CSVæ–‡ä»¶å

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ— ç»“æœåˆ™è¿”å›None
    """
    if not results:
        print("âš ï¸  æ— ç»“æœæ•°æ®ï¼Œè·³è¿‡CSVä¿å­˜")
        return None

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs("runs", exist_ok=True)
    filepath = f"runs/{filename}"

    # åˆ›å»ºç»“æœç®¡ç†å™¨
    manager = ExperimentResultsManager(filepath)

    # è·å–å­—æ®µåå¹¶åˆå§‹åŒ–CSVæ–‡ä»¶
    fieldnames = manager.get_csv_fieldnames([r.get("params", {}) for r in results])
    manager.initialize_csv_file(fieldnames)

    # å†™å…¥æ‰€æœ‰ç»“æœ
    for result in results:
        manager.append_result_to_csv(result)

    print(f"ğŸ“Š å®éªŒç»“æœå·²ä¿å­˜åˆ°: {filepath}")
    print(f"   æ€»å®éªŒæ•°: {len(results)}")
    print(f"   æˆåŠŸå®éªŒ: {sum(1 for r in results if r.get('success', False))}")
    print(f"   å¤±è´¥å®éªŒ: {sum(1 for r in results if not r.get('success', False))}")

    return filepath


def apply_param_overrides(config, params):
    """åº”ç”¨å‚æ•°è¦†ç›–åˆ°é…ç½®å­—å…¸

    Args:
        config (dict): åŸºç¡€é…ç½®å­—å…¸
        params (dict): å‚æ•°è¦†ç›–å­—å…¸ï¼Œæ”¯æŒåµŒå¥—è·¯å¾„

    Returns:
        dict: åº”ç”¨è¦†ç›–åçš„é…ç½®å­—å…¸
    """
    import copy
    config = copy.deepcopy(config)
    
    for k, v in (params or {}).items():
        keys = k.split('.')
        target = config
        for key in keys[:-1]:
            target = target.setdefault(key, {})
        target[keys[-1]] = v
    
    return config


def run_single_experiment_in_process(params, exp_id, config_path):
    """è¿›ç¨‹å†…è°ƒç”¨æ–¹å¼è¿è¡Œå•ä¸ªå®éªŒï¼ˆå•å¡è®­ç»ƒï¼‰"""
    exp_name = f"grid_{exp_id}"
    
    try:
        # å¯¼å…¥è®­ç»ƒå‡½æ•°
        from src.trainers.base_trainer import run_training
        
        # åŠ è½½åŸºç¡€é…ç½®
        config = load_grid_config(config_path)
        
        # åº”ç”¨å‚æ•°è¦†ç›–
        config = apply_param_overrides(config, params)
        
        # ç›´æ¥è°ƒç”¨è®­ç»ƒå‡½æ•°
        result = run_training(config, exp_name)
        
        # æ·»åŠ å‚æ•°ä¿¡æ¯åˆ°ç»“æœä¸­
        result["params"] = params
        
        return result
        
    except Exception as e:
        return {
            "success": False,
            "exp_name": exp_name,
            "params": params,
            "best_accuracy": 0.0,
            "final_accuracy": 0.0,
            "trained_epochs": 0,
            "error": str(e)
        }


def run_single_experiment_subprocess(params, exp_id, use_multi_gpu, config_path):
    """å­è¿›ç¨‹æ–¹å¼è¿è¡Œå•ä¸ªå®éªŒï¼ˆå¤šå¡è®­ç»ƒï¼‰"""
    exp_name = f"grid_{exp_id}"
    
    # åˆ›å»ºä¸´æ—¶ç»“æœæ–‡ä»¶ç”¨äºè¿›ç¨‹é—´é€šä¿¡
    temp_result_file = f"/tmp/grid_result_{exp_id}_{random.randint(1000,9999)}.json"
    
    # ç»„è£…å‘½ä»¤
    if use_multi_gpu:
        import torch  # å±€éƒ¨å¯¼å…¥ï¼Œä»…åœ¨éœ€è¦æ—¶ä½¿ç”¨
        cmd = ["accelerate", "launch", "--multi_gpu", "--num_processes", str(torch.cuda.device_count())]
    else:
        cmd = [sys.executable, "-u"]
    
    # æ·»åŠ è®­ç»ƒè„šæœ¬å’ŒåŸºç¡€å‚æ•°
    cmd.extend(["scripts/train.py", "--config", config_path, "--exp_name", exp_name])
    cmd.extend(["--result_file", temp_result_file])  # æ–°å¢ï¼šæŒ‡å®šç»“æœæ–‡ä»¶
    
    # æ·»åŠ å‚æ•°è¦†ç›–ï¼ˆæ’é™¤groupå‚æ•°ï¼Œå®ƒåªç”¨äºè®°å½•ï¼‰
    for k, v in (params or {}).items():
        if k != "group":  # groupå‚æ•°ä¸ä¼ é€’ç»™è®­ç»ƒè„šæœ¬
            cmd.extend([f"--{k}", str(v)])

    # æ¸…ç†ç¯å¢ƒå˜é‡å¹¶è®¾ç½®å”¯ä¸€ç«¯å£
    env = os.environ.copy()
    for k in ["LOCAL_RANK", "RANK", "WORLD_SIZE", "MASTER_ADDR", "MASTER_PORT"]:
        env.pop(k, None)
    env["MASTER_ADDR"] = env.get("MASTER_ADDR", "127.0.0.1")
    env["MASTER_PORT"] = str(20000 + random.randint(0, 10000))

    # å¯åŠ¨å­è¿›ç¨‹
    process = subprocess.Popen(cmd, env=env)
    try:
        rc = process.wait()
    except KeyboardInterrupt:
        print(f"æ•è·åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ç»ˆæ­¢å­è¿›ç¨‹ {process.pid}...")
        process.terminate()
        process.wait()
        raise

    success = (rc == 0)
    
    # è¯»å–ç»“æœæ–‡ä»¶
    try:
        if os.path.exists(temp_result_file):
            with open(temp_result_file, 'r', encoding='utf-8') as f:
                result = json.load(f)
            os.remove(temp_result_file)  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            
            # ç¡®ä¿ç»“æœåŒ…å«å¿…è¦çš„å­—æ®µ
            result["params"] = params
            result["success"] = result.get("success", success)
            result["exp_name"] = result.get("exp_name", exp_name)
            
            # ç¡®ä¿accuracyå­—æ®µä¸ä¸ºNone
            if result.get("best_accuracy") is None:
                result["best_accuracy"] = 0.0
            if result.get("final_accuracy") is None:
                result["final_accuracy"] = 0.0
                
            return result
        else:
            print(f"ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {temp_result_file}")
    except Exception as e:
        print(f"è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        if os.path.exists(temp_result_file):
            try:
                with open(temp_result_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                print(f"æ–‡ä»¶å†…å®¹: {content[:200]}...")  # æ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
            except:
                pass
    
    # å›é€€ï¼šè¿”å›é»˜è®¤ç»“æœ
    return {
        "success": success,
        "exp_name": exp_name,
        "params": params,
        "best_accuracy": 0.0,
        "final_accuracy": 0.0,
        "trained_epochs": 0,
        "error": "Failed to read result file" if success else "Training process failed"
    }


def run_single_experiment(params, exp_id, use_multi_gpu=False, config_path="config/grid.yaml"):
    """è¿è¡Œå•ä¸ªå®éªŒ

    Args:
        params (dict): å®éªŒå‚æ•°è¦†ç›–
        exp_id (str): å®éªŒID
        use_multi_gpu (bool): æ˜¯å¦ä½¿ç”¨å¤šGPU
        config_path (str): é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        dict: å®éªŒç»“æœå­—å…¸
    """
    exp_name = f"grid_{exp_id}"

    # å®éªŒä¿¡æ¯å°†åœ¨è®­ç»ƒå™¨ä¸­çš„SwanLabå¯åŠ¨åæ˜¾ç¤º

    if use_multi_gpu:
        # å¤šå¡è®­ç»ƒï¼šä½¿ç”¨å­è¿›ç¨‹æ–¹å¼
        result = run_single_experiment_subprocess(params, exp_id, use_multi_gpu, config_path)
    else:
        # å•å¡è®­ç»ƒï¼šä½¿ç”¨è¿›ç¨‹å†…è°ƒç”¨æ–¹å¼
        result = run_single_experiment_in_process(params, exp_id, config_path)
    
    print(f"âœ… å®éªŒ {exp_name} å®Œæˆï¼Œæœ€ä½³: {result['best_accuracy']:.2f}% | æœ€ç»ˆ: {result['final_accuracy']:.2f}%")
    
    return result


def run_grid_search(args):
    """è¿è¡Œç½‘æ ¼æœç´¢"""
    config = load_grid_config(args.config)
    combinations = generate_combinations(config)

    if len(combinations) > args.max_experiments:
        combinations = combinations[:args.max_experiments]

    # å‡†å¤‡CSVæ–‡ä»¶ - æ ¹æ®ä»»åŠ¡ç±»å‹åˆ›å»ºå¯¹åº”ç›®å½•
    task_tag = config.get('task', {}).get('tag', '')
    dataset_type = config.get('data', {}).get('type', '')

    # æ ¹æ®ä»»åŠ¡ç±»å‹ç¡®å®šå­ç›®å½•å
    if 'multilabel' in task_tag.lower() or 'multilabel' in dataset_type.lower():
        if 'neonatal' in dataset_type.lower():
            task_subdir = "neonatal_multilabel"
        else:
            task_subdir = "multilabel_classification"
    elif 'video' in task_tag.lower():
        task_subdir = "video_classification"
    elif 'image' in task_tag.lower():
        task_subdir = "image_classification"
    elif 'text' in task_tag.lower():
        task_subdir = "text_classification"
    else:
        # é»˜è®¤ä½¿ç”¨æ•°æ®é›†ç±»å‹ä½œä¸ºå­ç›®å½•å
        task_subdir = dataset_type.replace('_', '_').lower() or "general"

    results_dir = os.path.join("runs", task_subdir)

    if args.results_file:
        # ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„æ–‡ä»¶å
        results_filename = args.results_file
    else:
        # ä½¿ç”¨é»˜è®¤çš„æ—¶é—´æˆ³æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_filename = f"grid_search_results_{timestamp}.csv"
    csv_filepath = os.path.join(results_dir, results_filename)

    # åˆ›å»ºå¢å¼ºçš„ç½‘æ ¼æœç´¢æ–‡ä»¶å¤¹ç»“æ„
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    grid_search_dir = os.path.join(results_dir, f"grid_search_{timestamp}")

    # ç§»åŠ¨ä¸»ç»“æœæ–‡ä»¶åˆ°ç½‘æ ¼æœç´¢ç›®å½•
    csv_filepath = os.path.join(grid_search_dir, "grid_search_results.csv")
    details_filepath = os.path.join(grid_search_dir, "grid_search_details.csv")

    # è·å–CSVå­—æ®µå
    all_params = [params for params in combinations]
    fieldnames = get_csv_fieldnames(all_params)

    # åˆ›å»ºå¢å¼ºçš„ç»“æœç®¡ç†å™¨
    results_manager = ExperimentResultsManager(
        csv_filepath=csv_filepath,
        details_filepath=details_filepath,
        grid_search_dir=grid_search_dir
    )

    # åˆå§‹åŒ–CSVæ–‡ä»¶
    if args.save_results:
        os.makedirs(grid_search_dir, exist_ok=True)
        results_manager.initialize_csv_file(fieldnames)
    else:
        # ä¸ä¿å­˜ç»“æœæ—¶ä¹Ÿéœ€è¦åˆå§‹åŒ–
        results_manager.initialize_csv_file(fieldnames)

    print(f"ğŸš€ å¼€å§‹ç½‘æ ¼æœç´¢ï¼Œå…± {len(combinations)} ä¸ªå®éªŒ")
    print(f"ğŸ“Š ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
    print(f"ğŸ“ ç½‘æ ¼æœç´¢ç›®å½•: {grid_search_dir}")
    print(f"ğŸ’¾ ä¸»ç»“æœæ–‡ä»¶: {csv_filepath}")
    print(f"ğŸ“‹ è¯¦æƒ…è¡¨æ–‡ä»¶: {details_filepath}")
    
    # å¤„ç†data_percentageå‚æ•°ï¼šå¦‚æœæœªæŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼1.0
    data_percentage = args.data_percentage if args.data_percentage is not None else 1.0

    # æ˜¾ç¤ºå…¨å±€å‚æ•°è¦†ç›–
    if args.data_percentage is not None:
        print(f"ğŸ¯ å…¨å±€å‚æ•°è¦†ç›–: data_percentage={args.data_percentage}")
    else:
        print(f"ğŸ¯ ä½¿ç”¨é»˜è®¤data_percentage: {data_percentage}")

    print("=" * 60)

    results = []
    successful = 0

    for i, params in enumerate(combinations, 1):
        exp_name = f"grid_{i:03d}"

        print(f"ğŸ“Š å‡†å¤‡å®éªŒ {i}/{len(combinations)}")

        # å°†å‘½ä»¤è¡Œå‚æ•°æ·»åŠ åˆ°å®éªŒå‚æ•°ä¸­
        experiment_params = params.copy()
        # å§‹ç»ˆæ·»åŠ data_percentageå‚æ•°ï¼Œç¡®ä¿CSVè®°å½•å®Œæ•´
        experiment_params['data_percentage'] = data_percentage

        result = run_single_experiment(
            experiment_params, f"{i:03d}",
            use_multi_gpu=args.multi_gpu,
            config_path=args.config,
        )

        results.append(result)
        if result["success"]:
            successful += 1
            
        # å®æ—¶å†™å…¥CSVï¼ˆåŒ…æ‹¬å¢å¼ºåŠŸèƒ½ï¼‰
        if args.save_results:
            print(f"ğŸ’¾ å†™å…¥å®éªŒç»“æœåˆ°CSV: {result.get('exp_name', 'unknown')}")
            results_manager.append_result_to_csv(result)
            
        # å®æ—¶æ˜¾ç¤ºæœ€ä½³ç»“æœ
        if successful > 0:
            current_best = max([r for r in results if r["success"]], key=lambda x: x["best_accuracy"])
            print(f"ğŸ† å½“å‰æœ€ä½³: {current_best['exp_name']} - {current_best['best_accuracy']:.2f}%")

    # æ€»ç»“
    print("=" * 60)
    print(f"ğŸ“ˆ ç½‘æ ¼æœç´¢å®Œæˆï¼")
    print(f"âœ… æˆåŠŸå®éªŒæ•°é‡: {successful}/{len(combinations)}")

    if successful > 0:
        successful_results = [r for r in results if r["success"]]
        # æ‰¾åˆ°â€œæœ€ä½³å‡†ç¡®ç‡â€æœ€é«˜çš„å®éªŒç»“æœ
        best_result = max(successful_results, key=lambda x: x["best_accuracy"])

        print(f"ğŸ† æœ€ä½³å®éªŒç»“æœ:")
        print(f"å®éªŒåç§°: {best_result['exp_name']}, æœ€ä½³å‡†ç¡®ç‡: {best_result['best_accuracy']:.2f}%, æœ€ç»ˆå‡†ç¡®ç‡: {best_result['final_accuracy']:.2f}%")
        
        # æŒ‰æœ€ä½³ç²¾åº¦æ’åºå‰nç»„ç»“æœ
        top_results = sorted(successful_results, key=lambda x: x["best_accuracy"], reverse=True)[:args.top_n]
        
        print(f"ğŸ“Š å‰{args.top_n}åå®éªŒç»“æœ:")
        for i, r in enumerate(top_results, 1):
            print(f"{i}. {r['exp_name']} - {r['best_accuracy']:.2f}% - {r['params']}")

    if args.save_results:
        print(f"ğŸ’¾ ä¸»ç»“æœå·²å®æ—¶ä¿å­˜åˆ°: {csv_filepath}")
        print(f"ğŸ“‹ è¯¦æƒ…è¡¨å·²å®æ—¶ä¿å­˜åˆ°: {details_filepath}")
        print(f"ğŸ“ å•å®éªŒæ–‡ä»¶å·²ä¿å­˜åˆ°: {results_manager.experiments_dir}")

    return 0 if successful > 0 else 1


def main():
    """ä¸»å‡½æ•°ï¼šè°ƒåº¦å™¨å§‹ç»ˆå•è¿›ç¨‹ï¼Œä¸è¿›å…¥ Accelerate ç¯å¢ƒ"""
    args, _ = parse_arguments(mode="grid_search")
    return run_grid_search(args)


if __name__ == "__main__":
    sys.exit(main())