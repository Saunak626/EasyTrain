"""
ç½‘æ ¼æœç´¢å¯åŠ¨è„šæœ¬
- è°ƒåº¦å™¨ä¿æŒå•è¿›ç¨‹è¿è¡Œ
- æ¯ä¸ªå®éªŒç‹¬ç«‹ç”¨ accelerate å¯åŠ¨ï¼ˆå¤šå¡ï¼‰æˆ– python å¯åŠ¨ï¼ˆå•å¡/CPUï¼‰
- ä¸ºæ¯æ¬¡å®éªŒè®¾ç½®å”¯ä¸€ MASTER_PORTï¼Œæ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ï¼Œé¿å…è¿›ç¨‹é—´ä¸²æ‰°
"""

import itertools
import subprocess
import yaml
import os
import sys
import time
import csv
import json
import random
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.utils.config_parser import parse_arguments


# ----------------------------- å·¥å…·å‡½æ•° -----------------------------

def load_grid_config(path="config/grid.yaml"):
    """åŠ è½½ç½‘æ ¼æœç´¢é…ç½®"""
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def _as_list(v):
    """æ ‡é‡â†’å•å…ƒç´ åˆ—è¡¨ï¼›åˆ—è¡¨/å…ƒç»„åŸæ ·ï¼›Noneâ†’ç©ºåˆ—è¡¨"""
    if v is None:
        return []
    return v if isinstance(v, (list, tuple)) else [v]

def generate_combinations(config):
    """
    åªæ”¯æŒç¬›å¡å°”ç§¯ï¼š
      - grid_search.grid: dict[str, list|scalar]ï¼Œæ ‡é‡ä¼šå½“ä½œå•å…ƒç´ åˆ—è¡¨
      - grid_search.fixed: dictï¼Œå›ºå®šå‚æ•°å¹¶å…¥æ¯ä¸ªç»„åˆ
    """
    gs = (config or {}).get("grid_search", {}) or {}
    fixed = gs.get("fixed", {}) or {}
    grid = gs.get("grid", {}) or {}

    if not grid:
        return [fixed] if fixed else [{}]

    # è¿‡æ»¤ç©ºåˆ—è¡¨çš„é”®ï¼Œé¿å…ç”Ÿæˆç©ºç»„åˆ
    valid_items = [(k, _as_list(v)) for k, v in grid.items() if _as_list(v)]
    
    if not valid_items:
        return [fixed] if fixed else [{}]

    keys, values_lists = zip(*valid_items)

    # ç¬›å¡å°”ç§¯ç”Ÿæˆç»„åˆï¼Œå¹¶åˆå¹¶ fixed
    return [{**fixed, **dict(zip(keys, combo))} 
            for combo in itertools.product(*values_lists)]


def parse_result_from_files(exp_name):
    """ä»ç»“æ„åŒ–æ–‡ä»¶ä¸­è§£ææœ€ç»ˆç»“æœï¼ˆä¼˜å…ˆ result.jsonï¼Œå›é€€ metrics.jsonlï¼‰"""
    result_dir = os.path.join("runs", exp_name)
    final_json = os.path.join(result_dir, "result.json")
    metrics_path = os.path.join(result_dir, "metrics.jsonl")

    # ä¼˜å…ˆè¯»å– result.json
    try:
        if os.path.exists(final_json):
            with open(final_json, "r", encoding="utf-8") as f:
                data = json.load(f) or {}
                best_accuracy = float(data.get("best_accuracy", 0.0))
                final_accuracy = float(data.get("final_accuracy", best_accuracy))
                return best_accuracy, final_accuracy
    except Exception:
        pass

    # å›é€€ï¼šæ‰«æ metrics.jsonl
    try:
        if os.path.exists(metrics_path):
            last_val, best_val = None, 0.0
            with open(metrics_path, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        va = json.loads(line).get("val_acc")
                        if isinstance(va, (int, float)):
                            last_val = float(va)
                            best_val = max(best_val, last_val)
                    except Exception:
                        continue
            if last_val is not None:
                return best_val, last_val
    except Exception:
        pass

    return 0.0, 0.0


def save_results_to_csv(results, filename):
    """ä¿å­˜å®éªŒç»“æœåˆ°CSVæ–‡ä»¶ï¼ˆç»Ÿä¸€ä¿å­˜åˆ° runs/ ç›®å½•ï¼‰"""
    if not results:
        return None

    results_dir = "runs"
    os.makedirs(results_dir, exist_ok=True)
    filepath = os.path.join(results_dir, filename)

    # æ”¶é›†æ‰€æœ‰å‡ºç°è¿‡çš„å‚æ•°å­—æ®µ
    param_keys = sorted({k for r in results for k in r.get("params", {}).keys()})

    fieldnames = [
        "experiment_id", "experiment_name", "success",
        "best_accuracy", "final_accuracy"
    ] + param_keys

    with open(filepath, "w", newline="", encoding="utf-8") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for i, r in enumerate(results, 1):
            row = {
                "experiment_id": f"{i:03d}",
                "experiment_name": r.get("exp_name"),
                "success": r.get("success"),
                "best_accuracy": r.get("best_accuracy"),
                "final_accuracy": r.get("final_accuracy"),
            }
            row.update(r.get("params", {}))
            writer.writerow(row)

    return filepath


# ----------------------------- å¤šå¡å­è¿›ç¨‹å¯åŠ¨è¾…åŠ© -----------------------------

def _clean_env_for_child():
    """
    æ¸…ç†çˆ¶è¿›ç¨‹é‡Œå¯èƒ½é—ç•™çš„åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ï¼Œ
    é˜²æ­¢å­è®­ç»ƒè¯¯ä»¥ä¸ºè‡ªå·±åŠ å…¥äº†æŸä¸ªç°å­˜çš„ DDP ç»„ã€‚
    """
    env = os.environ.copy()
    for k in ["LOCAL_RANK", "RANK", "WORLD_SIZE", "MASTER_ADDR", "MASTER_PORT"]:
        env.pop(k, None)
    return env


def _unique_master_port(base=20000, span=10000):
    """ä¸ºæ¯ä¸ªå®éªŒåˆ†é…å”¯ä¸€ç«¯å£ï¼Œé¿å…ç«¯å£å¤ç”¨å¯¼è‡´ NCCL è¿æ¥å¼‚å¸¸"""
    return str(base + random.randint(0, span))


def _infer_num_procs() -> int:
    """æ ¹æ® gpu_ids æˆ–å®é™…è®¾å¤‡æ•°æ¨æ–­è¿›ç¨‹æ•°"""
    # if gpu_ids:
    #     return max(1, len([x for x in gpu_ids.split(",") if x.strip() != ""]))
    env_ids = (os.environ.get("CUDA_VISIBLE_DEVICES") or "").strip()
    if env_ids:
        return max(1, len([x for x in env_ids.split(",") if x.strip() != ""]))
    try:
        import torch
        return max(1, torch.cuda.device_count())
    except Exception:
        return 1


# ----------------------------- æ ¸å¿ƒé€»è¾‘ -----------------------------

def run_single_experiment(params, exp_id, use_multi_gpu=False, config_path="config/grid.yaml",
                        accelerate_args=""):
    """è¿è¡Œå•ä¸ªå®éªŒï¼ˆæ¯ä¸ªå®éªŒç‹¬ç«‹çš„è¿›ç¨‹/è¿›ç¨‹ç»„ï¼‰"""
    exp_name = f"grid_{exp_id}"

    # ç»„è£…åŸºç¡€å‘½ä»¤
    if use_multi_gpu:
        cmd = ["accelerate", "launch", "--multi_gpu", "--num_processes", str(_infer_num_procs())]
        if accelerate_args:
            cmd.extend(accelerate_args.split())
    else:
        cmd = [sys.executable, "-u"]
    
    # æ·»åŠ è®­ç»ƒè„šæœ¬å’ŒåŸºç¡€å‚æ•°
    cmd.extend(["scripts/train.py", "--config", config_path, "--experiment_name", exp_name])
    
    # æ·»åŠ å‚æ•°è¦†ç›–
    for k, v in (params or {}).items():
        cmd.extend([f"--{k}", str(v)])

    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹å®éªŒ {exp_id}: {exp_name}")
    print(f"ğŸ“‹ å‚æ•°: {params}")
    print(f"{'='*60}")

    # æ¸…ç†çˆ¶ç¯å¢ƒ + ä¸ºæœ¬å®éªŒè®¾ç½®å”¯ä¸€ç«¯å£
    env = _clean_env_for_child()
    env["MASTER_ADDR"] = env.get("MASTER_ADDR", "127.0.0.1")
    env["MASTER_PORT"] = _unique_master_port()

    # ç›´æ¥ç»§æ‰¿ TTYï¼Œä¿ç•™ tqdm ä¸€è¡Œåˆ·æ–°
    process = subprocess.Popen(cmd, env=env)
    rc = process.wait()
    success = (rc == 0)

    # ä»æ–‡ä»¶è§£æç»“æœ
    best_accuracy, final_accuracy = parse_result_from_files(exp_name)
    if success:
        if best_accuracy == 0.0 and final_accuracy == 0.0:
            print(f"âš ï¸  {exp_name} ç»“æŸï¼Œä½†æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ã€‚è¯·æ£€æŸ¥ runs/{exp_name}/ã€‚")
        else:
            print(f"âœ… å®éªŒ {exp_name} å®Œæˆï¼Œæœ€ä½³: {best_accuracy:.2f}% | æœ€ç»ˆ: {final_accuracy:.2f}%")
    else:
        print(f"âŒ å®éªŒ {exp_name} å¤±è´¥ï¼ˆè¿”å›ç  {rc}ï¼‰ã€‚è¯·æŸ¥çœ‹æ§åˆ¶å°ä¸ runs/{exp_name}/ã€‚")

    return {
        "success": success,
        "exp_name": exp_name,
        "params": params,
        "best_accuracy": best_accuracy,
        "final_accuracy": final_accuracy,
    }


def run_grid_search(args):
    """è¿è¡Œç½‘æ ¼æœç´¢ï¼ˆä¸²è¡Œï¼Œç¡®ä¿èµ„æºå¹²å‡€é‡Šæ”¾ï¼‰"""
    config = load_grid_config(args.config)
    combinations = generate_combinations(config)

    # æˆªæ–­å®éªŒæ•°é‡
    if len(combinations) > args.max_experiments:
        combinations = combinations[:args.max_experiments]

    print(f"\nğŸš€ å¼€å§‹ç½‘æ ¼æœç´¢ï¼Œå…± {len(combinations)} ä¸ªå®éªŒ")
    print(f"ğŸ“Š ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
    print(f"ğŸ¯ å¤šå¡è®­ç»ƒ: {'æ˜¯' if args.multi_gpu else 'å¦'}")
    print("=" * 60)

    results = []
    successful = 0

    for i, params in enumerate(combinations, 1):
        print(f"\nğŸ“Š å‡†å¤‡å®éªŒ {i}/{len(combinations)}")

        result = run_single_experiment(
            params, f"{i:03d}",
            use_multi_gpu=args.multi_gpu,
            config_path="config/grid.yaml",     # è®­ç»ƒä½¿ç”¨çš„ç»Ÿä¸€é…ç½®
            # gpu_ids=args.gpu_ids,
            accelerate_args=(args.accelerate_args or "")
        )
        results.append(result)
        if result["success"]:
            successful += 1

        # é€‚å½“é—´éš”ï¼Œä¾¿äºè§‚å¯Ÿåˆ†éš”ï¼Œä¹Ÿç»™ç³»ç»Ÿæ—¶é—´é‡Šæ”¾ç«¯å£/å¥æŸ„
        time.sleep(0.5 if not args.multi_gpu else 1.0)

    # æ€»ç»“
    print("\n" + "=" * 60)
    print(f"ğŸ“ˆ ç½‘æ ¼æœç´¢å®Œæˆï¼")
    print(f"âœ… æˆåŠŸå®éªŒ: {successful}/{len(combinations)}")

    if successful > 0:
        successful_results = [r for r in results if r["success"]]
        best_result = max(successful_results, key=lambda x: x["best_accuracy"])

        print(f"\nğŸ† æœ€ä½³å®éªŒç»“æœ:")
        print(f"   å®éªŒåç§°: {best_result['exp_name']}")
        print(f"   æœ€ä½³å‡†ç¡®ç‡: {best_result['best_accuracy']:.2f}%")
        print(f"   æœ€ç»ˆå‡†ç¡®ç‡: {best_result['final_accuracy']:.2f}%")
        print(f"   æœ€ä¼˜å‚æ•°: {best_result['params']}")

        top_results = sorted(successful_results, key=lambda x: x["best_accuracy"], reverse=True)[:3]
        print(f"\nğŸ“Š å‰3åå®éªŒç»“æœ:")
        for i, r in enumerate(top_results, 1):
            print(f"   {i}. {r['exp_name']} - {r['best_accuracy']:.2f}% - {r['params']}")

    if args.save_results:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_filename = f"grid_search_results_{timestamp}.csv"
        saved_filepath = save_results_to_csv(results, results_filename)
        if saved_filepath:
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {saved_filepath}")

    return 0 if successful > 0 else 1


def main():
    """ä¸»å‡½æ•°ï¼šè°ƒåº¦å™¨å§‹ç»ˆå•è¿›ç¨‹ï¼Œä¸è¿›å…¥ Accelerate ç¯å¢ƒ"""
    args, _ = parse_arguments(mode="grid_search")
    return run_grid_search(args)


if __name__ == "__main__":
    sys.exit(main())
