# EasyTrain å¼€å‘è€…æŒ‡å—

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

EasyTrainæ˜¯ä¸€ä¸ªåŸºäºPyTorchçš„æ·±åº¦å­¦ä¹ è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒå›¾åƒåˆ†ç±»å’Œè§†é¢‘åˆ†ç±»ä»»åŠ¡ã€‚é¡¹ç›®é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒå¤šç§æ¨¡å‹ã€æ•°æ®é›†å’Œè®­ç»ƒç­–ç•¥ã€‚

### æ ¸å¿ƒç‰¹æ€§
- **ä»»åŠ¡æ”¯æŒ**: å›¾åƒåˆ†ç±»ã€è§†é¢‘åˆ†ç±»
- **æ¨¡å‹ç»Ÿä¸€**: ç»Ÿä¸€çš„æ¨¡å‹åˆ›å»ºå’Œç®¡ç†æ¥å£
- **é…ç½®é©±åŠ¨**: çµæ´»çš„YAMLé…ç½®ç³»ç»Ÿ
- **åˆ†å¸ƒå¼è®­ç»ƒ**: åŸºäºAccelerateçš„å¤šGPUæ”¯æŒ
- **å®éªŒè¿½è¸ª**: é›†æˆSwanLabå®éªŒç®¡ç†

## ğŸ“š ä»£ç é˜…è¯»é¡ºåº

### ğŸš€ å¿«é€Ÿå…¥é—¨è·¯å¾„ (30åˆ†é’Ÿ)

#### 1. é¡¹ç›®ç»“æ„æ¦‚è§ˆ
```
EasyTrain/
â”œâ”€â”€ scripts/              # å…¥å£è„šæœ¬
â”‚   â”œâ”€â”€ train.py         # å•å®éªŒè®­ç»ƒå…¥å£ â­
â”‚   â””â”€â”€ grid_search.py   # ç½‘æ ¼æœç´¢å…¥å£
â”œâ”€â”€ src/                 # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ trainers/        # è®­ç»ƒå™¨ â­
â”‚   â”œâ”€â”€ models/          # æ¨¡å‹å®šä¹‰ â­
â”‚   â”œâ”€â”€ datasets/        # æ•°æ®é›† â­
â”‚   â”œâ”€â”€ utils/           # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ losses/          # æŸå¤±å‡½æ•°
â”‚   â”œâ”€â”€ optimizers/      # ä¼˜åŒ–å™¨
â”‚   â””â”€â”€ schedules/       # å­¦ä¹ ç‡è°ƒåº¦å™¨
â”œâ”€â”€ config/              # é…ç½®æ–‡ä»¶ â­
â””â”€â”€ data/               # æ•°æ®å­˜å‚¨
```

#### 2. æ ¸å¿ƒæ–‡ä»¶é˜…è¯»é¡ºåº (â­ å¿…è¯»)
1. **config/grid.yaml** - äº†è§£é…ç½®ç»“æ„
2. **scripts/train.py** - ç†è§£è®­ç»ƒå…¥å£
3. **src/trainers/base_trainer.py** - æ ¸å¿ƒè®­ç»ƒé€»è¾‘
4. **src/models/model_registry.py** - æ¨¡å‹ç®¡ç†ç³»ç»Ÿ
5. **src/datasets/dataloader_factory.py** - æ•°æ®åŠ è½½

### ğŸ” æ·±å…¥ç†è§£è·¯å¾„ (2-3å°æ—¶)

#### é˜¶æ®µ1: é…ç½®ç³»ç»Ÿ (30åˆ†é’Ÿ)
```
config/grid.yaml                    # å›¾åƒåˆ†ç±»é…ç½®ç¤ºä¾‹
config/ucf101_video.yaml           # è§†é¢‘åˆ†ç±»é…ç½®ç¤ºä¾‹
src/utils/config_parser.py         # é…ç½®è§£æé€»è¾‘
src/utils/config_parser_simplified.py  # ç®€åŒ–ç‰ˆè§£æå™¨
```

#### é˜¶æ®µ2: ä»»åŠ¡åˆ‡æ¢æœºåˆ¶ (45åˆ†é’Ÿ)
```
src/trainers/base_trainer.py:249-272   # ä»»åŠ¡é…ç½®è§£æ
src/trainers/base_trainer.py:32-65     # SUPPORTED_TASKSå®šä¹‰
src/trainers/base_trainer.py:67-89     # å‘åå…¼å®¹æ¨æ–­
```

### ğŸ¬ ä»»åŠ¡é…ç½®ä¸å…¥å£
- **å•å®éªŒï¼ˆUCF101ï¼‰**ï¼š`python scripts/train.py --config config/ucf101_video.yaml`
- **ç½‘æ ¼æœç´¢ï¼ˆUCF101ï¼‰**ï¼š`python scripts/grid_search.py --config config/ucf101_video_grid.yaml`
- **å•å®éªŒï¼ˆNeonatalï¼Œå¤šæ ‡ç­¾ï¼‰**ï¼š`python scripts/train.py --config config/neonatal_multilabel.yaml`
- **ç½‘æ ¼æœç´¢ï¼ˆNeonatalï¼Œå¤šæ ‡ç­¾ï¼‰**ï¼š`python scripts/grid_search.py --config config/neonatal_multilabel_grid.yaml`
- **é…ç½®ç¤ºä¾‹**ï¼š`config/examples` æä¾›æœ€å°åŒ–æ¨¡æ¿ï¼Œå¯å¤åˆ¶åæŒ‰éœ€ä¿®æ”¹ `task.tag`ã€`data.type`ã€`model.type` ç­‰å­—æ®µã€‚
- âœ… **å”¯ä¸€å…¥å£**ï¼šæ‰€æœ‰è®­ç»ƒæµç¨‹éƒ½é€šè¿‡ `scripts/train.py` / `scripts/grid_search.py` åŠ  YAML é…ç½®é©±åŠ¨ï¼Œæ—§ç‰ˆ `tmp/train_multilabel.py` å·²ç§»é™¤ï¼Œé¿å…å†—ä½™å‚æ•°å’Œé‡å¤å®ç°ã€‚

#### é˜¶æ®µ3: æ¨¡å‹ç³»ç»Ÿ (60åˆ†é’Ÿ)
```
src/models/model_registry.py:11-97     # æ¨¡å‹æ³¨å†Œè¡¨
src/models/model_registry.py:100-178   # ç»Ÿä¸€åˆ›å»ºæ¥å£
src/models/image_net.py:75-92          # å›¾åƒæ¨¡å‹å·¥å‚
src/models/video_net.py:90-120         # è§†é¢‘æ¨¡å‹å·¥å‚
```

#### é˜¶æ®µ4: æ•°æ®ç³»ç»Ÿ (45åˆ†é’Ÿ)
```
src/datasets/dataloader_factory.py:15-110  # æ•°æ®åŠ è½½å™¨å·¥å‚
src/datasets/video_dataset.py:12-68        # è§†é¢‘æ•°æ®é›†åŸºç±»
src/datasets/cifar10_dataset.py            # å›¾åƒæ•°æ®é›†ç¤ºä¾‹
```

## ğŸ—ï¸ æ¶æ„è®¾è®¡ç†å¿µ

### 1. ä»»åŠ¡é©±åŠ¨æ¶æ„
```python
# æ ¸å¿ƒè®¾è®¡ï¼šåŸºäºtask_tagçš„ä»»åŠ¡è¯†åˆ«
task_tag = config.get('task', {}).get('tag')  # 'image_classification' æˆ– 'video_classification'

# ä»»åŠ¡ä¿¡æ¯æŸ¥æ‰¾
task_info = SUPPORTED_TASKS[task_tag]

# åŸºäºä»»åŠ¡é€‰æ‹©å¯¹åº”ç»„ä»¶
model_factory = globals()[task_info['model_factory']]  # get_model æˆ– get_video_model
```

### 2. ç»Ÿä¸€æ¥å£è®¾è®¡
```python
# æ¨¡å‹åˆ›å»ºç»Ÿä¸€æ¥å£
model = create_model_unified(model_name, num_classes, **kwargs)

# æ•°æ®åŠ è½½ç»Ÿä¸€æ¥å£  
train_loader, test_loader, dataset_info = create_dataloaders(dataset_name, **params)
```

### 3. é…ç½®é©±åŠ¨æ¨¡å¼
```yaml
# é…ç½®æ–‡ä»¶é©±åŠ¨æ‰€æœ‰è®­ç»ƒè¡Œä¸º
task:
  tag: "image_classification"  # ä»»åŠ¡ç±»å‹
  
model:
  type: "resnet18"            # æ¨¡å‹é€‰æ‹©
  
data:
  type: "cifar10"             # æ•°æ®é›†é€‰æ‹©
```

## ğŸ”„ æ•°æ®æµåˆ†æ

### è®­ç»ƒæµç¨‹æ•°æ®æµ
```
1. é…ç½®è§£æ
   config.yaml â†’ parse_arguments() â†’ config dict

2. ä»»åŠ¡è¯†åˆ«  
   config['task']['tag'] â†’ SUPPORTED_TASKS â†’ task_info

3. ç»„ä»¶åˆ›å»º
   task_info â†’ model_factory â†’ model
   data_config â†’ create_dataloaders â†’ dataloaders
   
4. è®­ç»ƒæ‰§è¡Œ
   model + dataloaders â†’ train_epoch() â†’ metrics
   
5. ç»“æœè®°å½•
   metrics â†’ SwanLab â†’ å®éªŒè¿½è¸ª
```

### æ¨¡å—ä¾èµ–å…³ç³»
```
scripts/train.py
â”œâ”€â”€ src.utils.config_parser (é…ç½®è§£æ)
â”œâ”€â”€ src.trainers.base_trainer (è®­ç»ƒé€»è¾‘)
â”‚   â”œâ”€â”€ src.models.* (æ¨¡å‹åˆ›å»º)
â”‚   â”œâ”€â”€ src.datasets.* (æ•°æ®åŠ è½½)
â”‚   â”œâ”€â”€ src.losses.* (æŸå¤±å‡½æ•°)
â”‚   â”œâ”€â”€ src.optimizers.* (ä¼˜åŒ–å™¨)
â”‚   â””â”€â”€ src.schedules.* (è°ƒåº¦å™¨)
â””â”€â”€ accelerate (åˆ†å¸ƒå¼è®­ç»ƒ)
```

## ğŸ› ï¸ ä¿®æ”¹ä»£ç æœ€ä½³å®è·µ

### 1. æ·»åŠ æ–°æ¨¡å‹

#### A. å›¾åƒåˆ†ç±»æ¨¡å‹
```python
# 1. åœ¨ src/models/model_registry.py ä¸­æ³¨å†Œ
MODEL_REGISTRY['new_model'] = {
    'library': 'timm',  # æˆ– 'torchvision'
    'adapt_cifar': True,  # æ˜¯å¦éœ€è¦CIFARé€‚é…
    'task_type': 'image_classification'
}

# 2. å¦‚æœä½¿ç”¨torchvisionï¼Œéœ€è¦æ·»åŠ åˆ›å»ºé€»è¾‘
elif library == 'torchvision':
    if model_name == 'new_model':
        model = models.new_model(pretrained=pretrained)
        # ä¿®æ”¹åˆ†ç±»å¤´...
```

#### B. è§†é¢‘åˆ†ç±»æ¨¡å‹
```python
# åœ¨ MODEL_REGISTRY ä¸­æ·»åŠ 
'new_video_model': {
    'library': 'torchvision.video',
    'task_type': 'video_classification',
    'model_func': 'new_video_model'  # torchvision.models.videoä¸­çš„å‡½æ•°å
}
```

### 2. æ·»åŠ æ–°æ•°æ®é›†

#### A. åˆ›å»ºæ•°æ®é›†ç±»
```python
# src/datasets/new_dataset.py
class NewDataset(Dataset):
    def __init__(self, root, train=True, transform=None):
        # å®ç°åˆå§‹åŒ–é€»è¾‘
        
    def __len__(self):
        # è¿”å›æ•°æ®é›†å¤§å°
        
    def __getitem__(self, idx):
        # è¿”å› (data, label)
```

#### B. æ³¨å†Œåˆ°å·¥å‚å‡½æ•°
```python
# src/datasets/dataloader_factory.py
def create_dataloaders(dataset_name, data_dir, batch_size, **kwargs):
    if dataset_name == "new_dataset":
        train_dataset = NewDataset(root=data_dir, train=True)
        test_dataset = NewDataset(root=data_dir, train=False)
        num_classes = 10  # è®¾ç½®ç±»åˆ«æ•°
        # ...
```

#### C. æ›´æ–°ä»»åŠ¡æ”¯æŒ
```python
# src/trainers/base_trainer.py
SUPPORTED_TASKS = {
    'image_classification': {
        'supported_datasets': ['cifar10', 'custom', 'new_dataset'],  # æ·»åŠ æ–°æ•°æ®é›†
        # ...
    }
}
```

### 3. æ·»åŠ æ–°ä»»åŠ¡ç±»å‹

#### A. å®šä¹‰ä»»åŠ¡é…ç½®
```python
# src/trainers/base_trainer.py
SUPPORTED_TASKS['new_task'] = {
    'description': 'æ–°ä»»åŠ¡ç±»å‹',
    'supported_datasets': ['dataset1', 'dataset2'],
    'model_factory': 'get_new_task_model',
    'default_model': 'default_model_name'
}
```

#### B. åˆ›å»ºæ¨¡å‹å·¥å‚
```python
# src/models/new_task_models.py
def get_new_task_model(model_name, **kwargs):
    """æ–°ä»»åŠ¡çš„æ¨¡å‹å·¥å‚å‡½æ•°"""
    # å®ç°æ¨¡å‹åˆ›å»ºé€»è¾‘
```

#### C. æ›´æ–°é…ç½®æ–‡ä»¶
```yaml
# config/new_task.yaml
task:
  tag: "new_task"
  description: "æ–°ä»»åŠ¡ç±»å‹"
```

### 4. ä¿®æ”¹è®­ç»ƒé€»è¾‘

#### A. è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯
```python
# ç»§æ‰¿base_traineræˆ–åˆ›å»ºæ–°çš„è®­ç»ƒå™¨
class CustomTrainer(BaseTrainer):
    def train_epoch(self, dataloader, model, loss_fn, optimizer, lr_scheduler, accelerator, epoch):
        # è‡ªå®šä¹‰è®­ç»ƒé€»è¾‘
        pass
```

#### B. æ·»åŠ æ–°çš„æŸå¤±å‡½æ•°
```python
# src/losses/custom_loss.py
class CustomLoss(nn.Module):
    def __init__(self, **kwargs):
        super().__init__()
        
    def forward(self, predictions, targets):
        # å®ç°æŸå¤±è®¡ç®—
        pass

# src/losses/loss_factory.py
def get_loss_function(loss_name, **kwargs):
    if loss_name == "custom_loss":
        return CustomLoss(**kwargs)
```

## âš ï¸ å¸¸è§é™·é˜±å’Œæ³¨æ„äº‹é¡¹

### 1. é…ç½®æ–‡ä»¶é™·é˜±
```yaml
# âŒ é”™è¯¯ï¼šä»»åŠ¡ç±»å‹ä¸æ•°æ®é›†ä¸åŒ¹é…
task:
  tag: "image_classification"
data:
  type: "ucf101_video"  # è§†é¢‘æ•°æ®é›†ç”¨äºå›¾åƒä»»åŠ¡

# âœ… æ­£ç¡®ï¼šä»»åŠ¡ç±»å‹ä¸æ•°æ®é›†åŒ¹é…
task:
  tag: "video_classification"
data:
  type: "ucf101_video"
```

### 2. æ¨¡å‹æ³¨å†Œé™·é˜±
```python
# âŒ é”™è¯¯ï¼šå¿˜è®°è®¾ç½®task_type
'new_model': {
    'library': 'timm',
    # ç¼ºå°‘ 'task_type': 'image_classification'
}

# âœ… æ­£ç¡®ï¼šå®Œæ•´çš„æ¨¡å‹é…ç½®
'new_model': {
    'library': 'timm',
    'task_type': 'image_classification',
    'adapt_cifar': True
}
```

### 3. æ•°æ®é›†æ¥å£é™·é˜±
```python
# âŒ é”™è¯¯ï¼šè¿”å›æ ¼å¼ä¸ä¸€è‡´
def __getitem__(self, idx):
    return data  # ç¼ºå°‘label

# âœ… æ­£ç¡®ï¼šç»Ÿä¸€è¿”å›æ ¼å¼
def __getitem__(self, idx):
    return data, label  # (input, target)
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### 1. åŠŸèƒ½æµ‹è¯•
```bash
# æµ‹è¯•å›¾åƒåˆ†ç±»
python scripts/train.py --config config/grid.yaml --epochs 1

# æµ‹è¯•è§†é¢‘åˆ†ç±»  
python scripts/train.py --config config/ucf101_video.yaml --epochs 1

# æµ‹è¯•ç½‘æ ¼æœç´¢
python scripts/grid_search.py --config config/grid.yaml --max_experiments 2
```

### 2. é…ç½®éªŒè¯
```python
# éªŒè¯æ–°é…ç½®æ–‡ä»¶
python -c "
from src.utils.config_parser import parse_arguments
args, config = parse_arguments('single_experiment')
print('é…ç½®éªŒè¯æˆåŠŸ')
"
```

### 3. æ¨¡å‹éªŒè¯
```python
# éªŒè¯æ–°æ¨¡å‹
python -c "
from src.models.model_registry import create_model_unified
model = create_model_unified('new_model', num_classes=10)
print('æ¨¡å‹åˆ›å»ºæˆåŠŸ')
"
```

## ğŸš€ å¿«é€Ÿå¼€å‘æ¨¡æ¿

### 1. æ–°æ¨¡å‹å¼€å‘æ¨¡æ¿
```python
# æ­¥éª¤1: æ³¨å†Œæ¨¡å‹ (src/models/model_registry.py)
MODEL_REGISTRY['my_new_model'] = {
    'library': 'timm',
    'adapt_cifar': True,
    'task_type': 'image_classification'
}

# æ­¥éª¤2: æµ‹è¯•æ¨¡å‹åˆ›å»º
python -c "
from src.models.model_registry import create_model_unified
model = create_model_unified('my_new_model', num_classes=10)
print(f'æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())}')
"

# æ­¥éª¤3: åˆ›å»ºé…ç½®æ–‡ä»¶
# config/my_experiment.yaml
task:
  tag: "image_classification"
model:
  type: "my_new_model"
# ... å…¶ä»–é…ç½®

# æ­¥éª¤4: è¿è¡Œæµ‹è¯•
python scripts/train.py --config config/my_experiment.yaml --epochs 1
```

### 2. æ–°æ•°æ®é›†å¼€å‘æ¨¡æ¿
```python
# æ­¥éª¤1: åˆ›å»ºæ•°æ®é›†ç±» (src/datasets/my_dataset.py)
from torch.utils.data import Dataset

class MyDataset(Dataset):
    def __init__(self, root, train=True, transform=None):
        self.root = root
        self.train = train
        self.transform = transform
        # åŠ è½½æ•°æ®ç´¢å¼•

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, idx):
        # åŠ è½½æ•°æ®å’Œæ ‡ç­¾
        data, label = self.load_item(idx)
        if self.transform:
            data = self.transform(data)
        return data, label

# æ­¥éª¤2: æ³¨å†Œåˆ°å·¥å‚ (src/datasets/dataloader_factory.py)
elif dataset_name == "my_dataset":
    train_dataset = MyDataset(root=data_dir, train=True)
    test_dataset = MyDataset(root=data_dir, train=False)
    num_classes = 10  # è®¾ç½®æ­£ç¡®çš„ç±»åˆ«æ•°

# æ­¥éª¤3: æ›´æ–°ä»»åŠ¡æ”¯æŒ (src/trainers/base_trainer.py)
SUPPORTED_TASKS['image_classification']['supported_datasets'].append('my_dataset')
```

### 3. å®éªŒé…ç½®æ¨¡æ¿
```yaml
# åŸºç¡€å®éªŒé…ç½®æ¨¡æ¿
task:
  tag: "image_classification"  # æˆ– "video_classification"
  description: "å®éªŒæè¿°"

training:
  exp_name: "my_experiment"
  save_model: true
  model_save_path: "models/my_model.pth"

swanlab:
  project_name: "MyProject"
  description: "å®éªŒè¯´æ˜"

data:
  type: "cifar10"  # æ•°æ®é›†ç±»å‹
  root: "./data"
  num_workers: 8

model:
  type: "resnet18"  # æ¨¡å‹ç±»å‹
  params:
    pretrained: true

hp:
  batch_size: 128
  learning_rate: 0.001
  epochs: 10
  dropout: 0.1

optimizer:
  name: "adam"
  params:
    weight_decay: 0.0001

scheduler:
  name: "cosine"
  params:
    T_max: 10

loss:
  name: "crossentropy"
```

## ğŸ”§ è°ƒè¯•å’Œæ•…éšœæ’é™¤

### 1. å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

#### é”™è¯¯: "ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹"
```python
# åŸå› ï¼štask_tagä¸åœ¨SUPPORTED_TASKSä¸­
# è§£å†³ï¼šæ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„task.tagå­—æ®µ
task:
  tag: "image_classification"  # ç¡®ä¿æ‹¼å†™æ­£ç¡®
```

#### é”™è¯¯: "ä»»åŠ¡ä¸æ”¯æŒæ•°æ®é›†"
```python
# åŸå› ï¼šæ•°æ®é›†ç±»å‹ä¸ä»»åŠ¡ç±»å‹ä¸åŒ¹é…
# è§£å†³ï¼šç¡®ä¿æ•°æ®é›†åœ¨ä»»åŠ¡çš„supported_datasetsä¸­
# æˆ–è€…æ·»åŠ æ•°æ®é›†æ”¯æŒ
SUPPORTED_TASKS['image_classification']['supported_datasets'].append('new_dataset')
```

#### é”™è¯¯: "ä¸æ”¯æŒçš„æ¨¡å‹"
```python
# åŸå› ï¼šæ¨¡å‹æœªåœ¨MODEL_REGISTRYä¸­æ³¨å†Œ
# è§£å†³ï¼šæ·»åŠ æ¨¡å‹æ³¨å†Œæˆ–æ£€æŸ¥æ¨¡å‹åç§°æ‹¼å†™
```

### 2. æ€§èƒ½è°ƒä¼˜å»ºè®®

#### A. æ•°æ®åŠ è½½ä¼˜åŒ–
```python
# å¢åŠ æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹
data:
  num_workers: 12  # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´

# ä½¿ç”¨æ•°æ®é¢„å–
dataloader = DataLoader(dataset, num_workers=12, pin_memory=True)
```

#### B. è®­ç»ƒé€Ÿåº¦ä¼˜åŒ–
```python
# ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
accelerator = Accelerator(mixed_precision='fp16')

# è°ƒæ•´æ‰¹å¤§å°
hp:
  batch_size: 256  # æ ¹æ®GPUå†…å­˜è°ƒæ•´
```

## ğŸ“– è¿›é˜¶å­¦ä¹ èµ„æº

### 1. é¡¹ç›®å®Œæ•´æ–‡æ¡£
- `PROJECT_DOCUMENTATION.md` - å®Œæ•´çš„é¡¹ç›®æ–‡æ¡£ï¼ŒåŒ…å«æ‰€æœ‰åŠŸèƒ½ç‰¹æ€§

### 2. æœ€ä½³å®è·µç¤ºä¾‹
- `config/` - é…ç½®æ–‡ä»¶ç¤ºä¾‹
- `src/models/model_registry.py` - ç»Ÿä¸€æ¥å£è®¾è®¡ç¤ºä¾‹
- `src/datasets/video_dataset.py` - æŠ½è±¡åŸºç±»è®¾è®¡ç¤ºä¾‹

## ğŸ¤ è´¡çŒ®æŒ‡å—

### 1. ä»£ç æäº¤è§„èŒƒ
- éµå¾ªç°æœ‰çš„ä»£ç é£æ ¼å’Œæ³¨é‡Šè§„èŒƒ
- ä¸ºæ–°åŠŸèƒ½æ·»åŠ ç›¸åº”çš„æµ‹è¯•
- æ›´æ–°ç›¸å…³æ–‡æ¡£å’Œé…ç½®ç¤ºä¾‹

### 2. æµ‹è¯•è¦æ±‚
- æ‰€æœ‰æ–°åŠŸèƒ½å¿…é¡»é€šè¿‡åŸºç¡€åŠŸèƒ½æµ‹è¯•
- ç¡®ä¿å‘åå…¼å®¹æ€§
- æä¾›ä½¿ç”¨ç¤ºä¾‹å’Œæ–‡æ¡£

### 3. æ–‡æ¡£æ›´æ–°
- æ›´æ–°DEVELOPER_GUIDE.mdä¸­çš„ç›¸å…³éƒ¨åˆ†
- æ·»åŠ é…ç½®æ–‡ä»¶ç¤ºä¾‹
- æ›´æ–°æ¶æ„å›¾å’Œä¾èµ–å…³ç³»

---

**æ›´æ–°æ—¶é—´**: 2025-01-10
**é€‚ç”¨ç‰ˆæœ¬**: é‡æ„åç‰ˆæœ¬
**ç»´æŠ¤è€…**: EasyTrainå¼€å‘å›¢é˜Ÿ
