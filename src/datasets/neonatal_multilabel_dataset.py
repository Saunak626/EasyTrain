"""æ–°ç”Ÿå„¿å¤šæ ‡ç­¾è¡Œä¸ºè¯†åˆ«æ•°æ®é›†

è¯¥æ¨¡å—å®ç°äº†åŸºäºCPUå¤„ç†å¸§å›¾åƒå’ŒExcelæ ‡ç­¾æ–‡ä»¶çš„æ–°ç”Ÿå„¿å¤šæ ‡ç­¾è¡Œä¸ºè¯†åˆ«æ•°æ®é›†ã€‚
å‚è€ƒUCF101è§†é¢‘æ•°æ®é›†çš„å®ç°ï¼Œæ”¯æŒä»é¢„å¤„ç†å¸§å›¾åƒåŠ è½½æ•°æ®ã€‚

Classes:
    NeonatalMultilabelDataset: æ–°ç”Ÿå„¿å¤šæ ‡ç­¾è¡Œä¸ºè¯†åˆ«æ•°æ®é›†å®ç°
"""

import os
import cv2
import torch
import logging
import numpy as np
import pandas as pd


from collections import Counter
from torch.utils.data import Dataset
from sklearn.model_selection import train_test_split
from .label_cache import LabelCache, OptimizedLabelProcessor

logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥iterative-stratificationåº“ï¼ˆç”¨äºçœŸæ­£çš„å¤šæ ‡ç­¾åˆ†å±‚æŠ½æ ·ï¼‰
try:
    from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit
    ITERSTRAT_AVAILABLE = True
except ImportError:
    ITERSTRAT_AVAILABLE = False
    logger.warning(
        "æœªå®‰è£…iterative-stratificationåº“ï¼Œå°†ä½¿ç”¨ç®€åŒ–çš„åˆ†å±‚æŠ½æ ·ç­–ç•¥ã€‚\n"
        "å»ºè®®å®‰è£…ä»¥è·å¾—æ›´å¥½çš„å¤šæ ‡ç­¾åˆ†å±‚æ•ˆæœ: pip install iterative-stratification"
    )


class NeonatalMultilabelDataset(Dataset):
    """æ–°ç”Ÿå„¿å¤šæ ‡ç­¾è¡Œä¸ºè¯†åˆ«æ•°æ®é›†
    
    ä»é¢„å¤„ç†çš„å¸§å›¾åƒå’ŒExcelæ ‡ç­¾æ–‡ä»¶ä¸­åŠ è½½æ–°ç”Ÿå„¿è¡Œä¸ºæ•°æ®ï¼Œæ”¯æŒå¤šæ ‡ç­¾åˆ†ç±»ã€‚
    
    æ•°æ®ç»“æ„:
    - å¸§å›¾åƒ: frames_segments/session_name/clip_id/00000.jpg
    - æ ‡ç­¾: multi_hot_labels.xlsx (24ç»´å¤šæ ‡ç­¾å‘é‡)
    
    Args:
        frames_dir (str): å¸§å›¾åƒæ ¹ç›®å½•è·¯å¾„
        labels_file (str): Excelæ ‡ç­¾æ–‡ä»¶è·¯å¾„
        split (str): æ•°æ®é›†åˆ†å‰² ('train', 'test')
        clip_len (int): æ¯ä¸ªè§†é¢‘ç‰‡æ®µçš„å¸§æ•°
        model_type (str): æ¨¡å‹ç±»å‹ï¼Œç”¨äºè·å–å¯¹åº”çš„transforms
    """
    
    def __init__(self, frames_dir, labels_file, split='train', clip_len=16, model_type=None,
                 top_n_classes=None, stratified_split=True, min_samples_per_class=10,
                 sampling_mode='random', target_fps=None, original_fps=16):
        """åˆå§‹åŒ–æ–°ç”Ÿå„¿å¤šæ ‡ç­¾æ•°æ®é›†

        Args:
            frames_dir (str): å¸§å›¾åƒæ ¹ç›®å½•è·¯å¾„
            labels_file (str): Excelæ ‡ç­¾æ–‡ä»¶è·¯å¾„
            split (str): æ•°æ®é›†åˆ†å‰²ï¼Œ'train'æˆ–'test'
            clip_len (int): æ¯ä¸ªè§†é¢‘ç‰‡æ®µçš„å¸§æ•°ï¼Œé»˜è®¤16
            model_type (str): æ¨¡å‹ç±»å‹ï¼Œç”¨äºè·å–å¯¹åº”çš„transforms
            top_n_classes (int, optional): åªä½¿ç”¨æ ·æœ¬æ•°é‡å‰Nå¤šçš„ç±»åˆ«ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨å…¨éƒ¨ç±»åˆ«
            stratified_split (bool): æ˜¯å¦ä½¿ç”¨åˆ†å±‚æŠ½æ ·è¿›è¡Œæ•°æ®åˆ’åˆ†ï¼Œé»˜è®¤True
            min_samples_per_class (int): ç±»åˆ«æœ€å°æ ·æœ¬æ•°é˜ˆå€¼ï¼Œé»˜è®¤10
            sampling_mode (str): é‡‡æ ·æ¨¡å¼ï¼Œ'random'æˆ–'fps'ï¼Œé»˜è®¤'random'
            target_fps (float, optional): ç›®æ ‡é‡‡æ ·å¸§ç‡ï¼Œä»…åœ¨sampling_mode='fps'æ—¶ä½¿ç”¨
            original_fps (float): åŸå§‹è§†é¢‘å¸§ç‡ï¼Œé»˜è®¤16fps
        """
        self.frames_dir = frames_dir
        self.labels_file = labels_file
        self.split = split
        self.clip_len = clip_len
        self.model_type = model_type
        self.top_n_classes = top_n_classes
        self.stratified_split = stratified_split
        self.min_samples_per_class = min_samples_per_class

        # FPSé‡‡æ ·ç›¸å…³å‚æ•°
        self.sampling_mode = sampling_mode
        self.target_fps = target_fps
        self.original_fps = original_fps

        # å‚æ•°éªŒè¯
        self._validate_sampling_params()

        # è·å–æ¨¡å‹ç‰¹å®šçš„transforms
        self.model_transforms = self._get_model_transforms()

        # ä¼˜åŒ–çš„é¢„å¤„ç†å‚æ•°
        self.resize_height = 224
        self.resize_width = 224
        self.crop_size = 112

        # å®šä¹‰24ä¸ªåŸå§‹è¡Œä¸ºæ ‡ç­¾
        self.original_behavior_labels = [
            'å–‚å…»å¼€å§‹', 'å–‚å…»ç»“æŸ', 'æ˜“å“­é—¹', 'å¼ å˜´é—­å˜´', 'å¸å®è¡Œä¸º', 'åƒæ‰‹æŒ‡',
            'åƒè„šæŒ‡', 'çš±çœ‰', 'å“­æ³£', 'å‘è„¾æ°”', 'æ¥å›æ‘‡å¤´', 'æ‰‹è„šæ´»åŠ¨åŠ å¿«',
            'å¯»æ‰¾å¥¶ç“¶', 'æ³¨è§†å¥¶ç“¶', 'å£°è°ƒå˜é«˜', 'æ‰“å“ˆæ¬ ', 'ç¡ç€äº†', 'é—´æ­‡å–å¥¶',
            'å”‡éƒ¨è§¦é£Ÿååº”', 'å–‚å…»æœŸé¬¼è„¸', 'å£è…”å™¨å…·å’¬åˆ', 'å¤´é¢ˆä¾§å‘å›é¿',
            'è‚¢ä½“å¼ åŠ›å‡é€€', 'è¿œç¦»å¥¶ç“¶'
        ]

        # ä½¿ç”¨ä¼˜åŒ–çš„æ ‡ç­¾å¤„ç†å™¨ï¼ˆä½¿ç”¨åŸå§‹æ ‡ç­¾ï¼‰
        self.label_processor = OptimizedLabelProcessor(self.labels_file, self.original_behavior_labels)

        # åŠ è½½å’Œå¤„ç†æ•°æ®ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        all_samples = self._load_samples_optimized()

        # åˆ†æç±»åˆ«åˆ†å¸ƒå¹¶ç­›é€‰ç±»åˆ«
        self.selected_classes, self.class_mapping = self._select_top_classes(all_samples)
        self.behavior_labels = self.selected_classes
        self.num_classes = len(self.behavior_labels)
        self.class_names = self.behavior_labels

        # æ›´æ–°æ ·æœ¬æ ‡ç­¾ï¼ˆåªä¿ç•™é€‰å®šçš„ç±»åˆ«ï¼‰
        all_samples = self._update_sample_labels(all_samples)

        # æ•°æ®åˆ†å‰²ï¼ˆä½¿ç”¨åˆ†å±‚æŠ½æ ·æˆ–ç®€å•åˆ†å‰²ï¼‰
        self.samples = self._split_data(all_samples, split)

        logger.info(f"åŠ è½½ {split} æ•°æ®é›†: {len(self.samples)} ä¸ªæ ·æœ¬ï¼Œä½¿ç”¨ {self.num_classes} ä¸ªç±»åˆ«")
        if self.sampling_mode == 'fps':
            logger.info(f"ä½¿ç”¨FPSé‡‡æ ·æ¨¡å¼: target_fps={self.target_fps}, original_fps={self.original_fps}")
        if self.top_n_classes is not None:
            logger.info(f"é€‰å®šçš„ç±»åˆ«: {self.behavior_labels}")

    def _validate_sampling_params(self):
        """éªŒè¯é‡‡æ ·å‚æ•°çš„æœ‰æ•ˆæ€§"""
        if self.sampling_mode not in ['random', 'fps']:
            raise ValueError(f"ä¸æ”¯æŒçš„é‡‡æ ·æ¨¡å¼: {self.sampling_mode}ã€‚æ”¯æŒçš„æ¨¡å¼: 'random', 'fps'")

        if self.sampling_mode == 'fps':
            if self.target_fps is None:
                raise ValueError("ä½¿ç”¨FPSé‡‡æ ·æ¨¡å¼æ—¶ï¼Œå¿…é¡»æŒ‡å®štarget_fpså‚æ•°")
            if self.target_fps <= 0:
                raise ValueError(f"target_fpså¿…é¡»å¤§äº0ï¼Œå½“å‰å€¼: {self.target_fps}")
            if self.original_fps <= 0:
                raise ValueError(f"original_fpså¿…é¡»å¤§äº0ï¼Œå½“å‰å€¼: {self.original_fps}")

    def fps_sampling_neonatal(self, buffer, clip_len, target_fps, original_fps=16, min_fps=4):
        """é’ˆå¯¹æ–°ç”Ÿå„¿æ•°æ®é›†ä¼˜åŒ–çš„FPSé‡‡æ ·æ–¹æ³•

        ä¸“é—¨é’ˆå¯¹5ç§’å·¦å³çš„çŸ­è§†é¢‘è¿›è¡Œä¼˜åŒ–ï¼Œç¡®ä¿é‡‡æ ·è´¨é‡ä¸ä½äº4fpsã€‚

        Args:
            buffer (np.ndarray): è¾“å…¥è§†é¢‘å¸§ç¼“å†²åŒºï¼Œå½¢çŠ¶ä¸º(T, H, W, C)
            clip_len (int): ç›®æ ‡è¾“å‡ºå¸§æ•°
            target_fps (float): ç›®æ ‡é‡‡æ ·å¸§ç‡
            original_fps (float): åŸå§‹è§†é¢‘å¸§ç‡ï¼Œé»˜è®¤16fps
            min_fps (float): æœ€ä½é‡‡æ ·å¸§ç‡é™åˆ¶ï¼Œé»˜è®¤4fps

        Returns:
            np.ndarray: é‡‡æ ·åçš„å¸§ç¼“å†²åŒºï¼Œå½¢çŠ¶ä¸º(clip_len, H, W, C)
        """
        total_frames = buffer.shape[0]

        # åº”ç”¨æœ€ä½FPSé™åˆ¶ï¼ˆé’ˆå¯¹æ–°ç”Ÿå„¿æ•°æ®é›†çš„ç‰¹æ®Šè¦æ±‚ï¼‰
        effective_fps = max(target_fps, min_fps)

        # è®¡ç®—é‡‡æ ·é—´éš”
        interval = original_fps / effective_fps

        # ç”Ÿæˆé‡‡æ ·ç´¢å¼•
        indices = []
        current_idx = 0.0

        while len(indices) < clip_len and int(current_idx) < total_frames:
            indices.append(int(current_idx))
            current_idx += interval

        # é’ˆå¯¹çŸ­è§†é¢‘çš„å¸§æ•°ä¸è¶³å¤„ç†ç­–ç•¥
        if len(indices) < clip_len:
            # ç­–ç•¥1: ä»è§†é¢‘å¼€å§‹ä½ç½®è¿›è¡Œæ›´å¯†é›†çš„é‡‡æ ·
            remaining_frames = clip_len - len(indices)

            # è®¡ç®—æ›´å¯†é›†çš„é—´éš”ï¼Œç¡®ä¿èƒ½å¤Ÿé‡‡æ ·åˆ°è¶³å¤Ÿçš„å¸§
            if total_frames >= clip_len:
                # å¦‚æœæ€»å¸§æ•°è¶³å¤Ÿï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒé‡‡æ ·
                dense_interval = (total_frames - 1) / (clip_len - 1)
                indices = [int(i * dense_interval) for i in range(clip_len)]
            else:
                # å¦‚æœæ€»å¸§æ•°ä¸è¶³ï¼Œå…ˆå‡åŒ€é‡‡æ ·æ‰€æœ‰å¸§ï¼Œç„¶åé‡å¤å…³é”®å¸§
                indices = list(range(total_frames))

                # é‡å¤å…³é”®å¸§å¡«å……åˆ°clip_len
                while len(indices) < clip_len:
                    # ä¼˜å…ˆé‡å¤ä¸­é—´å¸§å’Œæœ€åå¸§
                    if total_frames > 1:
                        mid_frame = total_frames // 2
                        last_frame = total_frames - 1
                        indices.extend([mid_frame, last_frame])
                    else:
                        # åªæœ‰ä¸€å¸§çš„æƒ…å†µï¼Œé‡å¤è¯¥å¸§
                        indices.append(0)

                # æˆªæ–­åˆ°æ‰€éœ€é•¿åº¦
                indices = indices[:clip_len]

        # å¦‚æœé‡‡æ ·å¸§æ•°è¶…è¿‡clip_lenï¼Œæˆªæ–­
        indices = indices[:clip_len]

        # ç¡®ä¿ç´¢å¼•ä¸è¶…å‡ºèŒƒå›´
        indices = [min(idx, total_frames - 1) for idx in indices]

        # é‡‡æ ·å¸§
        sampled_buffer = buffer[indices]

        return sampled_buffer

    def _get_model_transforms(self):
        """è·å–æ¨¡å‹ç‰¹å®šçš„transformsï¼ˆå‚è€ƒUCF101å®ç°ï¼‰"""
        if self.model_type:
            try:
                from ..models.model_registry import get_video_model_transforms, validate_model_transforms_compatibility

                # è·å–transforms
                transforms = get_video_model_transforms(self.model_type)
                if transforms is None:
                    return None

                # éªŒè¯å…¼å®¹æ€§
                is_compatible, message = validate_model_transforms_compatibility(self.model_type)
                if not is_compatible:
                    logger.warning(f"{self.model_type} transformsä¸å…¼å®¹: {message}ï¼Œå›é€€åˆ°ä¼ ç»Ÿé¢„å¤„ç†")
                    return None

                return transforms

            except ImportError:
                # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
                pass
        return None
    def _load_samples_optimized(self):
        """ä½¿ç”¨ä¼˜åŒ–çš„æ ‡ç­¾å¤„ç†å™¨åŠ è½½æ ·æœ¬æ•°æ®"""
        logger.info(f"ä½¿ç”¨ä¼˜åŒ–ç¼“å­˜åŠ è½½æ ·æœ¬æ•°æ®...")

        # ä½¿ç”¨ä¼˜åŒ–çš„æ ‡ç­¾å¤„ç†å™¨è·å–æ‰€æœ‰æœ‰æ•ˆæ ·æœ¬
        samples = self.label_processor.get_all_valid_samples(self.frames_dir)

        logger.info(f"ä¼˜åŒ–åŠ è½½å®Œæˆ: {len(samples)} ä¸ªæœ‰æ•ˆæ ·æœ¬")
        return samples

    def _select_top_classes(self, samples):
        """æ ¹æ®æ ·æœ¬æ•°é‡é€‰æ‹©å‰Nä¸ªç±»åˆ«

        Args:
            samples (list): æ‰€æœ‰æ ·æœ¬æ•°æ®

        Returns:
            tuple: (selected_classes, class_mapping) é€‰å®šçš„ç±»åˆ«åˆ—è¡¨å’Œæ˜ å°„å…³ç³»
        """
        if self.top_n_classes is None:
            selected_classes = self.original_behavior_labels.copy()
            class_mapping = {i: i for i in range(len(selected_classes))}
            logger.info(f"ä½¿ç”¨å…¨éƒ¨ {len(selected_classes)} ä¸ªç±»åˆ«")
            return selected_classes, class_mapping

        # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡
        class_counts = Counter()
        for sample in samples:
            labels = sample['labels']
            for i, label_value in enumerate(labels):
                if label_value > 0:  # æ­£æ ·æœ¬
                    class_counts[i] += 1

        # æŒ‰æ ·æœ¬æ•°é‡æ’åºï¼Œé€‰æ‹©å‰Nä¸ªç±»åˆ«
        sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)

        # è¿‡æ»¤æ‰æ ·æœ¬æ•°é‡å°‘äºé˜ˆå€¼çš„ç±»åˆ«
        filtered_classes = [(class_idx, count) for class_idx, count in sorted_classes
                           if count >= self.min_samples_per_class]

        # é€‰æ‹©å‰top_n_classesä¸ªç±»åˆ«
        selected_class_indices = [class_idx for class_idx, count in filtered_classes[:self.top_n_classes]]
        selected_classes = [self.original_behavior_labels[i] for i in selected_class_indices]

        # åˆ›å»ºæ–°æ—§ç±»åˆ«ç´¢å¼•çš„æ˜ å°„å…³ç³»
        class_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(selected_class_indices)}

        return selected_classes, class_mapping

    def _update_sample_labels(self, samples):
        """æ›´æ–°æ ·æœ¬æ ‡ç­¾ï¼Œåªä¿ç•™é€‰å®šçš„ç±»åˆ«

        Args:
            samples (list): åŸå§‹æ ·æœ¬æ•°æ®

        Returns:
            list: æ›´æ–°åçš„æ ·æœ¬æ•°æ®
        """
        if self.top_n_classes is None:
            return samples  # ä¸éœ€è¦æ›´æ–°

        updated_samples = []
        for sample in samples:
            old_labels = sample['labels']
            new_labels = []

            # æ ¹æ®class_mappingé‡æ–°æ„å»ºæ ‡ç­¾å‘é‡
            for new_idx in range(len(self.class_mapping)):
                # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹ç±»åˆ«ç´¢å¼•
                old_idx = None
                for old_i, new_i in self.class_mapping.items():
                    if new_i == new_idx:
                        old_idx = old_i
                        break

                if old_idx is not None:
                    new_labels.append(old_labels[old_idx])
                else:
                    new_labels.append(0.0)

            # è·³è¿‡å…¨é›¶æ ‡ç­¾çš„æ ·æœ¬
            if sum(new_labels) == 0:
                continue

            # åˆ›å»ºæ–°çš„æ ·æœ¬
            updated_sample = sample.copy()
            updated_sample['labels'] = new_labels
            updated_samples.append(updated_sample)

        logger.info(f"æ ‡ç­¾æ›´æ–°å®Œæˆ: {len(samples)} -> {len(updated_samples)} ä¸ªæœ‰æ•ˆæ ·æœ¬")
        return updated_samples
    
    def _split_data(self, samples, split):
        """æ•°æ®åˆ†å‰²ï¼ˆæ”¯æŒçœŸæ­£çš„å¤šæ ‡ç­¾åˆ†å±‚æŠ½æ ·ï¼‰

        ä½¿ç”¨iterative stratificationç®—æ³•ç¡®ä¿æ¯ä¸ªç±»åˆ«åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­çš„åˆ†å¸ƒæ¯”ä¾‹ä¸€è‡´ã€‚
        å¦‚æœiterative-stratificationåº“æœªå®‰è£…ï¼Œå›é€€åˆ°ç®€åŒ–çš„åˆ†å±‚ç­–ç•¥ã€‚

        Args:
            samples (list): æ‰€æœ‰æ ·æœ¬æ•°æ®
            split (str): 'train' æˆ– 'test'

        Returns:
            list: åˆ’åˆ†åçš„æ ·æœ¬æ•°æ®
        """
        if len(samples) <= 2:
            return samples

        if not self.stratified_split:
            # ä½¿ç”¨ç®€å•çš„8:2åˆ†å‰²
            split_idx = max(1, int(len(samples) * 0.8))
            if split == 'train':
                return samples[:split_idx]
            else:
                return samples[split_idx:]

        # ğŸ”§ æ–°å¢ï¼šä½¿ç”¨çœŸæ­£çš„å¤šæ ‡ç­¾åˆ†å±‚æŠ½æ ·ï¼ˆIterative Stratificationï¼‰
        if ITERSTRAT_AVAILABLE:
            try:
                # æ„å»ºå¤šæ ‡ç­¾çŸ©é˜µ (n_samples, n_classes)
                y = np.array([sample['labels'] for sample in samples])

                # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ ·æœ¬è¿›è¡Œåˆ†å±‚
                if len(samples) < 10:
                    logger.warning(f"æ ·æœ¬æ•°é‡å¤ªå°‘({len(samples)})ï¼Œå›é€€åˆ°ç®€å•åˆ†å‰²")
                    split_idx = max(1, int(len(samples) * 0.8))
                    return samples[:split_idx] if split == 'train' else samples[split_idx:]

                # ä½¿ç”¨MultilabelStratifiedShuffleSplitè¿›è¡Œåˆ†å±‚åˆ†å‰²
                msss = MultilabelStratifiedShuffleSplit(
                    n_splits=1,
                    test_size=0.2,
                    random_state=42
                )

                # æ‰§è¡Œåˆ†å±‚åˆ†å‰²
                for train_indices, test_indices in msss.split(X=np.zeros(len(samples)), y=y):
                    if split == 'train':
                        result_samples = [samples[i] for i in train_indices]
                    else:
                        result_samples = [samples[i] for i in test_indices]

                    # éªŒè¯åˆ†å±‚æ•ˆæœ
                    self._validate_stratified_split(samples, train_indices, test_indices,
                                                    method="Iterative Stratification")

                    return result_samples

            except Exception as e:
                logger.warning(f"Iterative Stratificationå¤±è´¥: {e}ï¼Œå›é€€åˆ°ç®€åŒ–åˆ†å±‚ç­–ç•¥")
                # ç»§ç»­æ‰§è¡Œä¸‹é¢çš„ç®€åŒ–åˆ†å±‚ç­–ç•¥

        # ğŸ”§ é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç®€åŒ–çš„åˆ†å±‚æŠ½æ ·ï¼ˆåªè€ƒè™‘ç¬¬ä¸€ä¸ªæ­£æ ‡ç­¾ï¼‰
        try:
            # ä¸ºæ¯ä¸ªæ ·æœ¬åˆ›å»ºåˆ†å±‚æ ‡è¯†
            # ä½¿ç”¨æ ·æœ¬çš„ç¬¬ä¸€ä¸ªæ­£æ ‡ç­¾ä½œä¸ºåˆ†å±‚ä¾æ®
            stratify_labels = []
            for sample in samples:
                labels = sample['labels']
                if sum(labels) == 0:
                    stratify_labels.append(-1)  # æ— æ ‡ç­¾æ ·æœ¬
                else:
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ­£æ ‡ç­¾ä½œä¸ºåˆ†å±‚ä¾æ®
                    main_class = next(i for i, label in enumerate(labels) if label > 0)
                    stratify_labels.append(main_class)

            # æ£€æŸ¥æ¯ä¸ªç±»åˆ«æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ ·æœ¬è¿›è¡Œåˆ†å±‚
            class_counts = Counter(stratify_labels)
            min_count = min(count for label, count in class_counts.items() if label != -1)

            if min_count < 2:
                # å¦‚æœæŸäº›ç±»åˆ«æ ·æœ¬å¤ªå°‘ï¼Œå›é€€åˆ°ç®€å•åˆ†å‰²
                logger.warning(f"æŸäº›ç±»åˆ«æ ·æœ¬æ•°å°‘äº2ä¸ªï¼Œå›é€€åˆ°ç®€å•åˆ†å‰²")
                split_idx = max(1, int(len(samples) * 0.8))
                if split == 'train':
                    return samples[:split_idx]
                else:
                    return samples[split_idx:]

            # æ‰§è¡Œåˆ†å±‚åˆ†å‰²
            train_indices, test_indices = train_test_split(
                range(len(samples)),
                test_size=0.2,
                stratify=stratify_labels,
                random_state=42
            )

            if split == 'train':
                result_samples = [samples[i] for i in train_indices]
            else:
                result_samples = [samples[i] for i in test_indices]

            # éªŒè¯åˆ†å±‚æ•ˆæœ
            self._validate_stratified_split(samples, train_indices, test_indices,
                                           method="Simplified Stratification (first label)")

            return result_samples

        except Exception as e:
            logger.warning(f"åˆ†å±‚æŠ½æ ·å¤±è´¥: {e}ï¼Œå›é€€åˆ°ç®€å•åˆ†å‰²")
            # å›é€€åˆ°ç®€å•åˆ†å‰²
            split_idx = max(1, int(len(samples) * 0.8))
            if split == 'train':
                return samples[:split_idx]
            else:
                return samples[split_idx:]

    def _validate_stratified_split(self, samples, train_indices, test_indices, method="Stratification"):
        """éªŒè¯åˆ†å±‚åˆ†å‰²çš„æ•ˆæœ

        Args:
            samples (list): æ‰€æœ‰æ ·æœ¬æ•°æ®
            train_indices (list): è®­ç»ƒé›†ç´¢å¼•
            test_indices (list): æµ‹è¯•é›†ç´¢å¼•
            method (str): åˆ†å±‚æ–¹æ³•åç§°ï¼Œç”¨äºæ—¥å¿—è¾“å‡º
        """
        train_class_counts = Counter()
        test_class_counts = Counter()

        # ç»Ÿè®¡è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ
        for idx in train_indices:
            labels = samples[idx]['labels']
            for i, label_value in enumerate(labels):
                if label_value > 0:
                    train_class_counts[i] += 1

        # ç»Ÿè®¡æµ‹è¯•é›†ç±»åˆ«åˆ†å¸ƒ
        for idx in test_indices:
            labels = samples[idx]['labels']
            for i, label_value in enumerate(labels):
                if label_value > 0:
                    test_class_counts[i] += 1

        # è®¡ç®—åˆ†å¸ƒå·®å¼‚çš„ç»Ÿè®¡æŒ‡æ ‡ï¼ˆç”¨äºéªŒè¯åˆ†å±‚æ•ˆæœï¼‰
        ratios_diff = []
        for i in range(len(self.behavior_labels)):
            train_count = train_class_counts.get(i, 0)
            test_count = test_class_counts.get(i, 0)
            total_count = train_count + test_count

            if total_count > 0:
                train_ratio = train_count / total_count
                ratio_diff = abs(train_ratio - 0.8)  # ç†æƒ³æƒ…å†µä¸‹è®­ç»ƒé›†åº”è¯¥å 80%
                ratios_diff.append(ratio_diff)

        return True
    
    def set_model_type(self, model_type):
        """è®¾ç½®æ¨¡å‹ç±»å‹å¹¶æ›´æ–°transformsï¼ˆç”¨äºç½‘æ ¼æœç´¢ï¼‰"""
        self.model_type = model_type
        self.model_transforms = self._get_model_transforms()
    
    def __len__(self):
        return len(self.samples)
    
    def _sample_frames(self, buffer):
        """ç»Ÿä¸€çš„å¸§é‡‡æ ·æ–¹æ³•

        Args:
            buffer: è¾“å…¥å¸§ç¼“å†²åŒºï¼Œå½¢çŠ¶ä¸º (T, H, W, C)

        Returns:
            é‡‡æ ·åçš„å¸§ç¼“å†²åŒºï¼Œå½¢çŠ¶ä¸º (clip_len, H, W, C)
        """
        if self.sampling_mode == 'fps' and self.target_fps is not None:
            # FPS é‡‡æ ·
            return self.fps_sampling_neonatal(buffer, self.clip_len, self.target_fps, self.original_fps)
        else:
            # éšæœºé‡‡æ ·
            return self._temporal_crop(buffer, self.clip_len)

    def __getitem__(self, index):
        """è·å–å•ä¸ªæ ·æœ¬"""
        sample = self.samples[index]

        # åŠ è½½è§†é¢‘å¸§
        buffer = self.load_frames(sample['frames_dir'])

        # ç»Ÿä¸€çš„å¸§é‡‡æ ·
        buffer = self._sample_frames(buffer)

        # å¦‚æœæœ‰æ¨¡å‹ç‰¹å®šçš„transformsï¼Œä½¿ç”¨å®˜æ–¹transforms
        if self.model_transforms is not None:
            # è½¬æ¢ä¸ºtorch tensoræ ¼å¼: (T, H, W, C) -> (T, C, H, W)
            buffer = torch.from_numpy(buffer).float() / 255.0
            buffer = buffer.permute(0, 3, 1, 2)  # (T, H, W, C) -> (T, C, H, W)

            # åº”ç”¨æ¨¡å‹ç‰¹å®šçš„å®˜æ–¹transforms (è¾“å…¥: T, C, H, W -> è¾“å‡º: C, T, H, W)
            buffer = self.model_transforms(buffer)
        else:
            # ä½¿ç”¨ä¼ ç»Ÿçš„é¢„å¤„ç†æ–¹å¼ï¼ˆå‘åå…¼å®¹ï¼‰
            buffer = self.crop(buffer, crop_size=self.crop_size, temporal_crop=False)
            buffer = self.normalize(buffer)  # å¯¹æ¨¡å‹è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
            buffer = self.to_tensor(buffer)  # å¯¹ç»´åº¦è¿›è¡Œè½¬åŒ–
            buffer = torch.from_numpy(buffer)

        # è·å–å¤šæ ‡ç­¾å‘é‡
        labels = torch.tensor(sample['labels'], dtype=torch.float32)

        # è¿”å›torchæ ¼å¼çš„ç‰¹å¾å’Œæ ‡ç­¾
        return buffer, labels
    
    def load_frames(self, frames_dir):
        """ä»ç›®å½•ä¸­åŠ è½½è§†é¢‘å¸§ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼Œå‡å°‘å†…å­˜å ç”¨å’ŒåŠ è½½æ—¶é—´ï¼‰"""
        frame_paths = sorted([os.path.join(frames_dir, img)
                             for img in os.listdir(frames_dir) if img.endswith('.jpg')])
        frame_count = len(frame_paths)

        if frame_count == 0:
            raise ValueError(f"æ²¡æœ‰æ‰¾åˆ°å¸§å›¾åƒæ–‡ä»¶: {frames_dir}")

        # é™åˆ¶æœ€å¤§å¸§æ•°ï¼Œé¿å…å†…å­˜è¿‡è½½
        max_frames = 60  # é™åˆ¶æœ€å¤§å¸§æ•°
        if frame_count > max_frames:
            # å‡åŒ€é‡‡æ ·ï¼Œè€Œéæˆªæ–­
            indices = np.linspace(0, frame_count - 1, max_frames, dtype=int)
            frame_paths = [frame_paths[i] for i in indices]
            frame_count = max_frames

        # è¯»å–ç¬¬ä¸€å¸§ä»¥è·å–å®é™…å°ºå¯¸
        first_frame = cv2.imread(frame_paths[0])
        if first_frame is None:
            raise ValueError(f"æ— æ³•è¯»å–ç¬¬ä¸€å¸§å›¾åƒ: {frame_paths[0]}")

        actual_height, actual_width = first_frame.shape[:2]

        # é¢„å¤„ç†å°ºå¯¸ï¼Œå‡å°‘å†…å­˜å ç”¨
        target_height, target_width = 224, 224  # æ ‡å‡†å°ºå¯¸

        # æ ¹æ®ç›®æ ‡å°ºå¯¸åˆ›å»ºç¼“å†²åŒº
        buffer = np.empty((frame_count, target_height, target_width, 3), dtype=np.float32)

        # å¤„ç†ç¬¬ä¸€å¸§
        if (actual_height, actual_width) != (target_height, target_width):
            first_frame = cv2.resize(first_frame, (target_width, target_height))
        buffer[0] = first_frame.astype(np.float32)  # ç›´æ¥ä½¿ç”¨float32

        # æ‰¹é‡åŠ è½½å‰©ä½™å¸§
        for i, frame_name in enumerate(frame_paths[1:], 1):
            frame = cv2.imread(frame_name)
            if frame is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {frame_name}")

            # ç»Ÿä¸€resizeåˆ°ç›®æ ‡å°ºå¯¸
            if frame.shape[:2] != (target_height, target_width):
                frame = cv2.resize(frame, (target_width, target_height))

            buffer[i] = frame.astype(np.float32)

        return buffer
    
    def _temporal_crop(self, buffer, clip_len):
        """æ—¶é—´ç»´åº¦è£å‰ª

        Args:
            buffer: è¾“å…¥å¸§ç¼“å†²åŒºï¼Œå½¢çŠ¶ä¸º (T, H, W, C)
            clip_len: ç›®æ ‡å¸§æ•°

        Returns:
            è£å‰ªåçš„å¸§ç¼“å†²åŒºï¼Œå½¢çŠ¶ä¸º (clip_len, H, W, C)
        """
        if buffer.shape[0] <= clip_len:
            # å¸§æ•°ä¸è¶³ï¼Œå¡«å……
            if buffer.shape[0] == 0:
                buffer = np.zeros((1, buffer.shape[1], buffer.shape[2], 3), dtype=buffer.dtype)
            last_frame = buffer[-1]
            pad_size = clip_len - buffer.shape[0]
            padding = np.tile(last_frame[np.newaxis], (pad_size, 1, 1, 1))
            return np.concatenate([buffer, padding], axis=0)
        else:
            # éšæœºè£å‰ª
            time_index = np.random.randint(buffer.shape[0] - clip_len)
            return buffer[time_index:time_index + clip_len, :, :, :]

    def _spatial_crop(self, buffer, crop_size):
        """ç©ºé—´ç»´åº¦è£å‰ªï¼ˆresize æˆ–éšæœºè£å‰ªï¼‰

        Args:
            buffer: è¾“å…¥å¸§ç¼“å†²åŒºï¼Œå½¢çŠ¶ä¸º (T, H, W, C)
            crop_size: è£å‰ªå°ºå¯¸

        Returns:
            è£å‰ªåçš„å¸§ç¼“å†²åŒºï¼Œå½¢çŠ¶ä¸º (T, crop_size, crop_size, C)
        """
        clip_len = buffer.shape[0]
        target_shape = (clip_len, crop_size, crop_size, 3)

        if buffer.shape[1] < crop_size or buffer.shape[2] < crop_size:
            # è¾“å…¥å°ºå¯¸å°äºç›®æ ‡å°ºå¯¸ï¼Œè¿›è¡Œ resize
            resized_buffer = np.zeros(target_shape, dtype=buffer.dtype)
            for i in range(clip_len):
                resized_buffer[i] = cv2.resize(buffer[i], (crop_size, crop_size))
            return resized_buffer
        else:
            # è¾“å…¥å°ºå¯¸å¤§äºç­‰äºç›®æ ‡å°ºå¯¸ï¼Œè¿›è¡Œéšæœºè£å‰ª
            height_index = np.random.randint(buffer.shape[1] - crop_size)
            width_index = np.random.randint(buffer.shape[2] - crop_size)
            return buffer[:, height_index:height_index + crop_size,
                          width_index:width_index + crop_size, :]

    def crop(self, buffer, clip_len=None, crop_size=None, temporal_crop=True):
        """ç»Ÿä¸€çš„è£å‰ªæ–¹æ³•

        Args:
            buffer: è¾“å…¥å¸§ç¼“å†²åŒºï¼Œå½¢çŠ¶ä¸º (T, H, W, C)
            clip_len: ç›®æ ‡å¸§æ•°ï¼ˆNone è¡¨ç¤ºä¸è¿›è¡Œæ—¶é—´è£å‰ªï¼‰
            crop_size: è£å‰ªå°ºå¯¸ï¼ˆNone è¡¨ç¤ºä¸è¿›è¡Œç©ºé—´è£å‰ªï¼‰
            temporal_crop: æ˜¯å¦è¿›è¡Œæ—¶é—´ç»´åº¦è£å‰ª

        Returns:
            è£å‰ªåçš„å¸§ç¼“å†²åŒº
        """
        # æ—¶é—´ç»´åº¦è£å‰ª
        if temporal_crop and clip_len is not None:
            buffer = self._temporal_crop(buffer, clip_len)

        # ç©ºé—´ç»´åº¦è£å‰ª
        if crop_size is not None:
            buffer = self._spatial_crop(buffer, crop_size)

        return buffer

    def normalize(self, buffer):
        """å¯¹è§†é¢‘å¸§è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼ˆå‚è€ƒUCF101å®ç°ï¼‰"""
        # è¿›è¡Œå½’ä¸€åŒ–
        for i, frame in enumerate(buffer):
            frame -= np.array([[[90.0, 98.0, 102.0]]])
            buffer[i] = frame
        return buffer

    def to_tensor(self, buffer):
        """å°†numpyæ•°ç»„è½¬æ¢ä¸ºtensoræ ¼å¼ï¼ˆå‚è€ƒUCF101å®ç°ï¼‰"""
        # è¿›è¡Œç»´åº¦çš„è½¬åŒ–ï¼Œå°†æœ€åçš„ä¸€ä¸ªç»´è°ƒè½¬åˆ°ç¬¬ä¸€ç»´
        return buffer.transpose((3, 0, 1, 2))
    
    def get_num_classes(self):
        """è·å–ç±»åˆ«æ•°"""
        return self.num_classes
    
    def get_class_names(self):
        """è·å–ç±»åˆ«åç§°åˆ—è¡¨"""
        return self.class_names
    
    def get_sample_id(self, index):
        """è·å–æ ·æœ¬ID"""
        sample = self.samples[index]
        return f"{sample['session_name']}/{sample['clip_id']}"
