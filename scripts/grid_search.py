"""ç½‘æ ¼æœç´¢å¯åŠ¨è„šæœ¬

å®ç°è¶…å‚æ•°ç½‘æ ¼æœç´¢ï¼Œæ”¯æŒè¿›ç¨‹å†…è°ƒç”¨å’Œå¤šç§å‚æ•°ç»„åˆç­–ç•¥ã€‚
ä¸»è¦åŠŸèƒ½ï¼šå‚æ•°ç»„åˆç”Ÿæˆã€å®éªŒæ‰§è¡Œã€ç»“æœæ”¶é›†å’ŒCSVæŠ¥å‘Šç”Ÿæˆã€‚
"""
import itertools
import subprocess
import yaml
import os
import sys
import csv
import json
import random
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.utils.config_parser import parse_arguments

def load_grid_config(path="config/grid.yaml"):
    """åŠ è½½ç½‘æ ¼æœç´¢é…ç½®"""
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def _as_list(v):
    """å°†è¾“å…¥è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼

    Args:
        v: ä»»æ„ç±»å‹çš„å‚æ•°å€¼

    Returns:
        list: ç»Ÿä¸€æ ¼å¼åŒ–åçš„åˆ—è¡¨
    """
    if v is None:
        return []
    return v if isinstance(v, (list, tuple)) else [v]

def generate_combinations(config):
    """ç”Ÿæˆå‚æ•°ç»„åˆåˆ—è¡¨

    æ”¯æŒæ ‡å‡†ç¬›å¡å°”ç§¯å’Œæ™ºèƒ½é…å¯¹ä¸¤ç§æ¨¡å¼ã€‚
    å½“model.typeå’Œhp.batch_sizeæ•°ç»„é•¿åº¦ç›¸åŒæ—¶ï¼ŒæŒ‰ä½ç½®é…å¯¹ã€‚
    æ”¯æŒé€šè¿‡models_to_trainå‚æ•°è¿‡æ»¤è¦è®­ç»ƒçš„æ¨¡å‹ã€‚

    Args:
        config (dict): ç½‘æ ¼æœç´¢é…ç½®

    Returns:
        list[dict]: å‚æ•°ç»„åˆåˆ—è¡¨
    """
    gs = (config or {}).get("grid_search", {}) or {}
    fixed = gs.get("fixed", {}) or {}
    grid = gs.get("grid", {}) or {}

    if not grid:
        return [fixed] if fixed else [{}]

    # è·å–æ¨¡å‹é€‰æ‹©åˆ—è¡¨ï¼Œå¦‚æœæœªé…ç½®åˆ™ä½¿ç”¨gridä¸­çš„æ‰€æœ‰æ¨¡å‹
    models_to_train = config.get("models_to_train", [])

    # æ£€æµ‹æ™ºèƒ½é…å¯¹æ¨¡å¼
    model_types = _as_list(grid.get("model.type", []))

    # å¦‚æœé…ç½®äº†models_to_trainï¼Œåˆ™è¿‡æ»¤æ¨¡å‹åˆ—è¡¨
    if models_to_train:
        model_types = [model for model in model_types if model in models_to_train]
        print(f"ğŸ¯ æ ¹æ®models_to_trainé…ç½®ï¼Œå°†è®­ç»ƒä»¥ä¸‹æ¨¡å‹: {model_types}")

    batch_sizes = _as_list(grid.get("hp.batch_size", []))

    # é…å¯¹æ¨¡å¼ï¼šä¸¤ä¸ªæ•°ç»„é•¿åº¦ç›¸åŒæ—¶æŒ‰ä½ç½®é…å¯¹
    if (len(model_types) > 1 and len(batch_sizes) > 1 and
        len(model_types) == len(batch_sizes)):

        model_batch_pairs = list(zip(model_types, batch_sizes))
        other_grid = {k: v for k, v in grid.items()
                     if k not in ["model.type", "hp.batch_size"]}

        if not other_grid:
            return [{**fixed, "model.type": model_type, "hp.batch_size": batch_size}
                   for model_type, batch_size in model_batch_pairs]
        else:
            other_valid_items = [(k, _as_list(v)) for k, v in other_grid.items() if _as_list(v)]
            if other_valid_items:
                other_keys, other_values_lists = zip(*other_valid_items)
                combinations = []
                for model_type, batch_size in model_batch_pairs:
                    for other_combo in itertools.product(*other_values_lists):
                        combo = {**fixed, "model.type": model_type, "hp.batch_size": batch_size}
                        combo.update(dict(zip(other_keys, other_combo)))
                        combinations.append(combo)
                return combinations
            else:
                return [{**fixed, "model.type": model_type, "hp.batch_size": batch_size}
                       for model_type, batch_size in model_batch_pairs]

    # æ ‡å‡†ç¬›å¡å°”ç§¯æ¨¡å¼
    valid_items = [(k, _as_list(v)) for k, v in grid.items() if _as_list(v)]

    if not valid_items:
        return [fixed] if fixed else [{}]

    keys, values_lists = zip(*valid_items)
    return [{**fixed, **dict(zip(keys, combo))}
            for combo in itertools.product(*values_lists)]

def save_results_to_csv(results, filename):
    """ä¿å­˜å®éªŒç»“æœåˆ°CSVæ–‡ä»¶

    Args:
        results (list[dict]): å®éªŒç»“æœåˆ—è¡¨
        filename (str): CSVæ–‡ä»¶å

    Returns:
        str|None: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    if not results:
        return None

    results_dir = "runs"
    os.makedirs(results_dir, exist_ok=True)
    filepath = os.path.join(results_dir, filename)

    param_keys = sorted({k for r in results for k in r.get("params", {}).keys()})

    fieldnames = [
        "experiment_id", "exp_name", "success",
        "best_accuracy", "final_accuracy"
    ] + param_keys

    with open(filepath, "w", newline="", encoding="utf-8") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for i, r in enumerate(results, 1):
            row = {
                "experiment_id": f"{i:03d}",
                "exp_name": r.get("exp_name"),
                "success": r.get("success"),
                "best_accuracy": r.get("best_accuracy"),
                "final_accuracy": r.get("final_accuracy"),
            }
            row.update(r.get("params", {}))
            writer.writerow(row)

    return filepath


def apply_param_overrides(config, params):
    """åº”ç”¨å‚æ•°è¦†ç›–åˆ°é…ç½®å­—å…¸

    Args:
        config (dict): åŸºç¡€é…ç½®å­—å…¸
        params (dict): å‚æ•°è¦†ç›–å­—å…¸ï¼Œæ”¯æŒåµŒå¥—è·¯å¾„

    Returns:
        dict: åº”ç”¨è¦†ç›–åçš„é…ç½®å­—å…¸
    """
    import copy
    config = copy.deepcopy(config)
    
    for k, v in (params or {}).items():
        keys = k.split('.')
        target = config
        for key in keys[:-1]:
            target = target.setdefault(key, {})
        target[keys[-1]] = v
    
    return config


def run_single_experiment_in_process(params, exp_id, config_path):
    """è¿›ç¨‹å†…è°ƒç”¨æ–¹å¼è¿è¡Œå•ä¸ªå®éªŒï¼ˆå•å¡è®­ç»ƒï¼‰"""
    exp_name = f"grid_{exp_id}"
    
    try:
        # å¯¼å…¥è®­ç»ƒå‡½æ•°
        from src.trainers.base_trainer import run_training
        
        # åŠ è½½åŸºç¡€é…ç½®
        config = load_grid_config(config_path)
        
        # åº”ç”¨å‚æ•°è¦†ç›–
        config = apply_param_overrides(config, params)
        
        # ç›´æ¥è°ƒç”¨è®­ç»ƒå‡½æ•°
        result = run_training(config, exp_name)
        
        # æ·»åŠ å‚æ•°ä¿¡æ¯åˆ°ç»“æœä¸­
        result["params"] = params
        
        return result
        
    except Exception as e:
        return {
            "success": False,
            "exp_name": exp_name,
            "params": params,
            "best_accuracy": 0.0,
            "final_accuracy": 0.0,
            "error": str(e)
        }


def run_single_experiment_subprocess(params, exp_id, use_multi_gpu, config_path):
    """å­è¿›ç¨‹æ–¹å¼è¿è¡Œå•ä¸ªå®éªŒï¼ˆå¤šå¡è®­ç»ƒï¼‰"""
    exp_name = f"grid_{exp_id}"
    
    # åˆ›å»ºä¸´æ—¶ç»“æœæ–‡ä»¶ç”¨äºè¿›ç¨‹é—´é€šä¿¡
    temp_result_file = f"/tmp/grid_result_{exp_id}_{random.randint(1000,9999)}.json"
    
    # ç»„è£…å‘½ä»¤
    if use_multi_gpu:
        import torch  # å±€éƒ¨å¯¼å…¥ï¼Œä»…åœ¨éœ€è¦æ—¶ä½¿ç”¨
        cmd = ["accelerate", "launch", "--multi_gpu", "--num_processes", str(torch.cuda.device_count())]
    else:
        cmd = [sys.executable, "-u"]
    
    # æ·»åŠ è®­ç»ƒè„šæœ¬å’ŒåŸºç¡€å‚æ•°
    cmd.extend(["scripts/train.py", "--config", config_path, "--exp_name", exp_name])
    cmd.extend(["--result_file", temp_result_file])  # æ–°å¢ï¼šæŒ‡å®šç»“æœæ–‡ä»¶
    
    # æ·»åŠ å‚æ•°è¦†ç›–
    for k, v in (params or {}).items():
        cmd.extend([f"--{k}", str(v)])

    # æ¸…ç†ç¯å¢ƒå˜é‡å¹¶è®¾ç½®å”¯ä¸€ç«¯å£
    env = os.environ.copy()
    for k in ["LOCAL_RANK", "RANK", "WORLD_SIZE", "MASTER_ADDR", "MASTER_PORT"]:
        env.pop(k, None)
    env["MASTER_ADDR"] = env.get("MASTER_ADDR", "127.0.0.1")
    env["MASTER_PORT"] = str(20000 + random.randint(0, 10000))

    # å¯åŠ¨å­è¿›ç¨‹
    process = subprocess.Popen(cmd, env=env)
    try:
        rc = process.wait()
    except KeyboardInterrupt:
        print(f"æ•è·åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ç»ˆæ­¢å­è¿›ç¨‹ {process.pid}...")
        process.terminate()
        process.wait()
        raise

    success = (rc == 0)
    
    # è¯»å–ç»“æœæ–‡ä»¶
    try:
        if os.path.exists(temp_result_file):
            with open(temp_result_file, 'r', encoding='utf-8') as f:
                result = json.load(f)
            os.remove(temp_result_file)  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            
            # ç¡®ä¿ç»“æœåŒ…å«å¿…è¦çš„å­—æ®µ
            result["params"] = params
            result["success"] = result.get("success", success)
            result["exp_name"] = result.get("exp_name", exp_name)
            
            # ç¡®ä¿accuracyå­—æ®µä¸ä¸ºNone
            if result.get("best_accuracy") is None:
                result["best_accuracy"] = 0.0
            if result.get("final_accuracy") is None:
                result["final_accuracy"] = 0.0
                
            return result
        else:
            print(f"ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {temp_result_file}")
    except Exception as e:
        print(f"è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        if os.path.exists(temp_result_file):
            try:
                with open(temp_result_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                print(f"æ–‡ä»¶å†…å®¹: {content[:200]}...")  # æ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
            except:
                pass
    
    # å›é€€ï¼šè¿”å›é»˜è®¤ç»“æœ
    return {
        "success": success,
        "exp_name": exp_name,
        "params": params,
        "best_accuracy": 0.0,
        "final_accuracy": 0.0,
        "error": "Failed to read result file" if success else "Training process failed"
    }


def run_single_experiment(params, exp_id, use_multi_gpu=False, config_path="config/grid.yaml"):
    """è¿è¡Œå•ä¸ªå®éªŒ

    Args:
        params (dict): å®éªŒå‚æ•°è¦†ç›–
        exp_id (str): å®éªŒID
        use_multi_gpu (bool): æ˜¯å¦ä½¿ç”¨å¤šGPU
        config_path (str): é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        dict: å®éªŒç»“æœå­—å…¸
    """
    exp_name = f"grid_{exp_id}"

    print(f"{'='*60}")
    print(f"ğŸš€ å¼€å§‹å®éªŒ {exp_id}: {exp_name}")
    print(f"ğŸ“‹ å‚æ•°: {params}")
    print(f"ğŸ¯ å¤šå¡è®­ç»ƒ: {'æ˜¯' if use_multi_gpu else 'å¦'}")
    print(f"{'='*60}")

    if use_multi_gpu:
        # å¤šå¡è®­ç»ƒï¼šä½¿ç”¨å­è¿›ç¨‹æ–¹å¼
        result = run_single_experiment_subprocess(params, exp_id, use_multi_gpu, config_path)
    else:
        # å•å¡è®­ç»ƒï¼šä½¿ç”¨è¿›ç¨‹å†…è°ƒç”¨æ–¹å¼
        result = run_single_experiment_in_process(params, exp_id, config_path)
    
    print(f"âœ… å®éªŒ {exp_name} å®Œæˆï¼Œæœ€ä½³: {result['best_accuracy']:.2f}% | æœ€ç»ˆ: {result['final_accuracy']:.2f}%")
    
    return result


def run_grid_search(args):
    """è¿è¡Œç½‘æ ¼æœç´¢"""
    config = load_grid_config(args.config)
    combinations = generate_combinations(config)

    if len(combinations) > args.max_experiments:
        combinations = combinations[:args.max_experiments]

    print(f"ğŸš€ å¼€å§‹ç½‘æ ¼æœç´¢ï¼Œå…± {len(combinations)} ä¸ªå®éªŒ")
    print(f"ğŸ“Š ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
    print("=" * 60)

    results = []
    successful = 0

    for i, params in enumerate(combinations, 1):
        print(f"ğŸ“Š å‡†å¤‡å®éªŒ {i}/{len(combinations)}")

        result = run_single_experiment(
            params, f"{i:03d}",
            use_multi_gpu=args.multi_gpu,
            config_path=args.config,
        )

        results.append(result)
        if result["success"]:
            successful += 1

    # æ€»ç»“
    print("=" * 60)
    print(f"ğŸ“ˆ ç½‘æ ¼æœç´¢å®Œæˆï¼")
    print(f"âœ… æˆåŠŸå®éªŒæ•°é‡: {successful}/{len(combinations)}")

    if successful > 0:
        successful_results = [r for r in results if r["success"]]
        # æ‰¾åˆ°â€œæœ€ä½³å‡†ç¡®ç‡â€æœ€é«˜çš„å®éªŒç»“æœ
        best_result = max(successful_results, key=lambda x: x["best_accuracy"])

        print(f"ğŸ† æœ€ä½³å®éªŒç»“æœ:")
        print(f"å®éªŒåç§°: {best_result['exp_name']}, æœ€ä½³å‡†ç¡®ç‡: {best_result['best_accuracy']:.2f}%, æœ€ç»ˆå‡†ç¡®ç‡: {best_result['final_accuracy']:.2f}%")
        
        # æŒ‰æœ€ä½³ç²¾åº¦æ’åºå‰nç»„ç»“æœ
        top_results = sorted(successful_results, key=lambda x: x["best_accuracy"], reverse=True)[:args.top_n]
        
        print(f"ğŸ“Š å‰{args.top_n}åå®éªŒç»“æœ:")
        for i, r in enumerate(top_results, 1):
            print(f"{i}. {r['exp_name']} - {r['best_accuracy']:.2f}% - {r['params']}")

    if args.save_results:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_filename = f"grid_search_results_{timestamp}.csv"
        saved_filepath = save_results_to_csv(results, results_filename)
        if saved_filepath:
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {saved_filepath}")

    return 0 if successful > 0 else 1


def main():
    """ä¸»å‡½æ•°ï¼šè°ƒåº¦å™¨å§‹ç»ˆå•è¿›ç¨‹ï¼Œä¸è¿›å…¥ Accelerate ç¯å¢ƒ"""
    args, _ = parse_arguments(mode="grid_search")
    return run_grid_search(args)


if __name__ == "__main__":
    sys.exit(main())