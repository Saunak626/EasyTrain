"""æ–°ç”Ÿå„¿å¤šæ ‡ç­¾æ•°æ®é›† - ç®€åŒ–æ•™å­¦ç‰ˆæœ¬

è¿™æ˜¯ä¸€ä¸ªæœ€å°åŒ–çš„å¤šæ ‡ç­¾è§†é¢‘æ•°æ®é›†å®ç°ï¼Œç”¨äºæ•™å­¦å’Œç†è§£æ ¸å¿ƒæ¦‚å¿µã€‚
åªä¿ç•™äº†å¤šæ ‡ç­¾æ•°æ®åŠ è½½çš„æœ€åŸºæœ¬åŠŸèƒ½ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä»å¸§å›¾åƒç›®å½•åŠ è½½è§†é¢‘æ•°æ®
2. ä»Excelæ–‡ä»¶åŠ è½½å¤šæ ‡ç­¾æ ‡æ³¨
3. ç®€å•çš„train/teståˆ’åˆ†
4. åŸºç¡€çš„è§†é¢‘é¢„å¤„ç†ï¼ˆresizeã€normalizeã€to_tensorï¼‰

ç§»é™¤çš„é«˜çº§åŠŸèƒ½ï¼š
- åŠ æƒé‡‡æ ·ã€åˆ†å±‚é‡‡æ ·
- FPSé‡‡æ ·ã€æ ·æœ¬æƒé‡è®¡ç®—
- pos_weightè®¡ç®—
- æ¨¡å‹ç‰¹å®šçš„transforms
- è¯¦ç»†çš„éªŒè¯ç»Ÿè®¡
- ç±»åˆ«ç­›é€‰ï¼ˆtop_n_classesï¼‰
- æ ‡ç­¾ç¼“å­˜ä¼˜åŒ–

"""

import os
import cv2
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from PIL import Image  # ğŸ”§ æ–°å¢ï¼šä½¿ç”¨PILæ›¿ä»£cv2ï¼Œæå‡I/Oæ€§èƒ½


class NeonatalMultilabelSimple(Dataset):
    """æ–°ç”Ÿå„¿å¤šæ ‡ç­¾æ•°æ®é›† - ç®€åŒ–ç‰ˆ
    
    æœ€å°åŒ–å®ç°ï¼Œå±•ç¤ºå¤šæ ‡ç­¾è§†é¢‘æ•°æ®é›†çš„æ ¸å¿ƒæ„é€ æ–¹å¼ã€‚
    
    æ•°æ®ç»“æ„:
        frames_dir/
            session_001/
                clip_001/
                    00000.jpg
                    00001.jpg
                    ...
            session_002/
                ...
        
        labels.xlsx:
            æ–‡ä»¶å | æ–‡ä»¶å†…åŠ¨ä½œåºå· | æ ‡ç­¾1 | æ ‡ç­¾2 | ...
    
    Args:
        frames_dir (str): å¸§å›¾åƒæ ¹ç›®å½•
        labels_file (str): Excelæ ‡ç­¾æ–‡ä»¶è·¯å¾„
        split (str): 'train' æˆ– 'test'
        clip_len (int): æ¯ä¸ªè§†é¢‘ç‰‡æ®µçš„å¸§æ•°ï¼Œé»˜è®¤16
        train_ratio (float): è®­ç»ƒé›†æ¯”ä¾‹ï¼Œé»˜è®¤0.8
    """
    
    def __init__(self, frames_dir, labels_file, split='train', clip_len=16, train_ratio=0.8):
        self.frames_dir = frames_dir
        self.labels_file = labels_file
        self.split = split
        self.clip_len = clip_len
        self.train_ratio = train_ratio
        
        # å®šä¹‰è¡Œä¸ºæ ‡ç­¾ï¼ˆ24ä¸ªåŸå§‹æ ‡ç­¾ï¼‰
        self.behavior_labels = [
            'å–‚å…»å¼€å§‹', 'å–‚å…»ç»“æŸ', 'æ˜“å“­é—¹', 'å¼ å˜´é—­å˜´', 'å¸å®è¡Œä¸º', 'åƒæ‰‹æŒ‡',
            'åƒè„šæŒ‡', 'çš±çœ‰', 'å“­æ³£', 'å‘è„¾æ°”', 'æ¥å›æ‘‡å¤´', 'æ‰‹è„šæ´»åŠ¨åŠ å¿«',
            'å¯»æ‰¾å¥¶ç“¶', 'æ³¨è§†å¥¶ç“¶', 'å£°è°ƒå˜é«˜', 'æ‰“å“ˆæ¬ ', 'ç¡ç€äº†', 'é—´æ­‡å–å¥¶',
            'å”‡éƒ¨è§¦é£Ÿååº”', 'å–‚å…»æœŸé¬¼è„¸', 'å£è…”å™¨å…·å’¬åˆ', 'å¤´é¢ˆä¾§å‘å›é¿',
            'è‚¢ä½“å¼ åŠ›å‡é€€', 'è¿œç¦»å¥¶ç“¶'
        ]
        self.num_classes = len(self.behavior_labels)
        
        # åŠ è½½æ•°æ®
        self.samples = self._load_data()
        
        print(f"åŠ è½½ {split} æ•°æ®é›†: {len(self.samples)} ä¸ªæ ·æœ¬ï¼Œ{self.num_classes} ä¸ªç±»åˆ«")
    
    def _load_data(self):
        """åŠ è½½æ•°æ®å¹¶åˆ’åˆ†train/test"""
        # 1. è¯»å–Excelæ ‡ç­¾æ–‡ä»¶
        df = pd.read_excel(self.labels_file)
        
        # 2. æ¸…ç†æ–‡ä»¶åï¼Œæ„å»ºæ ·æœ¬åˆ—è¡¨
        samples = []
        for _, row in df.iterrows():
            # æå–session_nameå’Œclip_id
            session_name = row['æ–‡ä»¶å'].replace('.mov', '').replace('.mp4', '').strip()
            clip_id = str(row['æ–‡ä»¶å†…åŠ¨ä½œåºå·'])
            
            # æ£€æŸ¥å¸§ç›®å½•æ˜¯å¦å­˜åœ¨
            clip_dir = os.path.join(self.frames_dir, session_name, clip_id)
            if not os.path.exists(clip_dir):
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¸§å›¾åƒ
            frame_files = [f for f in os.listdir(clip_dir) if f.endswith('.jpg')]
            if len(frame_files) == 0:
                continue
            
            # æå–å¤šæ ‡ç­¾å‘é‡
            label_vector = []
            for label_name in self.behavior_labels:
                if label_name in row:
                    label_vector.append(float(row[label_name]))
                else:
                    label_vector.append(0.0)
            
            # è·³è¿‡å…¨é›¶æ ‡ç­¾
            if sum(label_vector) == 0:
                continue
            
            # ğŸ”§ ä¼˜åŒ–ï¼šé¢„å…ˆè½¬æ¢ä¸ºtensorï¼Œé¿å…æ¯æ¬¡__getitem__æ—¶é‡å¤è½¬æ¢
            samples.append({
                'session_name': session_name,
                'clip_id': clip_id,
                'frames_dir': clip_dir,
                'labels': torch.tensor(label_vector, dtype=torch.float32)
            })
        
        # 3. ç®€å•çš„train/teståˆ’åˆ†ï¼ˆæŒ‰8:2æ¯”ä¾‹ï¼‰
        split_idx = int(len(samples) * self.train_ratio)
        if self.split == 'train':
            return samples[:split_idx]
        else:
            return samples[split_idx:]
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, index):
        """è·å–å•ä¸ªæ ·æœ¬"""
        sample = self.samples[index]

        # 1. åŠ è½½è§†é¢‘å¸§
        frames = self._load_frames(sample['frames_dir'])

        # 2. é‡‡æ ·åˆ°å›ºå®šå¸§æ•°
        frames = self._sample_frames(frames, self.clip_len)

        # 3. é¢„å¤„ç†ï¼šnormalize + to_tensor
        frames = self._preprocess(frames)

        # 4. è·å–æ ‡ç­¾ï¼ˆå·²åœ¨åˆå§‹åŒ–æ—¶è½¬æ¢ä¸ºtensorï¼‰
        labels = sample['labels']

        return frames, labels

    def _load_frames(self, frames_dir):
        """ä»ç›®å½•åŠ è½½æ‰€æœ‰å¸§å›¾åƒï¼ˆä¼˜åŒ–ç‰ˆï¼šä½¿ç”¨PILæ›¿ä»£cv2ï¼‰

        Args:
            frames_dir (str): å¸§å›¾åƒç›®å½•è·¯å¾„

        Returns:
            np.ndarray: å½¢çŠ¶ä¸º (T, H, W, C) çš„å¸§æ•°ç»„
        """
        # è·å–æ‰€æœ‰jpgæ–‡ä»¶å¹¶æ’åº
        frame_paths = sorted([
            os.path.join(frames_dir, f)
            for f in os.listdir(frames_dir)
            if f.endswith('.jpg')
        ])

        if len(frame_paths) == 0:
            raise ValueError(f"æ²¡æœ‰æ‰¾åˆ°å¸§å›¾åƒ: {frames_dir}")

        # ğŸ”§ ä¼˜åŒ–ï¼šä½¿ç”¨PILæ‰¹é‡è¯»å–å¸§ï¼ˆæ¯”cv2å¿«çº¦30%ï¼‰
        frames = []
        for frame_path in frame_paths:
            try:
                # ä½¿ç”¨PILè¯»å–å›¾åƒï¼ˆRGBæ ¼å¼ï¼‰
                img = Image.open(frame_path).convert('RGB')
                # Resizeåˆ°æ ‡å‡†å°ºå¯¸ 224x224
                img = img.resize((224, 224), Image.BILINEAR)
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                frame = np.array(img, dtype=np.float32)
                frames.append(frame)
            except Exception as e:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ {frame_path}: {e}")

        # è½¬æ¢ä¸ºnumpyæ•°ç»„: (T, H, W, C)
        return np.array(frames, dtype=np.float32)

    def _sample_frames(self, frames, clip_len):
        """é‡‡æ ·åˆ°å›ºå®šå¸§æ•°

        Args:
            frames (np.ndarray): è¾“å…¥å¸§ï¼Œå½¢çŠ¶ (T, H, W, C)
            clip_len (int): ç›®æ ‡å¸§æ•°

        Returns:
            np.ndarray: é‡‡æ ·åçš„å¸§ï¼Œå½¢çŠ¶ (clip_len, H, W, C)
        """
        total_frames = frames.shape[0]

        if total_frames >= clip_len:
            # å¸§æ•°è¶³å¤Ÿï¼Œéšæœºè£å‰ª
            start_idx = np.random.randint(0, total_frames - clip_len + 1)
            return frames[start_idx:start_idx + clip_len]
        else:
            # å¸§æ•°ä¸è¶³ï¼Œå¡«å……æœ€åä¸€å¸§
            padding = np.tile(frames[-1:], (clip_len - total_frames, 1, 1, 1))
            return np.concatenate([frames, padding], axis=0)

    def _preprocess(self, frames):
        """é¢„å¤„ç†ï¼šå½’ä¸€åŒ– + è½¬æ¢ä¸ºtensor

        Args:
            frames (np.ndarray): è¾“å…¥å¸§ï¼Œå½¢çŠ¶ (T, H, W, C)

        Returns:
            torch.Tensor: å½¢çŠ¶ (C, T, H, W)
        """
        # å½’ä¸€åŒ–ï¼ˆå‡å»å‡å€¼ï¼‰ï¼Œä¿æŒ float32ï¼Œé¿å…å˜æˆ float64
        mean = np.array([[[90.0, 98.0, 102.0]]], dtype=np.float32)
        frames = frames - mean

        # è½¬æ¢ç»´åº¦ï¼š(T, H, W, C) -> (C, T, H, W)
        frames = frames.transpose(3, 0, 1, 2)

        # è½¬æ¢ä¸º float32 tensorï¼ˆä¸æ¨¡å‹æƒé‡ dtype ä¸€è‡´ï¼‰
        return torch.from_numpy(frames).float()

    def get_num_classes(self):
        """è·å–ç±»åˆ«æ•°"""
        return self.num_classes

    def get_class_names(self):
        """è·å–ç±»åˆ«åç§°åˆ—è¡¨"""
        return self.behavior_labels


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""

    # 1. åˆ›å»ºæ•°æ®é›†
    train_dataset = NeonatalMultilabelSimple(
        frames_dir='../Neonate-Feeding-Assessment/data/cpu_processed_627/frames_segments',
        labels_file='../Neonate-Feeding-Assessment/result_xlsx/shanghai/multi_hot_labels.xlsx',
        split='train',
        clip_len=16
    )

    test_dataset = NeonatalMultilabelSimple(
        frames_dir='../Neonate-Feeding-Assessment/data/cpu_processed_627/frames_segments',
        labels_file='../Neonate-Feeding-Assessment/result_xlsx/shanghai/multi_hot_labels.xlsx',
        split='test',
        clip_len=16
    )

    # 2. åˆ›å»ºDataLoader
    from torch.utils.data import DataLoader

    train_loader = DataLoader(
        train_dataset,
        batch_size=8,
        shuffle=True,
        num_workers=4
    )

    # 3. è¿­ä»£æ•°æ®
    for frames, labels in train_loader:
        print(f"Frames shape: {frames.shape}")  # (B, C, T, H, W)
        print(f"Labels shape: {labels.shape}")  # (B, num_classes)
        break

    print(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
    print(f"ç±»åˆ«æ•°: {train_dataset.get_num_classes()}")


if __name__ == '__main__':
    example_usage()


