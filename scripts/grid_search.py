"""ç½‘æ ¼æœç´¢å¯åŠ¨è„šæœ¬

è®¾è®¡æ€è·¯ï¼š
æœ¬è„šæœ¬å®ç°äº†é«˜æ•ˆã€ç¨³å®šçš„è¶…å‚æ•°ç½‘æ ¼æœç´¢ï¼Œé‡‡ç”¨è¿›ç¨‹å†…è°ƒç”¨çš„æ¶æ„è®¾è®¡ã€‚
æ ¸å¿ƒè®¾è®¡åŸåˆ™åŒ…æ‹¬ï¼š
- è¿›ç¨‹å†…è°ƒç”¨ï¼šç›´æ¥è°ƒç”¨è®­ç»ƒå‡½æ•°ï¼Œé¿å…å­è¿›ç¨‹å¼€é”€å’Œæ–‡ä»¶I/Oä¾èµ–
- å†…å­˜ä¼ é€’ï¼šé€šè¿‡å‡½æ•°è¿”å›å€¼ç›´æ¥è·å–è®­ç»ƒç»“æœï¼Œæé«˜æ•ˆç‡å’Œå¯é æ€§
- èµ„æºç®¡ç†ï¼šæ¯ä¸ªå®éªŒåè‡ªåŠ¨æ¸…ç†GPUç¼“å­˜ï¼Œç¡®ä¿èµ„æºå¹²å‡€é‡Šæ”¾
- çµæ´»é…ç½®ï¼šæ”¯æŒç¬›å¡å°”ç§¯å’Œç‰¹æ®Šé…å¯¹æ¨¡å¼çš„å‚æ•°ç»„åˆç”Ÿæˆ
- ç»“æœç®¡ç†ï¼šç›´æ¥æ”¶é›†è®­ç»ƒç»“æœï¼Œç”Ÿæˆç»“æ„åŒ–çš„CSVæŠ¥å‘Š

æ ¸å¿ƒåŠŸèƒ½ï¼š
- generate_combinations: æ™ºèƒ½å‚æ•°ç»„åˆç”Ÿæˆï¼Œæ”¯æŒå¤šç§ç»„åˆç­–ç•¥
- run_single_experiment: å•å®éªŒæ‰§è¡Œå™¨ï¼Œè¿›ç¨‹å†…è°ƒç”¨è®­ç»ƒå‡½æ•°
- run_grid_search: ç½‘æ ¼æœç´¢è°ƒåº¦å™¨ï¼Œåè°ƒæ•´ä¸ªæœç´¢æµç¨‹
- apply_param_overrides: å‚æ•°è¦†ç›–å™¨ï¼Œæ”¯æŒåµŒå¥—å‚æ•°è·¯å¾„
- save_results_to_csv: ç»“æœæŒä¹…åŒ–ï¼Œç”Ÿæˆä¾¿äºåˆ†æçš„CSVæŠ¥å‘Š

ç‰¹æ®Šå¤„ç†ï¼š
- å¼‚å¸¸å¤„ç†ï¼šå•ä¸ªå®éªŒå¤±è´¥ä¸å½±å“åç»­å®éªŒç»§ç»­æ‰§è¡Œ
- å†…å­˜ç®¡ç†ï¼šæ¯ä¸ªå®éªŒåæ¸…ç†GPUç¼“å­˜ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
- é…å¯¹æ¨¡å¼ï¼šå½“batch_sizeæ•°ç»„ä¸modelæ•°ç»„é•¿åº¦ç›¸åŒæ—¶ï¼ŒæŒ‰å¯¹åº”é¡ºåºé…å¯¹
- SwanLabé›†æˆï¼šä¿ç•™SwanLabå®éªŒè¿½è¸ªï¼Œåˆ é™¤JSONæ–‡ä»¶ä¾èµ–
"""
import itertools
import subprocess
import yaml
import os
import sys
import time
import csv
import json
import random
import torch

from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.utils.config_parser import parse_arguments

def load_grid_config(path="config/grid.yaml"):
    """åŠ è½½ç½‘æ ¼æœç´¢é…ç½®"""
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def _as_list(v):
    """æ ‡é‡â†’å•å…ƒç´ åˆ—è¡¨ï¼›åˆ—è¡¨/å…ƒç»„åŸæ ·ï¼›Noneâ†’ç©ºåˆ—è¡¨
    
    è®¾è®¡æ€è·¯ï¼š
    ç»Ÿä¸€å‚æ•°æ ¼å¼å¤„ç†çš„å·¥å…·å‡½æ•°ï¼Œç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½èƒ½ä»¥åˆ—è¡¨å½¢å¼è¿›è¡Œåç»­å¤„ç†ã€‚
    è¿™ç§è®¾è®¡ç®€åŒ–äº†å‚æ•°ç»„åˆç”Ÿæˆçš„é€»è¾‘ï¼Œé¿å…äº†å¤§é‡çš„ç±»å‹æ£€æŸ¥ä»£ç ã€‚
    
    Args:
        v: ä»»æ„ç±»å‹çš„å‚æ•°å€¼
        
    Returns:
        list: ç»Ÿä¸€æ ¼å¼åŒ–åçš„åˆ—è¡¨
            - None â†’ []
            - æ ‡é‡ â†’ [æ ‡é‡]
            - åˆ—è¡¨/å…ƒç»„ â†’ åŸæ ·è¿”å›
    """
    if v is None:
        return []
    return v if isinstance(v, (list, tuple)) else [v]

def generate_combinations(config):
    """
    æ™ºèƒ½å‚æ•°ç»„åˆç”Ÿæˆå™¨ï¼Œæ”¯æŒå¤šç§ç»„åˆç­–ç•¥
    
    è®¾è®¡æ€è·¯ï¼š
    æœ¬å‡½æ•°å®ç°äº†çµæ´»çš„è¶…å‚æ•°ç»„åˆç”Ÿæˆç­–ç•¥ï¼Œæ ¸å¿ƒè®¾è®¡åŒ…æ‹¬ï¼š
    - åŒæ¨¡å¼æ”¯æŒï¼šæ ‡å‡†ç¬›å¡å°”ç§¯æ¨¡å¼å’Œç‰¹æ®Šé…å¯¹æ¨¡å¼
    - æ™ºèƒ½æ£€æµ‹ï¼šè‡ªåŠ¨è¯†åˆ«batch_sizeä¸modelé…å¯¹çš„åœºæ™¯
    - å‚æ•°åˆ†å±‚ï¼šåŒºåˆ†å›ºå®šå‚æ•°(fixed)å’Œæœç´¢å‚æ•°(grid)
    - ç±»å‹å®¹é”™ï¼šè‡ªåŠ¨å¤„ç†æ ‡é‡ã€åˆ—è¡¨ã€Noneç­‰ä¸åŒç±»å‹
    
    ç»„åˆç­–ç•¥ï¼š
    1. æ ‡å‡†æ¨¡å¼ï¼šæ‰€æœ‰å‚æ•°è¿›è¡Œç¬›å¡å°”ç§¯ç»„åˆ
    2. é…å¯¹æ¨¡å¼ï¼šå½“model.typeæ•°ç»„ä¸hp.batch_sizeæ•°ç»„é•¿åº¦ç›¸åŒæ—¶ï¼Œ
       æŒ‰å¯¹åº”ä½ç½®é…å¯¹ï¼Œé¿å…ä¸åˆç†çš„æ¨¡å‹-æ‰¹å¤§å°ç»„åˆ
    
    Args:
        config (dict): ç½‘æ ¼æœç´¢é…ç½®
            - grid_search.grid: æœç´¢å‚æ•°å­—å…¸
            - grid_search.fixed: å›ºå®šå‚æ•°å­—å…¸
            
    Returns:
        list[dict]: å‚æ•°ç»„åˆåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€ç»„å®éªŒå‚æ•°
    
    ç¤ºä¾‹ï¼š
        é…å¯¹æ¨¡å¼ï¼šmodel.type=["resnet", "vit"], hp.batch_size=[32, 16]
        â†’ ç”Ÿæˆ[("resnet", 32), ("vit", 16)]è€Œé4ç§ç»„åˆ
    """
    gs = (config or {}).get("grid_search", {}) or {}
    fixed = gs.get("fixed", {}) or {}
    grid = gs.get("grid", {}) or {}

    # è¾¹ç•Œæƒ…å†µï¼šæ— æœç´¢å‚æ•°æ—¶è¿”å›å›ºå®šå‚æ•°
    if not grid:
        return [fixed] if fixed else [{}]

    # === æ™ºèƒ½é…å¯¹æ¨¡å¼æ£€æµ‹ ===
    # æå–model.typeå’Œhp.batch_sizeå‚æ•°åˆ—è¡¨
    model_types = _as_list(grid.get("model.type", []))
    batch_sizes = _as_list(grid.get("hp.batch_size", []))
    
    # é…å¯¹æ¨¡å¼è§¦å‘æ¡ä»¶ï¼šä¸¤ä¸ªæ•°ç»„éƒ½æœ‰å¤šä¸ªå…ƒç´ ä¸”é•¿åº¦ç›¸åŒ
    # è®¾è®¡ç›®çš„ï¼šé¿å…å¤§æ¨¡å‹é…å°batch_sizeæˆ–å°æ¨¡å‹é…å¤§batch_sizeçš„ä¸åˆç†ç»„åˆ
    if (len(model_types) > 1 and len(batch_sizes) > 1 and 
        len(model_types) == len(batch_sizes)):
        
        # åˆ›å»ºmodel-batché…å¯¹ï¼šæŒ‰ä½ç½®ä¸€ä¸€å¯¹åº”
        model_batch_pairs = list(zip(model_types, batch_sizes))
        
        # åˆ†ç¦»å…¶ä»–éœ€è¦æœç´¢çš„å‚æ•°
        other_grid = {k: v for k, v in grid.items() 
                     if k not in ["model.type", "hp.batch_size"]}
        
        if not other_grid:
            # çº¯é…å¯¹æ¨¡å¼ï¼šåªæœ‰modelå’Œbatch_sizeéœ€è¦é…å¯¹
            return [{**fixed, "model.type": model_type, "hp.batch_size": batch_size}
                   for model_type, batch_size in model_batch_pairs]
        else:
            # æ··åˆæ¨¡å¼ï¼šé…å¯¹å‚æ•°ä¸å…¶ä»–å‚æ•°åšç¬›å¡å°”ç§¯
            other_valid_items = [(k, _as_list(v)) for k, v in other_grid.items() if _as_list(v)]
            if other_valid_items:
                other_keys, other_values_lists = zip(*other_valid_items)
                combinations = []
                # æ¯ä¸ªmodel-batché…å¯¹ä¸å…¶ä»–å‚æ•°çš„æ‰€æœ‰ç»„åˆé…å¯¹
                for model_type, batch_size in model_batch_pairs:
                    for other_combo in itertools.product(*other_values_lists):
                        combo = {**fixed, "model.type": model_type, "hp.batch_size": batch_size}
                        combo.update(dict(zip(other_keys, other_combo)))
                        combinations.append(combo)
                return combinations
            else:
                # å…¶ä»–å‚æ•°ä¸ºç©ºï¼Œå›é€€åˆ°çº¯é…å¯¹æ¨¡å¼
                return [{**fixed, "model.type": model_type, "hp.batch_size": batch_size}
                       for model_type, batch_size in model_batch_pairs]
    
    # === æ ‡å‡†ç¬›å¡å°”ç§¯æ¨¡å¼ ===
    # è¿‡æ»¤æ‰ç©ºå€¼å‚æ•°ï¼Œé¿å…ç”Ÿæˆæ— æ•ˆç»„åˆ
    valid_items = [(k, _as_list(v)) for k, v in grid.items() if _as_list(v)]
    
    # è¾¹ç•Œæƒ…å†µï¼šæ‰€æœ‰å‚æ•°éƒ½ä¸ºç©º
    if not valid_items:
        return [fixed] if fixed else [{}]

    # åˆ†ç¦»å‚æ•°åå’Œå‚æ•°å€¼åˆ—è¡¨
    keys, values_lists = zip(*valid_items)

    # ç”Ÿæˆæ‰€æœ‰å‚æ•°çš„ç¬›å¡å°”ç§¯ç»„åˆï¼Œå¹¶åˆå¹¶å›ºå®šå‚æ•°
    return [{**fixed, **dict(zip(keys, combo))} 
            for combo in itertools.product(*values_lists)]

# parse_result_from_files å‡½æ•°å·²åˆ é™¤ï¼Œæ”¹ä¸ºç›´æ¥ä»è®­ç»ƒå‡½æ•°è·å–ç»“æœ


def save_results_to_csv(results, filename):
    """ä¿å­˜å®éªŒç»“æœåˆ°CSVæ–‡ä»¶
    
    è®¾è®¡æ€è·¯ï¼š
    å°†ç½‘æ ¼æœç´¢çš„æ‰€æœ‰å®éªŒç»“æœæ±‡æ€»åˆ°ä¸€ä¸ªCSVæ–‡ä»¶ä¸­ï¼Œä¾¿äºåç»­åˆ†æå’Œæ¯”è¾ƒã€‚
    é‡‡ç”¨æ ‡å‡†åŒ–çš„CSVæ ¼å¼ï¼Œç¡®ä¿æ•°æ®çš„å¯è¯»æ€§å’Œå¯å¤„ç†æ€§ã€‚
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    - è‡ªåŠ¨åˆ›å»ºrunsç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    - åŒ…å«å®Œæ•´çš„è¶…å‚æ•°ä¿¡æ¯å’Œè®­ç»ƒç»“æœ
    - ä½¿ç”¨UTF-8ç¼–ç ï¼Œæ”¯æŒä¸­æ–‡å­—ç¬¦
    - è‡ªåŠ¨å¤„ç†åµŒå¥—å‚æ•°çš„å±•å¹³
    
    Args:
        results (list[dict]): å®éªŒç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ï¼š
            - è¶…å‚æ•°å­—æ®µï¼ˆå¦‚model.type, hp.batch_sizeç­‰ï¼‰
            - best_accuracy: æœ€ä½³å‡†ç¡®ç‡
            - final_accuracy: æœ€ç»ˆå‡†ç¡®ç‡
            - exp_name: å®éªŒåç§°
        filename (str): CSVæ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
        
    Returns:
        str|None: ä¿å­˜çš„å®Œæ•´æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœresultsä¸ºç©ºåˆ™è¿”å›None
    
    CSVæ ¼å¼ï¼š
        åŒ…å«æ‰€æœ‰è¶…å‚æ•°åˆ—å’Œç»“æœåˆ—ï¼Œä¾¿äºExcelç­‰å·¥å…·æ‰“å¼€åˆ†æ
    """
    if not results:
        return None

    results_dir = "runs"
    os.makedirs(results_dir, exist_ok=True)
    filepath = os.path.join(results_dir, filename)

    # æ”¶é›†æ‰€æœ‰å‡ºç°è¿‡çš„å‚æ•°å­—æ®µ
    param_keys = sorted({k for r in results for k in r.get("params", {}).keys()})

    fieldnames = [
        "experiment_id", "exp_name", "success",
        "best_accuracy", "final_accuracy"
    ] + param_keys

    with open(filepath, "w", newline="", encoding="utf-8") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for i, r in enumerate(results, 1):
            row = {
                "experiment_id": f"{i:03d}",
                "exp_name": r.get("exp_name"),
                "success": r.get("success"),
                "best_accuracy": r.get("best_accuracy"),
                "final_accuracy": r.get("final_accuracy"),
            }
            row.update(r.get("params", {}))
            writer.writerow(row)

    return filepath


# å­è¿›ç¨‹å¯åŠ¨è¾…åŠ©å‡½æ•°å·²åˆ é™¤ï¼Œæ”¹ä¸ºè¿›ç¨‹å†…è°ƒç”¨æ–¹å¼


def apply_param_overrides(config, params):
    """åº”ç”¨å‚æ•°è¦†ç›–åˆ°é…ç½®å­—å…¸
    
    Args:
        config (dict): åŸºç¡€é…ç½®å­—å…¸
        params (dict): å‚æ•°è¦†ç›–å­—å…¸ï¼Œæ”¯æŒåµŒå¥—è·¯å¾„å¦‚ "hp.batch_size"
        
    Returns:
        dict: åº”ç”¨è¦†ç›–åçš„é…ç½®å­—å…¸
    """
    import copy
    config = copy.deepcopy(config)
    
    for k, v in (params or {}).items():
        # è§£æåµŒå¥—å‚æ•°è·¯å¾„ï¼Œå¦‚ "hp.batch_size" -> config["hp"]["batch_size"]
        keys = k.split('.')
        target = config
        for key in keys[:-1]:
            target = target.setdefault(key, {})
        target[keys[-1]] = v
    
    return config


def run_single_experiment(params, exp_id, use_multi_gpu=False, config_path="config/grid.yaml"):
    """è¿è¡Œå•ä¸ªå®éªŒï¼ˆè¿›ç¨‹å†…è°ƒç”¨æ–¹å¼ï¼‰
    
    è®¾è®¡æ€è·¯ï¼š
    æ”¹ä¸ºè¿›ç¨‹å†…ç›´æ¥è°ƒç”¨è®­ç»ƒå‡½æ•°ï¼Œé¿å…å­è¿›ç¨‹å¯åŠ¨å¼€é”€å’Œæ–‡ä»¶I/Oä¾èµ–ã€‚
    é€šè¿‡ç›´æ¥å‡½æ•°è°ƒç”¨è·å–è®­ç»ƒç»“æœï¼Œæé«˜æ•ˆç‡å’Œå¯é æ€§ã€‚
    
    Args:
        params (dict): å®éªŒå‚æ•°è¦†ç›–
        exp_id (str): å®éªŒID
        use_multi_gpu (bool): æ˜¯å¦ä½¿ç”¨å¤šGPUï¼ˆæš‚æ—¶å¿½ç•¥ï¼Œç”±Acceleratorè‡ªåŠ¨å¤„ç†ï¼‰
        config_path (str): é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        dict: å®éªŒç»“æœå­—å…¸
    """
    exp_name = f"grid_{exp_id}"

    print(f"{'='*60}")
    print(f"ğŸš€ å¼€å§‹å®éªŒ {exp_id}: {exp_name}")
    print(f"ğŸ“‹ å‚æ•°: {params}")
    print(f"{'='*60}")

    try:
        # å¯¼å…¥è®­ç»ƒå‡½æ•°
        from src.trainers.base_trainer import run_training
        
        # åŠ è½½åŸºç¡€é…ç½®
        config = load_grid_config(config_path)
        
        # åº”ç”¨å‚æ•°è¦†ç›–
        config = apply_param_overrides(config, params)
        
        # ç›´æ¥è°ƒç”¨è®­ç»ƒå‡½æ•°
        result = run_training(config, exp_name)
        
        # æ·»åŠ å‚æ•°ä¿¡æ¯åˆ°ç»“æœä¸­
        result["params"] = params
        
        print(f"âœ… å®éªŒ {exp_name} å®Œæˆï¼Œæœ€ä½³: {result['best_accuracy']:.2f}% | æœ€ç»ˆ: {result['final_accuracy']:.2f}%")
        
        return result
        
    except Exception as e:
        print(f"âŒ å®éªŒ {exp_name} å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "exp_name": exp_name,
            "params": params,
            "best_accuracy": 0.0,
            "final_accuracy": 0.0,
            "error": str(e)
        }


def run_grid_search(args):
    """è¿è¡Œç½‘æ ¼æœç´¢ï¼ˆä¸²è¡Œï¼Œç¡®ä¿èµ„æºå¹²å‡€é‡Šæ”¾ï¼‰"""
    config = load_grid_config(args.config)
    
    # å®éªŒå‚æ•°è¿›è¡Œç¬›å¡å°”ç§¯ç»„åˆ
    combinations = generate_combinations(config)

    # æˆªæ–­å®éªŒæ•°é‡
    if len(combinations) > args.max_experiments:
        combinations = combinations[:args.max_experiments]

    print(f"ğŸš€ å¼€å§‹ç½‘æ ¼æœç´¢ï¼Œå…± {len(combinations)} ä¸ªå®éªŒ")
    print(f"ğŸ“Š ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
    print(f"ğŸ¯ å¤šå¡è®­ç»ƒ: {'æ˜¯' if args.multi_gpu else 'å¦'}")
    print("=" * 60)

    results = []
    successful = 0

    for i, params in enumerate(combinations, 1):
        print(f"ğŸ“Š å‡†å¤‡å®éªŒ {i}/{len(combinations)}")

        result = run_single_experiment(
            params, f"{i:03d}",
            use_multi_gpu=args.multi_gpu,
            config_path=args.config, # è®­ç»ƒä½¿ç”¨çš„ç»Ÿä¸€é…ç½®
        )
        
        results.append(result)
        if result["success"]:
            successful += 1

        # é€‚å½“é—´éš”
        # time.sleep(1.0)

    # æ€»ç»“
    print("=" * 60)
    print(f"ğŸ“ˆ ç½‘æ ¼æœç´¢å®Œæˆï¼")
    print(f"âœ… æˆåŠŸå®éªŒæ•°é‡: {successful}/{len(combinations)}")

    if successful > 0:
        # ç­›é€‰å‡ºæ‰€æœ‰æˆåŠŸå®Œæˆçš„å®éªŒç»“æœ
        successful_results = [r for r in results if r["success"]]
        # æ‰¾åˆ°â€œæœ€ä½³å‡†ç¡®ç‡â€æœ€é«˜çš„å®éªŒç»“æœ
        best_result = max(successful_results, key=lambda x: x["best_accuracy"])

        print(f"ğŸ† æœ€ä½³å®éªŒç»“æœ:")
        print(f"å®éªŒåç§°: {best_result['exp_name']}, æœ€ä½³å‡†ç¡®ç‡: {best_result['best_accuracy']:.2f}%, æœ€ç»ˆå‡†ç¡®ç‡: {best_result['final_accuracy']:.2f}%")
        
        # æŒ‰æœ€ä½³ç²¾åº¦æ’åºå‰nç»„ç»“æœ
        top_results = sorted(successful_results, key=lambda x: x["best_accuracy"], reverse=True)[:args.top_n]
        
        print(f"ğŸ“Š å‰{args.top_n}åå®éªŒç»“æœ:")
        for i, r in enumerate(top_results, 1):
            print(f"{i}. {r['exp_name']} - {r['best_accuracy']:.2f}% - {r['params']}")

    if args.save_results:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_filename = f"grid_search_results_{timestamp}.csv"
        saved_filepath = save_results_to_csv(results, results_filename)
        if saved_filepath:
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {saved_filepath}")

    return 0 if successful > 0 else 1


def main():
    """ä¸»å‡½æ•°ï¼šè°ƒåº¦å™¨å§‹ç»ˆå•è¿›ç¨‹ï¼Œä¸è¿›å…¥ Accelerate ç¯å¢ƒ"""
    args, _ = parse_arguments(mode="grid_search")
    return run_grid_search(args)


if __name__ == "__main__":
    sys.exit(main())