"""ç½‘æ ¼æœç´¢å¯åŠ¨è„šæœ¬
æ”¯æŒå‚æ•°ç½‘æ ¼æœç´¢å’Œé¢„è®­ç»ƒæ¨¡å‹æœç´¢ï¼ˆæ–¹æ¡ˆ 1ï¼šå­è¿›ç¨‹ç»§æ‰¿ TTYï¼‰
"""

import itertools
import subprocess
import yaml
import os
import sys
import time
import csv
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.utils.config_parser import parse_arguments

def is_accelerate_environment():
    """æ£€æµ‹æ˜¯å¦å·²åœ¨accelerateç¯å¢ƒä¸­"""
    return os.environ.get('ACCELERATE_USE_DEEPSPEED') is not None or \
           os.environ.get('LOCAL_RANK') is not None or \
           os.environ.get('WORLD_SIZE') is not None

def launch_with_accelerate():
    """ä½¿ç”¨accelerate launché‡æ–°å¯åŠ¨å½“å‰è„šæœ¬"""
    # è·å–å½“å‰è„šæœ¬çš„æ‰€æœ‰å‚æ•°ï¼Œä½†ç§»é™¤--multi_gpu
    current_args = [arg for arg in sys.argv[1:] if arg != '--multi_gpu']
    
    # æ„å»ºaccelerate launchå‘½ä»¤
    cmd = ['accelerate', 'launch', sys.argv[0]] + current_args
    
    print(f"ğŸš€ å¯åŠ¨å¤šå¡ç½‘æ ¼æœç´¢: {' '.join(cmd)}")
    print("-" * 50)
    
    # æ‰§è¡Œaccelerate launchå‘½ä»¤
    result = subprocess.run(cmd)
    return result.returncode


# ----------------------------- å·¥å…·å‡½æ•° -----------------------------

def load_grid_config(path="config/grid.yaml"):
    """åŠ è½½ç½‘æ ¼æœç´¢é…ç½®"""
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}


def _as_list(v):
    """æŠŠæ ‡é‡åŒ…è£…æˆå•å…ƒç´ åˆ—è¡¨ï¼›åˆ—è¡¨åˆ™åŸæ ·è¿”å›ï¼›None åˆ™è¿”å›ç©ºåˆ—è¡¨"""
    if v is None:
        return []
    return v if isinstance(v, (list, tuple)) else [v]


def generate_combinations(config):
    """
    ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆï¼ˆæ›´é€šç”¨ï¼‰
    æ”¯æŒä¸‰ç§å†™æ³•ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰ï¼š
    1) grid_search.combinations: ç›´æ¥ç»™å‡ºç»„åˆåˆ—è¡¨ï¼ˆlist[dict]ï¼‰ï¼Œå°†è¢«åŸæ ·è¿”å›
    2) grid_search.grid: dict[str, list|scalar]ï¼Œåšç¬›å¡å°”ç§¯ï¼›æ ‡é‡ä¼šå½“ä½œå•å…ƒç´ åˆ—è¡¨
    3) è‹¥ä¸¤è€…éƒ½æ²¡æœ‰ï¼Œè¿”å› [{}]

    å¦å¤–ï¼š
    - grid_search.fixed: dictï¼Œå›ºå®šå‚æ•°ï¼Œä¼šå¹¶å…¥æ¯ä¸ªç»„åˆ
    - å…¼å®¹ 'model_type' â†’ 'model_name'
    """
    gs = (config or {}).get("grid_search", {})
    fixed = gs.get("fixed", {}) or {}

    # å†™æ³• 1ï¼šç›´æ¥æšä¸¾å¥½çš„ç»„åˆ
    combos = gs.get("combinations")
    if isinstance(combos, list) and all(isinstance(x, dict) for x in combos) and combos:
        results = []
        for d in combos:
            merged = {**fixed, **d}
            if "model_type" in merged and "model_name" not in merged:
                merged["model_name"] = merged.pop("model_type")
            results.append(merged)
        return results

    # å†™æ³• 2ï¼šç¬›å¡å°”ç§¯
    grid = gs.get("grid", {})
    if grid:
        keys = list(grid.keys())
        values_lists = [ _as_list(grid[k]) for k in keys ]
        if any(len(v) == 0 for v in values_lists):
            print("è­¦å‘Š: grid ä¸­å­˜åœ¨ç©ºåˆ—è¡¨ï¼Œå·²è·³è¿‡ç©ºå€¼é”®ã€‚")
            keys = [k for k, vals in zip(keys, values_lists) if len(vals) > 0]
            values_lists = [vals for vals in values_lists if len(vals) > 0]

        combos = []
        for combo in itertools.product(*values_lists) if values_lists else [()]:
            param_set = dict(zip(keys, combo))
            param_set = {**fixed, **param_set}
            if "model_type" in param_set and "model_name" not in param_set:
                param_set["model_name"] = param_set.pop("model_type")
            combos.append(param_set)

        if not combos:
            print("è­¦å‘Š: ç½‘æ ¼ä¸ºç©ºï¼Œä½¿ç”¨å›ºå®šå‚æ•°ã€‚")
            combos = [{**fixed}]
        return combos

    # é»˜è®¤è¿”å›ä¸€ä¸ªç©ºç»„åˆï¼ˆåªæœ‰ fixedï¼‰
    return [{**fixed}] if fixed else [{}]


def parse_result_from_files(exp_name):
    """ä»ç»“æ„åŒ–æ–‡ä»¶ä¸­è§£ææœ€ç»ˆç»“æœï¼ˆä¼˜å…ˆ result.jsonï¼Œå›é€€ metrics.jsonlï¼‰"""
    result_dir = os.path.join("runs", exp_name)
    final_json = os.path.join(result_dir, "result.json")
    metrics_path = os.path.join(result_dir, "metrics.jsonl")

    best_accuracy = 0.0
    final_accuracy = 0.0

    # ä¼˜å…ˆè¯»å– result.json
    if os.path.exists(final_json):
        try:
            with open(final_json, "r", encoding="utf-8") as f:
                data = json.load(f) or {}
                best_accuracy = float(data.get("best_accuracy", 0.0))
                final_accuracy = float(data.get("final_accuracy", best_accuracy))
                return best_accuracy, final_accuracy
        except Exception:
            pass

    # å›é€€ï¼šæ‰«æ metrics.jsonlï¼Œå–æœ€å¤§ val_acc ä½œä¸º bestï¼Œæœ€åä¸€æ¡ val_acc ä½œä¸º final
    if os.path.exists(metrics_path):
        try:
            last_val = None
            best_val = 0.0
            with open(metrics_path, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        rec = json.loads(line)
                        va = rec.get("val_acc")
                        if isinstance(va, (int, float)):
                            last_val = float(va)
                            if last_val > best_val:
                                best_val = last_val
                    except Exception:
                        continue
            if last_val is not None:
                return best_val, last_val
        except Exception:
            pass

    return best_accuracy, final_accuracy


def save_results_to_csv(results, filename):
    """ä¿å­˜å®éªŒç»“æœåˆ°CSVæ–‡ä»¶ï¼ˆç»Ÿä¸€ä¿å­˜åˆ°runsç›®å½•ï¼‰"""
    if not results:
        return None

    # ç»Ÿä¸€ä½¿ç”¨runsç›®å½•ï¼Œé¿å…é‡å¤
    results_dir = "runs"
    os.makedirs(results_dir, exist_ok=True)
    filepath = os.path.join(results_dir, filename)

    # æ”¶é›†æ‰€æœ‰å‡ºç°è¿‡çš„å‚æ•°å­—æ®µ
    param_keys = sorted({k for r in results for k in r.get("params", {}).keys()})

    fieldnames = [
        "experiment_id", "experiment_name", "success",
        "best_accuracy", "final_accuracy"
    ] + param_keys

    with open(filepath, "w", newline="", encoding="utf-8") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for i, r in enumerate(results, 1):
            row = {
                "experiment_id": f"{i:03d}",
                "experiment_name": r.get("exp_name"),
                "success": r.get("success"),
                "best_accuracy": r.get("best_accuracy"),
                "final_accuracy": r.get("final_accuracy"),
            }
            row.update(r.get("params", {}))
            writer.writerow(row)

    return filepath


# ----------------------------- æ ¸å¿ƒé€»è¾‘ -----------------------------

def run_single_experiment(params, exp_id, use_multi_gpu=False):
    """è¿è¡Œå•ä¸ªå®éªŒï¼ˆå­è¿›ç¨‹ç»§æ‰¿ TTYï¼Œä¸æ•è·è¾“å‡ºï¼‰"""
    exp_name = f"grid_{exp_id}"

    # æ„å»ºè®­ç»ƒå‘½ä»¤ï¼ˆä¸å†ä¼  --is_grid_searchï¼Œé¿å… base_trainer ç¦ç”¨ tqdmï¼‰
    cmd = [
        sys.executable, "-u",
        "scripts/train.py",
        "--config", "config/unified.yaml",
        "--experiment_name", exp_name,
    ]

    # æ·»åŠ å‚æ•°
    for k, v in (params or {}).items():
        cmd.extend([f"--{k}", str(v)])

    # æ³¨æ„ï¼šä¸å†ä¼ é€’--multi_gpuå‚æ•°ç»™å­è¿›ç¨‹
    # å› ä¸ºå¦‚æœéœ€è¦å¤šå¡è®­ç»ƒï¼Œçˆ¶è¿›ç¨‹å·²ç»é€šè¿‡accelerate launchå¯åŠ¨äº†

    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹å®éªŒ {exp_id}: {exp_name}")
    print(f"ğŸ“‹ å‚æ•°: {params}")
    print(f"{'='*60}")

    # è®©å­è¿›ç¨‹ç›´æ¥ç»§æ‰¿çˆ¶è¿›ç¨‹ç»ˆç«¯ï¼ˆTTYï¼‰ï¼Œä»¥ä¾¿ tqdm åŒè¡Œåˆ·æ–°
    process = subprocess.Popen(cmd)
    rc = process.wait()
    success = (rc == 0)

    # è§£æè®­ç»ƒç»“æœï¼ˆä»…è¯»æ–‡ä»¶ï¼‰
    best_accuracy, final_accuracy = parse_result_from_files(exp_name)

    if success:
        if best_accuracy == 0.0 and final_accuracy == 0.0:
            print(f"âš ï¸  {exp_name} ç»“æŸï¼Œä½†æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ã€‚è¯·æ£€æŸ¥ runs/{exp_name}/ æ˜¯å¦ç”Ÿæˆ result.json æˆ– metrics.jsonlã€‚")
        else:
            print(f"âœ… å®éªŒ {exp_name} å®Œæˆï¼Œæœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}% | æœ€ç»ˆ: {final_accuracy:.2f}%")
    else:
        print(f"âŒ å®éªŒ {exp_name} å¤±è´¥ï¼ˆè¿”å›ç  {rc}ï¼‰ã€‚å»ºè®®æŸ¥çœ‹ runs/{exp_name}/ åŠæ§åˆ¶å°è¾“å‡ºå®šä½é—®é¢˜ã€‚")

    return {
        "success": success,
        "exp_name": exp_name,
        "params": params,
        "best_accuracy": best_accuracy,
        "final_accuracy": final_accuracy,
    }


def run_grid_search(args):
    """è¿è¡Œç½‘æ ¼æœç´¢"""
    config = load_grid_config(args.config)
    combinations = generate_combinations(config)

    # æˆªæ–­å®éªŒæ•°é‡
    if len(combinations) > args.max_experiments:
        combinations = combinations[:args.max_experiments]

    print(f"\nğŸš€ å¼€å§‹ç½‘æ ¼æœç´¢ï¼Œå…± {len(combinations)} ä¸ªå®éªŒ")
    print(f"ğŸ“Š ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
    print(f"ğŸ¯ å¤šå¡è®­ç»ƒ: {'æ˜¯' if args.multi_gpu else 'å¦'}")
    print("=" * 60)

    results = []
    successful = 0

    for i, params in enumerate(combinations, 1):
        print(f"\nğŸ“Š å‡†å¤‡å®éªŒ {i}/{len(combinations)}")
        result = run_single_experiment(params, f"{i:03d}", args.multi_gpu)
        results.append(result)
        if result["success"]:
            successful += 1
        # ç»™å‡ºè§†è§‰åˆ†éš”
        time.sleep(0.5)

    # æ€»ç»“
    print("\n" + "=" * 60)
    print(f"ğŸ“ˆ ç½‘æ ¼æœç´¢å®Œæˆï¼")
    print(f"âœ… æˆåŠŸå®éªŒ: {successful}/{len(combinations)}")

    if successful > 0:
        successful_results = [r for r in results if r["success"]]
        best_result = max(successful_results, key=lambda x: x["best_accuracy"])

        print(f"\nğŸ† æœ€ä½³å®éªŒç»“æœ:")
        print(f"   å®éªŒåç§°: {best_result['exp_name']}")
        print(f"   æœ€ä½³å‡†ç¡®ç‡: {best_result['best_accuracy']:.2f}%")
        print(f"   æœ€ç»ˆå‡†ç¡®ç‡: {best_result['final_accuracy']:.2f}%")
        print(f"   æœ€ä¼˜å‚æ•°:")
        for key, value in best_result["params"].items():
            print(f"     {key}: {value}")

        top_results = sorted(successful_results, key=lambda x: x["best_accuracy"], reverse=True)[:3]
        print(f"\nğŸ“Š å‰3åå®éªŒç»“æœ:")
        for i, r in enumerate(top_results, 1):
            print(f"   {i}. {r['exp_name']} - {r['best_accuracy']:.2f}% - {r['params']}")

    if args.save_results:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_filename = f"grid_search_results_{timestamp}.csv"
        saved_filepath = save_results_to_csv(results, results_filename)
        if saved_filepath:
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {saved_filepath}")

    return 0 if successful > 0 else 1


def main():
    """ä¸»å‡½æ•°"""
    args, _ = parse_arguments(mode="grid_search")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦å¯åŠ¨å¤šå¡è®­ç»ƒ
    if args.multi_gpu and not is_accelerate_environment():
        # å¦‚æœæŒ‡å®šäº†å¤šå¡è®­ç»ƒä½†ä¸åœ¨accelerateç¯å¢ƒä¸­ï¼Œé‡æ–°å¯åŠ¨
        return launch_with_accelerate()
    
    return run_grid_search(args)


if __name__ == "__main__":
    sys.exit(main())
