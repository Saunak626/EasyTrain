"""
åŸºç¡€è®­ç»ƒå™¨æ¨¡å—

æä¾›ç»Ÿä¸€çš„è®­ç»ƒæ¥å£ï¼Œæ”¯æŒå›¾åƒå’Œè§†é¢‘åˆ†ç±»ä»»åŠ¡ã€‚
é›†æˆAccelerateåº“å®ç°å¤šGPUè®­ç»ƒå’ŒSwanLabå®éªŒè¿½è¸ªã€‚
"""

import os
import sys
import torch
import numpy as np
from typing import Dict, Any, Tuple, Optional

from tqdm import tqdm
from accelerate import Accelerator

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

# å¯¼å…¥é¡¹ç›®å†…éƒ¨æ¨¡å—
from src.models.image_net import get_model                     # å›¾åƒæ¨¡å‹å·¥å‚å‡½æ•°
from src.models.video_net import get_video_model               # è§†é¢‘æ¨¡å‹å·¥å‚å‡½æ•°
from src.losses.loss_factory import get_loss_function          # æŸå¤±å‡½æ•°å·¥å‚å‡½æ•°
from src.optimizers.optimizer_factory import get_optimizer     # ä¼˜åŒ–å™¨å·¥å‚å‡½æ•°
from src.schedules.scheduler_factory import get_scheduler      # å­¦ä¹ ç‡è°ƒåº¦å™¨å·¥å‚å‡½æ•°
from src.datasets import create_dataloaders, get_dataset_info  # ç»Ÿä¸€æ•°æ®åŠ è½½å™¨å·¥å‚
from src.utils.data_utils import set_seed
from src.utils.training_logger import TrainingLogger           # è®­ç»ƒæ—¥å¿—ç®¡ç†å™¨
from src.utils.dataset_utils import unwrap_subset_dataset, get_dataset_metadata  # æ•°æ®é›†å·¥å…·å‡½æ•°
from src.utils.training_utils import log_multilabel_metrics_to_swanlab, get_learning_rate_info  # è®­ç»ƒå·¥å…·å‡½æ•°

# ============================================================================
# æ¨¡å—çº§å¸¸é‡é…ç½®
# ============================================================================

# è®­ç»ƒç›¸å…³å¸¸é‡
TRAINING_CONSTANTS = {
    'default_seed': 42,
    'default_num_workers': 8,
    'progress_update_interval': 10,
    'model_size_bytes_per_param': 4,  # float32
    'bytes_to_mb': 1024 * 1024
}

# æ”¯æŒçš„ä»»åŠ¡ç±»å‹é…ç½®
SUPPORTED_TASKS = {
    'image_classification': {
        'description': 'å›¾åƒåˆ†ç±»ä»»åŠ¡',
        'supported_datasets': ['cifar10', 'custom'],
        'model_factory': 'get_model',
        'default_model': 'resnet18'
    },
    'video_classification': {
        'description': 'è§†é¢‘åˆ†ç±»ä»»åŠ¡',
        'supported_datasets': ['ucf101', 'ucf101_video', 'neonatal_multilabel'],
        'model_factory': 'get_video_model',
        'default_model': 'r3d_18'
    }
}

# ============================================================================
# è¿›åº¦æ¡ç®¡ç†ç±»
# ============================================================================

class ProgressBarManager:
    """ç»Ÿä¸€çš„è¿›åº¦æ¡ç®¡ç†å™¨

    è´Ÿè´£åˆ›å»ºå’Œç®¡ç†è®­ç»ƒã€æµ‹è¯•é˜¶æ®µçš„è¿›åº¦æ¡ï¼Œé¿å…é‡å¤çš„è¿›åº¦æ¡åˆ›å»ºé€»è¾‘ã€‚
    """

    def __init__(self, accelerator: Accelerator):
        """åˆå§‹åŒ–è¿›åº¦æ¡ç®¡ç†å™¨

        Args:
            accelerator: Acceleratorå®ä¾‹ï¼Œç”¨äºæ£€æŸ¥æ˜¯å¦ä¸ºä¸»è¿›ç¨‹
        """
        self.accelerator = accelerator

    def create_training_progress_bar(self, dataloader, epoch: int) -> Optional[tqdm]:
        """åˆ›å»ºè®­ç»ƒè¿›åº¦æ¡

        Args:
            dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            epoch: å½“å‰epochç¼–å·

        Returns:
            è¿›åº¦æ¡å®ä¾‹ï¼Œå¦‚æœä¸æ˜¯ä¸»è¿›ç¨‹åˆ™è¿”å›None
        """
        if self.accelerator.is_main_process:
            return tqdm(
                total=len(dataloader),
                desc=f"Epoch {epoch} Training",
                unit="batch",
                dynamic_ncols=True,
                leave=False,
            )
        return None

    def create_testing_progress_bar(self, dataloader, epoch: int) -> Optional[tqdm]:
        """åˆ›å»ºæµ‹è¯•è¿›åº¦æ¡

        Args:
            dataloader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            epoch: å½“å‰epochç¼–å·

        Returns:
            è¿›åº¦æ¡å®ä¾‹ï¼Œå¦‚æœä¸æ˜¯ä¸»è¿›ç¨‹åˆ™è¿”å›None
        """
        if self.accelerator.is_main_process:
            return tqdm(
                total=len(dataloader),
                desc=f"Epoch {epoch} Testing",
                unit="batch",
                dynamic_ncols=True,
                leave=False,
            )
        return None


# ============================================================================
# æ ¸å¿ƒè®­ç»ƒå‡½æ•°
# ============================================================================

def train_epoch(dataloader, model, loss_fn, optimizer, lr_scheduler, accelerator, epoch,
                metrics_calculator=None, scheduler_step_interval='batch'):
    """æ‰§è¡Œå•ä¸ªè®­ç»ƒè½®æ¬¡

    Args:
        dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        model: ç¥ç»ç½‘ç»œæ¨¡å‹
        loss_fn: æŸå¤±å‡½æ•°
        optimizer: ä¼˜åŒ–å™¨
        lr_scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        accelerator: Acceleratorå®ä¾‹
        epoch: å½“å‰è½®æ¬¡ç¼–å·
        metrics_calculator: å¤šæ ‡ç­¾æŒ‡æ ‡è®¡ç®—å™¨ï¼ˆå¯é€‰ï¼‰

    Returns:
        tuple: (å¹³å‡è®­ç»ƒæŸå¤±, è®­ç»ƒå‡†ç¡®ç‡)
    """
    model.train()
    total_loss = 0.0
    num_batches = 0

    # ğŸ”§ æ–°å¢ï¼šæ”¶é›†è®­ç»ƒæ•°æ®ç”¨äºæŒ‡æ ‡è®¡ç®—
    collected_outputs = []
    collected_targets = []
    is_multilabel = metrics_calculator is not None

    # ä½¿ç”¨ç»Ÿä¸€çš„è¿›åº¦æ¡ç®¡ç†å™¨
    progress_manager = ProgressBarManager(accelerator)
    progress_bar = progress_manager.create_training_progress_bar(dataloader, epoch)

    for batch_idx, (inputs, targets) in enumerate(dataloader):
        outputs = model(inputs)
        loss = loss_fn(outputs, targets)

        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()
        if lr_scheduler is not None and scheduler_step_interval == 'batch':
            lr_scheduler.step()

        total_loss += loss.item()
        num_batches += 1

        # ğŸ”§ æ–°å¢ï¼šæ”¶é›†é¢„æµ‹å’Œç›®æ ‡æ•°æ®ï¼ˆç”¨äºè®­ç»ƒé›†æŒ‡æ ‡è®¡ç®—ï¼‰
        if is_multilabel:
            collected_outputs.append(outputs.detach())
            collected_targets.append(targets.detach())

        accelerator.log({"train/loss": loss.item(), "epoch_num": epoch})

        # æ›´æ–°è¿›åº¦æ¡
        if progress_bar and batch_idx % TRAINING_CONSTANTS['progress_update_interval'] == 0:
            current_lr = optimizer.param_groups[0]['lr']
            avg_loss = total_loss / num_batches
            progress_bar.set_postfix(
                loss=f"{avg_loss:.4f}",
                lr=f"{current_lr:.2e}"
            )

        if progress_bar:
            progress_bar.update(1)

    # å…³é—­è¿›åº¦æ¡
    if progress_bar:
        progress_bar.close()

    # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
    avg_train_loss = total_loss / num_batches if num_batches > 0 else 0.0

    if lr_scheduler is not None and scheduler_step_interval == 'epoch':
        lr_scheduler.step()

    # ğŸ”§ æ–°å¢ï¼šè®¡ç®—è®­ç»ƒé›†æŒ‡æ ‡ï¼ˆå¦‚æœæ˜¯å¤šæ ‡ç­¾ä»»åŠ¡ï¼‰
    train_accuracy = 0.0
    if is_multilabel and collected_outputs:
        stacked_outputs = torch.cat(collected_outputs, dim=0)
        stacked_targets = torch.cat(collected_targets, dim=0)

        gathered_outputs = accelerator.gather_for_metrics(stacked_outputs)
        gathered_targets = accelerator.gather_for_metrics(stacked_targets)

        if accelerator.is_main_process:
            probs = torch.sigmoid(gathered_outputs).cpu().numpy()
            targets_np = gathered_targets.cpu().numpy()

            # è®¡ç®—è®­ç»ƒé›†è¯¦ç»†æŒ‡æ ‡
            train_metrics = metrics_calculator.calculate_detailed_metrics(
                probs, targets_np, threshold=0.5
            )

            # ä¿å­˜è®­ç»ƒé›†æŒ‡æ ‡åˆ°å•ç‹¬çš„CSVæ–‡ä»¶
            metrics_calculator.save_train_metrics(train_metrics, epoch, avg_train_loss)

            # è®°å½•è®­ç»ƒé›†æŒ‡æ ‡åˆ°SwanLabï¼ˆä½¿ç”¨ç»Ÿä¸€çš„è¾…åŠ©å‡½æ•°ï¼‰
            log_multilabel_metrics_to_swanlab(accelerator, train_metrics, 'train', epoch)

            train_accuracy = train_metrics['macro_avg']['accuracy']

    return avg_train_loss, train_accuracy


def test_epoch(dataloader, model, loss_fn, accelerator, epoch, train_batches=None,
               metrics_calculator=None):
    """
    æ‰§è¡Œå•ä¸ªæµ‹è¯•è½®æ¬¡

    è¯¥å‡½æ•°åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œè®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡ã€‚
    æ”¯æŒå¤šGPUç¯å¢ƒä¸‹çš„æŒ‡æ ‡èšåˆï¼Œç¡®ä¿ç»“æœçš„å‡†ç¡®æ€§ã€‚
    æ”¯æŒè¯¦ç»†çš„å¤šæ ‡ç­¾åˆ†ç±»æŒ‡æ ‡è®¡ç®—å’ŒæŠ¥å‘Šã€‚

    Args:
        dataloader (torch.utils.data.DataLoader): æµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼Œæä¾›æµ‹è¯•æ‰¹æ¬¡æ•°æ®
        model (torch.nn.Module): ç¥ç»ç½‘ç»œæ¨¡å‹
        loss_fn (torch.nn.Module): æŸå¤±å‡½æ•°ï¼Œç”¨äºè®¡ç®—æµ‹è¯•æŸå¤±
        accelerator (accelerate.Accelerator): Acceleratorå®ä¾‹ï¼Œå¤„ç†å¤šGPUæŒ‡æ ‡èšåˆ
        epoch (int): å½“å‰æµ‹è¯•è½®æ¬¡ç¼–å·
        train_batches (int, optional): è®­ç»ƒæ‰¹æ¬¡æ•°ï¼Œç”¨äºæ—¥å¿—æ˜¾ç¤º
        metrics_calculator (MultilabelMetricsCalculator, optional): å¤šæ ‡ç­¾æŒ‡æ ‡è®¡ç®—å™¨

    Returns:
        tuple: (å¹³å‡æŸå¤±, å‡†ç¡®ç‡ç™¾åˆ†æ¯”) æˆ– (None, None) å¦‚æœä¸æ˜¯ä¸»è¿›ç¨‹
    """
    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œç¦ç”¨dropoutå’Œbatch normalizationçš„è®­ç»ƒè¡Œä¸º
    model.eval()
    device = accelerator.device

    # åˆå§‹åŒ–ç´¯è®¡æŒ‡æ ‡å¼ é‡ï¼Œç”¨äºè·¨GPUèšåˆ
    local_loss_sum = torch.tensor(0.0, device=device)  # å½“å‰GPUçš„æ€»æŸå¤±
    local_correct = torch.tensor(0, device=device)     # å½“å‰GPUçš„æ­£ç¡®é¢„æµ‹æ•°
    local_samples = torch.tensor(0, device=device)     # å½“å‰GPUçš„æ ·æœ¬æ€»æ•°

    # ç”¨äºè¯¦ç»†å¤šæ ‡ç­¾è¯„ä¼°çš„æ•°æ®æ”¶é›†
    all_predictions = []
    all_targets = []
    is_multilabel = False

    # ä½¿ç”¨ç»Ÿä¸€çš„è¿›åº¦æ¡ç®¡ç†å™¨
    progress_manager = ProgressBarManager(accelerator)
    progress_bar = progress_manager.create_testing_progress_bar(dataloader, epoch)

    # ç¦ç”¨æ¢¯åº¦è®¡ç®—ä»¥èŠ‚çœå†…å­˜å’ŒåŠ é€Ÿæ¨ç†
    with torch.no_grad():
        for inputs, targets in dataloader:
            # å‰å‘ä¼ æ’­è·å–é¢„æµ‹ç»“æœ
            outputs = model(inputs)
            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„æŸå¤±
            loss = loss_fn(outputs, targets)

            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„ç»Ÿè®¡ä¿¡æ¯
            batch_size = targets.size(0)

            # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ ‡ç­¾åˆ†ç±»ï¼ˆæ ‡ç­¾ç»´åº¦å¤§äº1ä¸”åŒ…å«æµ®ç‚¹æ•°ï¼‰
            is_multilabel = len(targets.shape) > 1 and targets.shape[1] > 1 and targets.dtype == torch.float32

            if is_multilabel:
                # å¤šæ ‡ç­¾åˆ†ç±»ï¼šä½¿ç”¨æ¯ç±»åˆ«å¹³å‡å‡†ç¡®ç‡
                sigmoid_outputs = torch.sigmoid(outputs)
                predictions = sigmoid_outputs > 0.5
                targets_bool = targets.bool()

                # æ”¶é›†é¢„æµ‹å’Œç›®æ ‡æ•°æ®ç”¨äºè¯¦ç»†è¯„ä¼°
                if metrics_calculator is not None:
                    # æ”¶é›†sigmoidæ¦‚ç‡å’ŒçœŸå®æ ‡ç­¾
                    all_predictions.append(sigmoid_outputs.cpu().numpy())
                    all_targets.append(targets.cpu().numpy())

                # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡ï¼Œç„¶åå¹³å‡ï¼ˆå®å¹³å‡ï¼‰
                class_accuracies = (predictions == targets_bool).float().mean(dim=0)
                macro_accuracy = class_accuracies.mean()
                # è½¬æ¢ä¸ºæ­£ç¡®æ ·æœ¬æ•°ï¼ˆç”¨äºå…¼å®¹ç°æœ‰ç»Ÿè®¡é€»è¾‘ï¼‰ï¼Œç¡®ä¿ç±»å‹ä¸ºLong
                correct = (macro_accuracy * batch_size).long()
            else:
                # å•æ ‡ç­¾åˆ†ç±»ï¼šä½¿ç”¨argmax
                correct = outputs.argmax(dim=1).eq(targets).sum()

            # ç´¯åŠ åˆ°æœ¬åœ°ç»Ÿè®¡é‡ï¼ˆè€ƒè™‘æ‰¹æ¬¡å¤§å°æƒé‡ï¼‰
            local_loss_sum += loss * batch_size
            local_correct += correct
            local_samples += batch_size

            # æ›´æ–°è¿›åº¦æ¡
            if progress_bar:
                progress_bar.update(1)

    # å…³é—­è¿›åº¦æ¡
    if progress_bar:
        progress_bar.close()

    # è·¨æ‰€æœ‰GPUè¿›ç¨‹èšåˆç»Ÿè®¡æŒ‡æ ‡
    total_loss = accelerator.reduce(local_loss_sum, reduction="sum")
    total_correct = accelerator.reduce(local_correct, reduction="sum")
    total_samples = accelerator.reduce(local_samples, reduction="sum")

    # åªåœ¨ä¸»è¿›ç¨‹è®¡ç®—æœ€ç»ˆæŒ‡æ ‡å¹¶è®°å½•
    if accelerator.is_main_process:
        # è®¡ç®—å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
        avg_loss = (total_loss / total_samples).item()
        accuracy = 100. * total_correct.item() / total_samples.item()

        # å¦‚æœæœ‰å¤šæ ‡ç­¾æŒ‡æ ‡è®¡ç®—å™¨ä¸”æ”¶é›†äº†æ•°æ®ï¼Œè¿›è¡Œè¯¦ç»†è¯„ä¼°
        if metrics_calculator is not None and all_predictions and is_multilabel:
            # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„é¢„æµ‹å’Œç›®æ ‡
            all_pred_array = np.concatenate(all_predictions, axis=0)
            all_target_array = np.concatenate(all_targets, axis=0)

            # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
            detailed_metrics = metrics_calculator.calculate_detailed_metrics(
                all_pred_array, all_target_array, threshold=0.5
            )

            # æ›´æ–°æœ€ä½³æŒ‡æ ‡ï¼ˆä¼ é€’é¢„æµ‹å’Œç›®æ ‡æ•°ç»„ç”¨äºè§†é¢‘çº§åˆ«æŠ¥å‘Šï¼‰
            is_best = metrics_calculator.update_best_metrics(
                detailed_metrics, epoch,
                predictions=all_pred_array,
                targets=all_target_array
            )

            # ä¿å­˜æŒ‡æ ‡ï¼ˆä¿æŒåŸæœ‰åŠŸèƒ½ï¼‰
            metrics_calculator.save_metrics(detailed_metrics, epoch, avg_loss, is_best)

            # ğŸ”§ æ–°å¢ï¼šä¿å­˜æµ‹è¯•é›†æŒ‡æ ‡åˆ°å•ç‹¬çš„CSVæ–‡ä»¶
            metrics_calculator.save_test_metrics(detailed_metrics, epoch, avg_loss)

            # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
            detailed_display = metrics_calculator.format_metrics_display(
                detailed_metrics, epoch, avg_loss, train_batches or 0
            )
            tqdm.write(detailed_display)

            if is_best:
                tqdm.write(f"ğŸ† æ–°æœ€ä½³å®å¹³å‡F1åˆ†æ•°: {detailed_metrics['macro_avg']['f1']:.4f}")

            # è®°å½•è¯¦ç»†æŒ‡æ ‡åˆ°å®éªŒè¿½è¸ªç³»ç»Ÿï¼ˆä½¿ç”¨ç»Ÿä¸€çš„è¾…åŠ©å‡½æ•°ï¼‰
            accelerator.log({"test/loss": avg_loss}, step=epoch)
            log_multilabel_metrics_to_swanlab(accelerator, detailed_metrics, 'test', epoch)
        else:
            # æ ‡å‡†è¾“å‡ºï¼ˆå•æ ‡ç­¾æˆ–æ— è¯¦ç»†è¯„ä¼°ï¼‰
            log_msg = f'Epoch {epoch:03d} | val_loss={avg_loss:.4f} | val_acc={accuracy:.2f}%'
            if train_batches is not None:
                log_msg += f' | train_batches={train_batches}'
            tqdm.write(log_msg)

            # è®°å½•æµ‹è¯•æŒ‡æ ‡åˆ°å®éªŒè¿½è¸ªç³»ç»Ÿ
            accelerator.log({"test/loss": avg_loss, "test/accuracy": accuracy}, step=epoch)

        return avg_loss, accuracy

    # éä¸»è¿›ç¨‹è¿”å›None
    return None, None


# ============================================================================
# è®­ç»ƒæµç¨‹æ‹†åˆ†å‡½æ•°
# ============================================================================

def setup_experiment(config: Dict[str, Any], exp_name: Optional[str] = None) -> Tuple[str, Dict[str, Any], str, Dict[str, Any], Accelerator]:
    """å®éªŒç¯å¢ƒåˆå§‹åŒ–

    è´Ÿè´£è®¾ç½®éšæœºç§å­ã€è§£æä»»åŠ¡é…ç½®ã€éªŒè¯æ•°æ®é›†å…¼å®¹æ€§ï¼Œå¹¶åˆå§‹åŒ–Acceleratorå’ŒSwanLabè¿½è¸ªã€‚

    Args:
        config: åŒ…å«æ‰€æœ‰è®­ç»ƒé…ç½®çš„å­—å…¸
        exp_name: å®éªŒåç§°ï¼Œç”¨äºè¿½è¸ªå’Œæ—¥å¿—è®°å½•

    Returns:
        Tuple[å®éªŒåç§°, ä»»åŠ¡ä¿¡æ¯, ä»»åŠ¡æ ‡ç­¾, æ•°æ®é…ç½®, Acceleratorå®ä¾‹]

    Raises:
        ValueError: å½“ä»»åŠ¡ç±»å‹ä¸æ”¯æŒæˆ–æ•°æ®é›†ä¸å…¼å®¹æ—¶
    """
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å®éªŒå¯é‡ç°æ€§
    set_seed(TRAINING_CONSTANTS['default_seed'])

    # å®éªŒåç§°ï¼Œä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‡½æ•°çš„å‚æ•°
    if exp_name is None:
        exp_name = config['training']['exp_name']

    # è§£æä»»åŠ¡é…ç½®
    task_config = config.get('task', {})
    task_tag = task_config.get('tag')

    # éªŒè¯ä»»åŠ¡ç±»å‹å¿…é¡»æ˜ç¡®æŒ‡å®š
    if not task_tag:
        raise ValueError(f"å¿…é¡»åœ¨é…ç½®æ–‡ä»¶ä¸­æ˜ç¡®æŒ‡å®štask.tagã€‚æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {list(SUPPORTED_TASKS.keys())}")

    if task_tag not in SUPPORTED_TASKS:
        raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_tag}ã€‚æ”¯æŒçš„ä»»åŠ¡: {list(SUPPORTED_TASKS.keys())}")

    task_info = SUPPORTED_TASKS[task_tag]

    # è§£æå’ŒéªŒè¯æ•°æ®é…ç½®
    data_config = config.get('data', {})
    dataset_type = data_config.get('type', 'cifar10')

    # éªŒè¯æ•°æ®é›†ä¸ä»»åŠ¡çš„å…¼å®¹æ€§
    if dataset_type not in task_info['supported_datasets']:
        raise ValueError(f"ä»»åŠ¡ '{task_tag}' ä¸æ”¯æŒæ•°æ®é›† '{dataset_type}'ã€‚"
                        f"æ”¯æŒçš„æ•°æ®é›†: {task_info['supported_datasets']}")

    # åˆå§‹åŒ–Acceleratorï¼ŒæŒ‡å®šswanlabä¸ºæ—¥å¿—è®°å½•å·¥å…·
    accelerator = Accelerator(log_with="swanlab")

    # è®°å½•åˆ°SwanLabçš„è¶…å‚æ•°
    hyperparams = config['hp']
    tracker_config = {**hyperparams, "exp_name": exp_name, "task_tag": task_tag}

    # åˆå§‹åŒ–SwanLabå®éªŒè¿½è¸ªå™¨
    accelerator.init_trackers(
        project_name=config['swanlab']['project_name'],  # SwanLab UIä¸­é¡¹ç›®åç§°
        config=tracker_config,    # è¦è®°å½•çš„è¶…å‚æ•°
        init_kwargs={             # é¢å¤–åˆå§‹åŒ–å‚æ•°
            "swanlab": {
                "exp_name": exp_name,
                "description": config['swanlab']['description']
            }
        }
    )

    return exp_name, task_info, task_tag, data_config, accelerator


def setup_data_and_model(config: Dict[str, Any], task_info: Dict[str, Any], data_config: Dict[str, Any], accelerator: Accelerator) -> Tuple:
    """æ•°æ®å’Œæ¨¡å‹åˆå§‹åŒ–

    è´Ÿè´£åˆ›å»ºæ•°æ®åŠ è½½å™¨ã€è·å–æ•°æ®é›†ä¿¡æ¯ã€åˆ›å»ºæ¨¡å‹ã€‚

    Args:
        config: å®Œæ•´é…ç½®å­—å…¸
        task_info: ä»»åŠ¡ä¿¡æ¯å­—å…¸
        data_config: æ•°æ®é…ç½®å­—å…¸
        accelerator: Acceleratorå®ä¾‹

    Returns:
        Tuple[è®­ç»ƒæ•°æ®åŠ è½½å™¨, æµ‹è¯•æ•°æ®åŠ è½½å™¨, æ¨¡å‹, æ•°æ®é›†ä¿¡æ¯]
    """
    # è·å–è¶…å‚æ•°å’Œæ¨¡å‹é…ç½®
    hyperparams = config['hp']
    model_config = config.get('model', {})
    dataset_type = data_config.get('type', 'cifar10')
    model_name = model_config.get('type', model_config.get('name', task_info['default_model']))

    # ä½¿ç”¨ç®€åŒ–çš„æ•°æ®åŠ è½½å™¨åˆ›å»ºå‡½æ•°
    train_dataloader, test_dataloader, num_classes = create_dataloaders(
        dataset_name=dataset_type,
        data_dir=data_config.get('root', './data'),
        batch_size=hyperparams['batch_size'],
        num_workers=data_config.get('num_workers', TRAINING_CONSTANTS['default_num_workers']),
        model_type=model_name,  # ä¼ é€’æ¨¡å‹ç±»å‹ç”¨äºåŠ¨æ€transforms
        data_percentage=hyperparams.get('data_percentage', 1.0),
        **data_config.get('params', {})
    )

    # è·å–æ•°æ®é›†ä¿¡æ¯
    dataset_info = get_dataset_info(dataset_type)
    dataset_info['num_classes'] = num_classes or dataset_info['num_classes']

    # ğŸ”§ ä½¿ç”¨ç»Ÿä¸€çš„å…ƒæ•°æ®è·å–å‡½æ•°ï¼ˆæ”¯æŒSubsetåŒ…è£…çš„æ•°æ®é›†ï¼‰
    # ä»å®é™…æ•°æ®é›†å®ä¾‹è·å–ç±»åˆ«åç§°ã€ç±»åˆ«æ•°é‡å’Œå¤šæ ‡ç­¾æ ‡å¿—
    metadata = get_dataset_metadata(train_dataloader.dataset, dataset_type)

    # æ›´æ–° dataset_infoï¼ˆä¼˜å…ˆä½¿ç”¨ä»æ•°æ®é›†è·å–çš„å…ƒæ•°æ®ï¼‰
    if metadata['num_classes'] is not None:
        dataset_info['num_classes'] = metadata['num_classes']
    if metadata['classes'] is not None:
        dataset_info['classes'] = metadata['classes']
    dataset_info['is_multilabel'] = metadata['is_multilabel']

    # åŸºäºä»»åŠ¡ç±»å‹åˆ›å»ºæ¨¡å‹
    model_factory_name = task_info['model_factory']
    model_factory = globals()[model_factory_name]

    # ç»Ÿä¸€çš„æ¨¡å‹åˆ›å»ºé€»è¾‘
    model_params = model_config.get('params', {}).copy()
    model_params['num_classes'] = dataset_info['num_classes']

    model = model_factory(
        model_type=model_name,
        **model_params
    )

    return train_dataloader, test_dataloader, model, dataset_info


def setup_training_components(config: Dict[str, Any], model, train_dataloader,
                             accelerator: Accelerator, logger: TrainingLogger,
                             dataset_info: Dict[str, Any]) -> Tuple:
    """ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ã€æŸå¤±å‡½æ•°åˆå§‹åŒ–

    è´Ÿè´£åˆ›å»ºæŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œå¹¶ä½¿ç”¨AcceleratoråŒ…è£…æ‰€æœ‰ç»„ä»¶ã€‚

    Args:
        config: å®Œæ•´é…ç½®å­—å…¸
        model: å·²åˆ›å»ºçš„æ¨¡å‹
        train_dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        accelerator: Acceleratorå®ä¾‹
        logger: è®­ç»ƒæ—¥å¿—ç®¡ç†å™¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯å­—å…¸ï¼ˆåŒ…å« num_classes, classes, is_multilabel ç­‰ï¼‰

    Returns:
        Tuple[æŸå¤±å‡½æ•°, ä¼˜åŒ–å™¨, å­¦ä¹ ç‡è°ƒåº¦å™¨]
    """
    hyperparams = config['hp']

    # åˆ›å»ºæŸå¤±å‡½æ•° - ä½¿ç”¨å·¥å‚å‡½æ•°ï¼Œä¼ é€’ç±»åˆ«æ•°é‡ä¿¡æ¯
    loss_config = config.get('loss', {}).copy()

    # ğŸ”§ ä¿®å¤ï¼šä¸ºæ‰€æœ‰å¤šæ ‡ç­¾æŸå¤±å‡½æ•°æ·»åŠ ç±»åˆ«æ•°é‡ä¿¡æ¯
    multilabel_loss_types = [
        'multilabel_bce',
        'focal_multilabel_bce',
        'focal_multilabel_balanced',
        'multilabel_focal_balanced'
    ]

    loss_name = loss_config.get('name') or loss_config.get('type')
    if loss_name in multilabel_loss_types:
        # ğŸ”§ ä½¿ç”¨ dataset_info ä¸­çš„ç±»åˆ«æ•°é‡ï¼ˆé¿å…é‡å¤è·å–ï¼‰
        num_classes = dataset_info.get('num_classes')

        # å‘åå…¼å®¹ï¼šå¦‚æœ dataset_info ä¸­æ²¡æœ‰ç±»åˆ«æ•°é‡ï¼Œä»æ¨¡å‹é…ç½®è·å–
        if num_classes is None:
            num_classes = config.get('model', {}).get('params', {}).get('num_classes', 24)

        if 'params' not in loss_config:
            loss_config['params'] = {}
        loss_config['params']['num_classes'] = num_classes

        # ğŸ”§ æ–°å¢ï¼šåŠ¨æ€è®¡ç®—pos_weightï¼ˆé«˜ä¼˜å…ˆçº§ä¿®å¤ï¼‰
        # å¦‚æœé…ç½®ä¸­æŒ‡å®šäº†pos_weightä½†æ˜¯æ ‡é‡å€¼ï¼Œåˆ™æ ¹æ®è®­ç»ƒé›†ç»Ÿè®¡åŠ¨æ€è®¡ç®—
        config_pos_weight = loss_config.get('params', {}).get('pos_weight', None)
        if config_pos_weight is not None and isinstance(config_pos_weight, (int, float)):
            #  ä½¿ç”¨è¾…åŠ©å‡½æ•°è§£åŒ… Subset æ•°æ®é›†
            dataset = unwrap_subset_dataset(train_dataloader.dataset)

            # ğŸ”§ ä¼˜åŒ–ï¼šç›´æ¥ä»æ•°æ®é›†çš„sampleså±æ€§è¯»å–æ ‡ç­¾ï¼Œé¿å…åŠ è½½å›¾åƒæ•°æ®
            # æ”¶é›†æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„æ ‡ç­¾
            all_labels = []

            # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦æœ‰sampleså±æ€§ï¼ˆNeonatalMultilabelDatasetæœ‰ï¼‰
            if hasattr(dataset, 'samples'):
                # ç›´æ¥ä»samplesè¯»å–æ ‡ç­¾ï¼Œé¿å…åŠ è½½å›¾åƒ
                for sample in dataset.samples:
                    labels = sample['labels']
                    if isinstance(labels, list):
                        labels = torch.tensor(labels, dtype=torch.float32)
                    elif not isinstance(labels, torch.Tensor):
                        labels = torch.tensor(labels, dtype=torch.float32)
                    all_labels.append(labels)
            else:
                # é™çº§æ–¹æ¡ˆï¼šéå†DataLoaderï¼ˆè¾ƒæ…¢ï¼‰
                for batch_idx, (_, targets) in enumerate(train_dataloader):
                    all_labels.append(targets.cpu())
                    # åªé‡‡æ ·éƒ¨åˆ†æ•°æ®ä»¥åŠ å¿«è®¡ç®—ï¼ˆæœ€å¤š1000ä¸ªbatchï¼‰
                    if batch_idx >= 1000:
                        break

            if all_labels:
                all_labels = torch.stack(all_labels) if isinstance(all_labels[0], torch.Tensor) and all_labels[0].dim() == 1 else torch.cat(all_labels, dim=0)
                pos_counts = all_labels.sum(dim=0)  # æ¯ä¸ªç±»åˆ«çš„æ­£æ ·æœ¬æ•°
                total_samples = all_labels.shape[0]
                neg_counts = total_samples - pos_counts  # æ¯ä¸ªç±»åˆ«çš„è´Ÿæ ·æœ¬æ•°

                # ğŸ”§ ä¼˜åŒ–ï¼šä½¿ç”¨è‡ªé€‚åº”ç¼©æ”¾è®¡ç®—pos_weightï¼Œé¿å…æç«¯å€¼
                # åŸå§‹å…¬å¼: pos_weight = neg_samples / pos_samples
                # é—®é¢˜: å¯¹äºæåº¦ç¨€æœ‰çš„ç±»åˆ«ä¼šäº§ç”Ÿæå¤§çš„æƒé‡(å¦‚51.36)ï¼Œå¯¼è‡´æ¨¡å‹è¿‡åº¦é¢„æµ‹æ­£ç±»
                #
                # æ–°å…¬å¼: è‡ªé€‚åº”ç¼©æ”¾ç­–ç•¥
                # - å¯¹äºè½»åº¦ä¸å¹³è¡¡(ratio < 5): pos_weight = sqrt(ratio) * 0.8
                # - å¯¹äºä¸­åº¦ä¸å¹³è¡¡(5 <= ratio < 20): pos_weight = sqrt(ratio) * 0.6
                # - å¯¹äºæåº¦ä¸å¹³è¡¡(ratio >= 20): pos_weight = sqrt(ratio) * 0.4
                #
                # ä¼˜ç‚¹:
                #   1. å¯¹äºæåº¦ç¨€æœ‰çš„ç±»åˆ«ä½¿ç”¨æ›´æ¿€è¿›çš„é™æƒï¼Œé¿å…è¿‡åº¦é¢„æµ‹
                #   2. å¯¹äºè½»åº¦ä¸å¹³è¡¡çš„ç±»åˆ«ä¿æŒè¾ƒé«˜æƒé‡ï¼Œç¡®ä¿å­¦ä¹ æ•ˆæœ
                #   3. ä¾‹å¦‚: å‘è„¾æ°”(ratio=51.36) -> sqrt(51.36) * 0.4 â‰ˆ 2.87
                raw_ratio = neg_counts / (pos_counts + 1e-6)

                # è‡ªé€‚åº”ç¼©æ”¾å› å­
                scale_factor = torch.where(
                    raw_ratio < 5.0,
                    torch.tensor(0.8, device=raw_ratio.device),  # è½»åº¦ä¸å¹³è¡¡
                    torch.where(
                        raw_ratio < 20.0,
                        torch.tensor(0.6, device=raw_ratio.device),  # ä¸­åº¦ä¸å¹³è¡¡
                        torch.tensor(0.4, device=raw_ratio.device)   # æåº¦ä¸å¹³è¡¡
                    )
                )

                pos_weight = torch.sqrt(raw_ratio) * scale_factor

                # é™åˆ¶pos_weightçš„èŒƒå›´ï¼Œé¿å…æç«¯å€¼
                pos_weight = torch.clamp(pos_weight, min=1.0, max=5.0)

                loss_config['params']['pos_weight'] = pos_weight

                # æ‰“å°æ‘˜è¦ä¿¡æ¯
                logger.print_pos_weight_summary(total_samples, num_classes)

    loss_fn = get_loss_function(loss_config)

    # åˆ›å»ºä¼˜åŒ–å™¨ - ä½¿ç”¨å·¥å‚å‡½æ•°
    optimizer = get_optimizer(model, config.get('optimizer', {}), hyperparams['learning_rate'])

    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½¿ç”¨å·¥å‚å‡½æ•°
    # éœ€è¦ä¼ é€’steps_per_epochç»™è°ƒåº¦å™¨
    scheduler_config = config.get('scheduler', {}).copy()
    if 'steps_per_epoch' not in scheduler_config:
        scheduler_config['steps_per_epoch'] = len(train_dataloader)

    lr_scheduler = get_scheduler(optimizer, scheduler_config, hyperparams)

    scheduler_name = (scheduler_config.get('name') or scheduler_config.get('type') or '').lower()
    scheduler_step_interval = scheduler_config.get('step_interval')
    if scheduler_step_interval is None:
        scheduler_step_interval = 'batch' if scheduler_name in ['onecycle'] else 'epoch'

    return loss_fn, optimizer, lr_scheduler, scheduler_step_interval


def get_task_output_dir(task_tag: str, dataset_type: str) -> str:
    """æ ¹æ®ä»»åŠ¡ç±»å‹è·å–è¾“å‡ºç›®å½•

    Args:
        task_tag: ä»»åŠ¡æ ‡ç­¾
        dataset_type: æ•°æ®é›†ç±»å‹

    Returns:
        ä»»åŠ¡å¯¹åº”çš„è¾“å‡ºç›®å½•è·¯å¾„
    """
    # åŸºç¡€è¾“å‡ºç›®å½•
    base_dir = "runs"

    # æ ¹æ®ä»»åŠ¡ç±»å‹ç¡®å®šå­ç›®å½•å
    if 'multilabel' in task_tag.lower() or 'multilabel' in dataset_type.lower():
        if 'neonatal' in dataset_type.lower():
            task_subdir = "neonatal_multilabel"
        else:
            task_subdir = "multilabel_classification"
    elif 'video' in task_tag.lower():
        task_subdir = "video_classification"
    elif 'image' in task_tag.lower():
        task_subdir = "image_classification"
    else:
        # é»˜è®¤ä½¿ç”¨æ•°æ®é›†ç±»å‹ä½œä¸ºå­ç›®å½•å
        task_subdir = dataset_type.replace('_', '_').lower() or "general"

    output_dir = os.path.join(base_dir, task_subdir)

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)

    return output_dir


def run_training_loop(config: Dict[str, Any], model, optimizer, lr_scheduler, loss_fn,
                     train_dataloader, test_dataloader, accelerator: Accelerator, logger: TrainingLogger,
                     metrics_calculator=None, scheduler_step_interval='batch') -> Tuple[float, float, int]:
    """ä¸»è®­ç»ƒå¾ªç¯

    è´Ÿè´£æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒå¾ªç¯ï¼ŒåŒ…æ‹¬è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µã€‚

    Args:
        config: å®Œæ•´é…ç½®å­—å…¸
        model: å·²å‡†å¤‡çš„æ¨¡å‹
        optimizer: å·²å‡†å¤‡çš„ä¼˜åŒ–å™¨
        lr_scheduler: å·²å‡†å¤‡çš„å­¦ä¹ ç‡è°ƒåº¦å™¨
        loss_fn: æŸå¤±å‡½æ•°
        train_dataloader: å·²å‡†å¤‡çš„è®­ç»ƒæ•°æ®åŠ è½½å™¨
        test_dataloader: å·²å‡†å¤‡çš„æµ‹è¯•æ•°æ®åŠ è½½å™¨
        accelerator: Acceleratorå®ä¾‹
        logger: è®­ç»ƒæ—¥å¿—ç®¡ç†å™¨
        metrics_calculator: å¤šæ ‡ç­¾æŒ‡æ ‡è®¡ç®—å™¨ï¼ˆå¯é€‰ï¼‰
        scheduler_step_interval: è°ƒåº¦å™¨æ­¥è¿›é—´éš”ï¼ˆ'batch' æˆ– 'epoch'ï¼‰

    Returns:
        Tuple[æœ€ä½³å‡†ç¡®ç‡, æœ€ç»ˆå‡†ç¡®ç‡, è®­ç»ƒè½®æ•°]
    """
    hyperparams = config['hp']
    scheduler_config = config.get('scheduler', {})
    initial_lr = hyperparams['learning_rate']

    # åˆå§‹åŒ–æœ€ä½³å‡†ç¡®ç‡è¿½è¸ª
    best_accuracy = 0.0
    trained_epochs = 0
    val_accuracy = 0.0

    # metrics_calculator ç°åœ¨ä½œä¸ºå‚æ•°ä¼ å…¥

    # ä¸»è®­ç»ƒå¾ªç¯ï¼šæ‰§è¡ŒæŒ‡å®šè½®æ•°çš„è®­ç»ƒ
    for epoch in range(1, hyperparams['epochs'] + 1):
        if accelerator.is_main_process:
            # æ‰“å°epochå¼€å§‹æ—¶çš„å­¦ä¹ ç‡ä¿¡æ¯
            lr_info = get_learning_rate_info(optimizer, lr_scheduler, scheduler_config, initial_lr)
            logger.print_learning_rate_info(lr_info, epoch, hyperparams['epochs'], "å¼€å§‹")

        # è®­ç»ƒepochï¼ˆä¼ é€’metrics_calculatorç”¨äºè®­ç»ƒé›†æŒ‡æ ‡è®¡ç®—ï¼‰
        train_loss, train_accuracy = train_epoch(
            train_dataloader,
            model,
            loss_fn,
            optimizer,
            lr_scheduler,
            accelerator,
            epoch,
            metrics_calculator,
            scheduler_step_interval
        )
        # æµ‹è¯•epoch
        _, val_accuracy = test_epoch(test_dataloader, model, loss_fn, accelerator, epoch,
                                   train_batches=len(train_dataloader),
                                   metrics_calculator=metrics_calculator)

        # æ‰“å°epochç»“æŸæ—¶çš„å­¦ä¹ ç‡ä¿¡æ¯
        if accelerator.is_main_process:
            lr_info = get_learning_rate_info(optimizer, lr_scheduler, scheduler_config, initial_lr)
            logger.print_learning_rate_info(lr_info, epoch, hyperparams['epochs'], "ç»“æŸ")

        # æ›´æ–°å¹¶è®°å½•æœ€ä½³å‡†ç¡®ç‡
        if accelerator.is_main_process and val_accuracy > best_accuracy:
            best_accuracy = val_accuracy
            tqdm.write(f"æ–°æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")

        # è®°å½•å®Œæˆçš„è®­ç»ƒè½®æ•°
        trained_epochs = epoch

    # è®­ç»ƒç»“æŸåæ˜¾ç¤ºæ€»ç»“æŠ¥å‘Š
    if accelerator.is_main_process and metrics_calculator is not None:
        summary_report = metrics_calculator.get_summary_report()
        tqdm.write(summary_report)

    return best_accuracy, val_accuracy, trained_epochs


def cleanup_and_return(accelerator: Accelerator, exp_name: str, best_accuracy: float,
                      val_accuracy: float, trained_epochs: int, tracker_config: Dict[str, Any],
                      metrics_calculator=None) -> Dict[str, Any]:
    """æ¸…ç†å’Œç»“æœè¿”å›

    è´Ÿè´£ç»“æŸå®éªŒè¿½è¸ªã€æ¸…ç†GPUç¼“å­˜å¹¶è¿”å›è®­ç»ƒç»“æœã€‚

    Args:
        accelerator: Acceleratorå®ä¾‹
        exp_name: å®éªŒåç§°
        best_accuracy: æœ€ä½³å‡†ç¡®ç‡
        val_accuracy: æœ€ç»ˆå‡†ç¡®ç‡
        trained_epochs: è®­ç»ƒè½®æ•°
        tracker_config: è¿½è¸ªé…ç½®
        metrics_calculator: å¤šæ ‡ç­¾æŒ‡æ ‡è®¡ç®—å™¨

    Returns:
        è®­ç»ƒç»“æœå­—å…¸
    """
    # ç»“æŸå®éªŒè¿½è¸ªï¼Œä¿å­˜æ—¥å¿—å’Œç»“æœ
    accelerator.end_training()

    # è¾“å‡ºè®­ç»ƒå®Œæˆä¿¡æ¯
    if accelerator.is_main_process:
        tqdm.write(f"è®­ç»ƒå®Œæˆ! æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")

    # æ¸…ç†GPUç¼“å­˜ï¼Œä¸ºä¸‹ä¸€ä¸ªå®éªŒé‡Šæ”¾èµ„æº
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # å‡†å¤‡è¿”å›ç»“æœ
    result = {
        "success": True,                       # è®­ç»ƒæˆåŠŸæ ‡å¿—
        "exp_name": exp_name,                  # å®éªŒåç§°
        "best_accuracy": best_accuracy,        # æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡
        "final_accuracy": val_accuracy,        # æœ€ç»ˆå‡†ç¡®ç‡
        "trained_epochs": trained_epochs,      # å®é™…è®­ç»ƒè½®æ•°
        "config": tracker_config               # å®Œæ•´çš„è®­ç»ƒé…ç½®
    }

    # å¦‚æœæœ‰å¤šæ ‡ç­¾æŒ‡æ ‡è®¡ç®—å™¨ï¼Œæ·»åŠ è¯¦ç»†çš„å¤šæ ‡ç­¾æŒ‡æ ‡
    if metrics_calculator is not None:
        best_metrics = metrics_calculator.best_metrics

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æŒ‡æ ‡æ•°æ®ï¼ˆé€šè¿‡æ£€æŸ¥macro_avgæ˜¯å¦ä¸ºç©ºå­—å…¸ï¼‰
        has_valid_metrics = (
            best_metrics.get("macro_avg") and
            isinstance(best_metrics.get("macro_avg"), dict) and
            len(best_metrics.get("macro_avg", {})) > 0
        )

        if has_valid_metrics:
            # è·å–æœ€æ–°çš„æŒ‡æ ‡ï¼ˆæœ€åä¸€æ¬¡è¯„ä¼°çš„ç»“æœï¼‰
            latest_metrics = None
            if metrics_calculator.metrics_history:
                latest_metrics = metrics_calculator.metrics_history[-1]

            multilabel_metrics = {
                "best": {
                    "macro_accuracy": best_metrics.get("macro_avg", {}).get("accuracy"),
                    "micro_accuracy": best_metrics.get("micro_avg", {}).get("accuracy"),
                    "weighted_accuracy": best_metrics.get("weighted_avg", {}).get("accuracy"),
                    "macro_f1": best_metrics.get("macro_avg_f1"),
                    "micro_f1": best_metrics.get("micro_avg", {}).get("f1"),
                    "weighted_f1": best_metrics.get("weighted_avg", {}).get("f1"),
                    "macro_precision": best_metrics.get("macro_avg", {}).get("precision"),
                    "macro_recall": best_metrics.get("macro_avg", {}).get("recall"),
                    "epoch": best_metrics.get("epoch")
                }
            }

            # æ·»åŠ æœ€ç»ˆæŒ‡æ ‡
            if latest_metrics:
                multilabel_metrics["final"] = {
                    "macro_accuracy": latest_metrics.get("macro_avg", {}).get("accuracy"),
                    "micro_accuracy": latest_metrics.get("micro_avg", {}).get("accuracy"),
                    "weighted_accuracy": latest_metrics.get("weighted_avg", {}).get("accuracy"),
                    "macro_f1": latest_metrics.get("macro_avg", {}).get("f1"),
                    "micro_f1": latest_metrics.get("micro_avg", {}).get("f1"),
                    "weighted_f1": latest_metrics.get("weighted_avg", {}).get("f1"),
                }

            result["multilabel_metrics"] = multilabel_metrics

            # ä¸ºç½‘æ ¼æœç´¢è¯¦æƒ…è¡¨æ·»åŠ å®Œæ•´çš„è¯¦ç»†æŒ‡æ ‡
            result["detailed_metrics"] = best_metrics
        else:
            # æ²¡æœ‰æœ‰æ•ˆæŒ‡æ ‡æ•°æ®æ—¶çš„è­¦å‘Š
            if accelerator.is_main_process:
                tqdm.write("âš ï¸ å¤šæ ‡ç­¾æŒ‡æ ‡è®¡ç®—å™¨æœªæ”¶é›†åˆ°æœ‰æ•ˆæ•°æ®ï¼Œå¯èƒ½æ˜¯è®­ç»ƒæœªæ­£å¸¸æ‰§è¡Œæˆ–æ•°æ®é›†ä¸ºç©º")

    return result


def run_training(config: Dict[str, Any], exp_name: Optional[str] = None) -> Dict[str, Any]:
    """
    è®­ç»ƒçš„ä¸»å…¥å£å‡½æ•°ï¼Œè´Ÿè´£æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„åè°ƒï¼ŒåŒ…æ‹¬ï¼š
    - ç¯å¢ƒåˆå§‹åŒ–ï¼ˆéšæœºç§å­ã€å®éªŒè¿½è¸ªï¼‰
    - æ•°æ®åŠ è½½å™¨åˆ›å»º
    - æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨åˆå§‹åŒ–
    - å¤šGPUç¯å¢ƒé…ç½®
    - è®­ç»ƒå¾ªç¯æ‰§è¡Œ
    - ç»“æœè®°å½•å’Œè¿”å›

    Args:
        config: åŒ…å«æ‰€æœ‰è®­ç»ƒé…ç½®çš„å­—å…¸ï¼ŒåŒ…æ‹¬æ¨¡å‹ã€æ•°æ®ã€è¶…å‚æ•°ç­‰è®¾ç½®
        exp_name: å®éªŒåç§°ï¼Œç”¨äºè¿½è¸ªå’Œæ—¥å¿—è®°å½•

    Returns:
        è®­ç»ƒç»“æœå­—å…¸ï¼ŒåŒ…å«å®éªŒåç§°ã€æœ€ä½³å‡†ç¡®ç‡å’Œé…ç½®ä¿¡æ¯
    """
    # ç¬¬1æ­¥ï¼šå®éªŒç¯å¢ƒåˆå§‹åŒ–
    exp_name, task_info, task_tag, data_config, accelerator = setup_experiment(config, exp_name)

    # åˆ›å»ºè®­ç»ƒæ—¥å¿—ç®¡ç†å™¨
    logger = TrainingLogger(accelerator)

    # ç¬¬2æ­¥ï¼šæ•°æ®å’Œæ¨¡å‹åˆå§‹åŒ–
    train_dataloader, test_dataloader, model, dataset_info = setup_data_and_model(config, task_info, data_config, accelerator)

    # ç¬¬3æ­¥ï¼šè®­ç»ƒç»„ä»¶åˆå§‹åŒ–
    loss_fn, optimizer, lr_scheduler, scheduler_step_interval = setup_training_components(
        config, model, train_dataloader, accelerator, logger, dataset_info
    )

    # æ¸…ç†GPUç¼“å­˜ï¼Œé‡Šæ”¾æœªä½¿ç”¨çš„å†…å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    # ä½¿ç”¨AcceleratoråŒ…è£…è®­ç»ƒç»„ä»¶ï¼Œè‡ªåŠ¨å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒ
    model, optimizer, lr_scheduler, train_dataloader, test_dataloader = accelerator.prepare(
        model, optimizer, lr_scheduler, train_dataloader, test_dataloader
    )

    # ç¬¬4æ­¥ï¼šåˆ›å»ºå¤šæ ‡ç­¾æŒ‡æ ‡è®¡ç®—å™¨ï¼ˆå¦‚æœæ˜¯å¤šæ ‡ç­¾ä»»åŠ¡ï¼‰
    metrics_calculator = None
    task_config = config.get('task', {})
    task_tag = task_config.get('tag', '')
    dataset_type = config.get('data', {}).get('type', '')

    # æ£€æµ‹å¤šæ ‡ç­¾ä»»åŠ¡ï¼šé€šè¿‡dataset_typeï¼ˆä¸»è¦ï¼‰æˆ–task_tag
    is_multilabel_task = ('multilabel' in dataset_type.lower() or
                         'multilabel' in task_tag.lower())

    if is_multilabel_task:
        from src.evaluation import MultilabelMetricsCalculator

        # ä»setup_data_and_modelè¿”å›çš„dataset_infoè·å–ç±»åˆ«åç§°
        class_names = dataset_info.get('classes', [])

        if class_names:
            # æ ¹æ®ä»»åŠ¡ç±»å‹åˆ›å»ºå¯¹åº”çš„è¾“å‡ºç›®å½•
            task_dir = get_task_output_dir(task_tag, dataset_type)

            # ä¼˜å…ˆä½¿ç”¨grid_search_dirï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤çš„task_dir
            output_dir = config.get('grid_search_dir', task_dir)

            # è·å–æµ‹è¯•æ•°æ®é›†ï¼ˆç”¨äºè§†é¢‘çº§åˆ«æŠ¥å‘Šï¼‰
            test_dataset = test_dataloader.dataset

            # æå–model_typeï¼šä¼˜å…ˆä»model.typeè·å–ï¼Œå…¶æ¬¡å›é€€åˆ°hp.model_type
            model_type = config.get('model', {}).get(
                'type',
                config.get('hp', {}).get('model_type', 'unknown')
            )

            metrics_calculator = MultilabelMetricsCalculator(
                class_names=class_names,
                output_dir=output_dir,
                dataset=test_dataset,
                model_type=model_type,
                exp_name=exp_name
            )
        else:
            if accelerator.is_main_process:
                tqdm.write(f"âš ï¸ å¤šæ ‡ç­¾ä»»åŠ¡æ£€æµ‹æˆåŠŸï¼Œä½†æœªè·å–åˆ°ç±»åˆ«åç§°")

    # ç¬¬5æ­¥ï¼šæ‰“å°å®éªŒä¿¡æ¯
    logger.print_experiment_info_full(config, exp_name, task_info, dataset_info, model, train_dataloader, test_dataloader)

    # ç¬¬6æ­¥ï¼šæ‰§è¡Œè®­ç»ƒå¾ªç¯
    best_accuracy, val_accuracy, trained_epochs = run_training_loop(
        config, model, optimizer, lr_scheduler, loss_fn, train_dataloader, test_dataloader, accelerator, logger, metrics_calculator, scheduler_step_interval
    )

    # ç¬¬7æ­¥ï¼šæ¸…ç†å’Œè¿”å›ç»“æœ
    hyperparams = config['hp']
    tracker_config = {**hyperparams, "exp_name": exp_name, "task_tag": task_tag}

    return cleanup_and_return(accelerator, exp_name, best_accuracy, val_accuracy, trained_epochs, tracker_config, metrics_calculator)
