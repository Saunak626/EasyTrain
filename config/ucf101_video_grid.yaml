# UCF-101视频分类网格搜索配置
# 用于搜索最佳的视频模型和超参数组合

# 任务配置
task:
  tag: "video_classification"
  description: "UCF-101视频分类网格搜索"

# 训练配置
training:
  exp_name: "ucf101_grid_exp"
  save_model: true
  model_save_path: "models/video_model.pth"

# SwanLab配置
swanlab:
  project_name: "EasyTrain-Video-Grid"
  description: "UCF-101视频分类网格搜索实验"

# 数据配置
data:
  type: ucf101_video  # 使用新的视频帧数据集类型
  root: data/ucf101   # 数据集根目录
  num_workers: 12      # 数据加载工作进程数
  params:
    clip_len: 16      # 每个视频片段的帧数

# 模型配置（仅保留必要的基础参数）
model:
  params:
    num_classes: 101  # UCF-101有101个动作类别

# 超参数配置（基础默认值，可被网格搜索和命令行覆盖）
hp:
  epochs: 10         # 训练轮数（固定值，不参与网格搜索）
  # data_percentage 由命令行参数控制，不在此设置默认值

# GPU配置
gpu:
  device_ids: "2,3"
  auto_select: true

# 多卡训练配置
multi_gpu:
  enabled: true
  strategy: "ddp"

# 模型选择配置
models_to_train:
  # 启用要训练的模型列表，注释掉不需要训练的模型
  # - "r3d_18"
  # - "mc3_18"
  # - "r2plus1d_18"
  # - "s3d"
  - "mvit_v1_b"
  - "mvit_v2_s"
  - "swin3d_b"
  - "swin3d_s"
  - "swin3d_t"
  # 可选的其他模型（当前已注释）

# 网格搜索设置
max_experiments: 100
continue_on_error: true
parallel_jobs: 1
save_results: true
results_file: "video_grid_search_results.csv"

# 网格搜索超参数 - 分组式配置
grid_search:
  # 分组式搜索：每组模型有自己的超参数搜索范围
  groups:
    # 轻量级3D CNN模型组 - 使用统一batch_size
    light_3d_cnn:
      model.type: ["r3d_18", "mc3_18", "r2plus1d_18"]
      hp.batch_size: [128]  # 统一batch_size，会自动扩充为 [128, 128, 128]
      hp.learning_rate: [0.001]
      optimizer.name: ["adam"]
      optimizer.params.weight_decay: [0.0001]
      scheduler.name: ["cosine"]
      loss.name: ["crossentropy"]
    
    # 复杂3D CNN模型组 - 单模型，多batch_size选择
    complex_3d_cnn:
      model.type: ["s3d"]
      hp.batch_size: [128]  # S3D需要小batch_size
      hp.learning_rate: [0.01]  # 测试不同学习率
      optimizer.name: ["adam"]  # S3D用Adam即可
      optimizer.params.weight_decay: [0.0001]  # 适中的权重衰减
      scheduler.name: ["cosine"]  # cosine和step调度
      loss.name: ["crossentropy"]
    
    # Transformer模型组 - 精确配对batch_size，使用适合的调度策略
    transformer_models:
      model.type: ["mvit_v1_b", "mvit_v2_s"]
      hp.batch_size: [36, 32]  # 按顺序配对：mvit_v1_b用36，mvit_v2_s用32
      hp.learning_rate: [0.001]  # 降低学习率，更稳定
      optimizer.name: ["adamw"]  # Transformer首选AdamW
      optimizer.params.weight_decay: [0.01]  # 适中的权重衰减
      scheduler.name: ["cosine"]  # 首选linear decay，次选cosine
      loss.name: ["crossentropy"]
    
    # Swin3D模型组 - 精确配对batch_size，使用适合的调度策略
    swin3d_models:
      model.type: ["swin3d_b", "swin3d_s", "swin3d_t"]
      hp.batch_size: [16, 16, 16]  # 按顺序配对：swin3d_b用4，swin3d_s用8，swin3d_t用16
      hp.learning_rate: [0.001, 0.0001]  # 保守的学习率
      optimizer.name: ["adamw"]  # Swin系列推荐AdamW
      optimizer.params.weight_decay: [0.01, 0.05]  # Swin系列用更大的weight_decay
      scheduler.name: ["cosine"]  # 首选linear decay，次选cosine
      loss.name: ["crossentropy"]

  # # 兼容旧格式的grid配置（如果groups不存在时使用）
  # grid:
  #   model.type: ["r3d_18", "mc3_18", "r2plus1d_18", "s3d", "mvit_v1_b", "mvit_v2_s", "swin3d_b", "swin3d_s", "swin3d_t"]
  #   hp.batch_size: [128, 128, 128, 128, 36, 32, 16, 16, 16]
  #   hp.learning_rate: [0.001]
  #   optimizer.name: ["adam"]
  #   optimizer.params.weight_decay: [0.0001]
  #   scheduler.name: ["cosine"]
  #   loss.name: ["crossentropy"]