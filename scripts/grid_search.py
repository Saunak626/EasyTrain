"""ç½‘æ ¼æœç´¢å¯åŠ¨è„šæœ¬

è®¾è®¡æ€è·¯ï¼š
æœ¬è„šæœ¬é‡‡ç”¨è°ƒåº¦å™¨-æ‰§è¡Œå™¨åˆ†ç¦»çš„æ¶æ„è®¾è®¡ï¼Œå®ç°äº†é«˜æ•ˆã€ç¨³å®šçš„è¶…å‚æ•°ç½‘æ ¼æœç´¢ã€‚
æ ¸å¿ƒè®¾è®¡åŸåˆ™åŒ…æ‹¬ï¼š
- è¿›ç¨‹éš”ç¦»ï¼šè°ƒåº¦å™¨ä¿æŒå•è¿›ç¨‹è¿è¡Œï¼Œæ¯ä¸ªå®éªŒç‹¬ç«‹å¯åŠ¨å­è¿›ç¨‹ï¼Œç¡®ä¿èµ„æºå¹²å‡€é‡Šæ”¾
- å¤šæ¨¡å¼æ”¯æŒï¼šæ”¯æŒå•å¡/CPUå’Œå¤šå¡åˆ†å¸ƒå¼è®­ç»ƒï¼Œè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å¯åŠ¨æ–¹å¼
- ç¯å¢ƒéš”ç¦»ï¼šä¸ºæ¯ä¸ªå®éªŒè®¾ç½®ç‹¬ç«‹çš„åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ï¼Œé¿å…è¿›ç¨‹é—´ä¸²æ‰°
- çµæ´»é…ç½®ï¼šæ”¯æŒç¬›å¡å°”ç§¯å’Œç‰¹æ®Šé…å¯¹æ¨¡å¼çš„å‚æ•°ç»„åˆç”Ÿæˆ
- ç»“æœç®¡ç†ï¼šè‡ªåŠ¨è§£æå®éªŒç»“æœï¼Œç”Ÿæˆç»“æ„åŒ–çš„CSVæŠ¥å‘Š

æ ¸å¿ƒåŠŸèƒ½ï¼š
- generate_combinations: æ™ºèƒ½å‚æ•°ç»„åˆç”Ÿæˆï¼Œæ”¯æŒå¤šç§ç»„åˆç­–ç•¥
- run_single_experiment: å•å®éªŒæ‰§è¡Œå™¨ï¼Œå¤„ç†è¿›ç¨‹å¯åŠ¨å’Œç»“æœæ”¶é›†
- run_grid_search: ç½‘æ ¼æœç´¢è°ƒåº¦å™¨ï¼Œåè°ƒæ•´ä¸ªæœç´¢æµç¨‹
- parse_result_from_files: ç»“æœè§£æå™¨ï¼Œä»å¤šç§æ ¼å¼ä¸­æå–è®­ç»ƒæŒ‡æ ‡
- save_results_to_csv: ç»“æœæŒä¹…åŒ–ï¼Œç”Ÿæˆä¾¿äºåˆ†æçš„CSVæŠ¥å‘Š

ç‰¹æ®Šå¤„ç†ï¼š
- ç«¯å£ç®¡ç†ï¼šä¸ºæ¯ä¸ªå®éªŒåˆ†é…å”¯ä¸€MASTER_PORTï¼Œé¿å…åˆ†å¸ƒå¼è®­ç»ƒå†²çª
- ç¯å¢ƒæ¸…ç†ï¼šæ¸…ç†çˆ¶è¿›ç¨‹çš„åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿å­è¿›ç¨‹ç¯å¢ƒå¹²å‡€
- ä¸­æ–­å¤„ç†ï¼šä¼˜é›…å¤„ç†Ctrl+Cä¸­æ–­ï¼Œç¡®ä¿å­è¿›ç¨‹æ­£ç¡®ç»ˆæ­¢
- é…å¯¹æ¨¡å¼ï¼šå½“batch_sizeæ•°ç»„ä¸modelæ•°ç»„é•¿åº¦ç›¸åŒæ—¶ï¼ŒæŒ‰å¯¹åº”é¡ºåºé…å¯¹
"""
import itertools
import subprocess
import yaml
import os
import sys
import time
import csv
import json
import random
import torch

from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.utils.config_parser import parse_arguments

def load_grid_config(path="config/grid.yaml"):
    """åŠ è½½ç½‘æ ¼æœç´¢é…ç½®"""
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def _as_list(v):
    """æ ‡é‡â†’å•å…ƒç´ åˆ—è¡¨ï¼›åˆ—è¡¨/å…ƒç»„åŸæ ·ï¼›Noneâ†’ç©ºåˆ—è¡¨
    
    è®¾è®¡æ€è·¯ï¼š
    ç»Ÿä¸€å‚æ•°æ ¼å¼å¤„ç†çš„å·¥å…·å‡½æ•°ï¼Œç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½èƒ½ä»¥åˆ—è¡¨å½¢å¼è¿›è¡Œåç»­å¤„ç†ã€‚
    è¿™ç§è®¾è®¡ç®€åŒ–äº†å‚æ•°ç»„åˆç”Ÿæˆçš„é€»è¾‘ï¼Œé¿å…äº†å¤§é‡çš„ç±»å‹æ£€æŸ¥ä»£ç ã€‚
    
    Args:
        v: ä»»æ„ç±»å‹çš„å‚æ•°å€¼
        
    Returns:
        list: ç»Ÿä¸€æ ¼å¼åŒ–åçš„åˆ—è¡¨
            - None â†’ []
            - æ ‡é‡ â†’ [æ ‡é‡]
            - åˆ—è¡¨/å…ƒç»„ â†’ åŸæ ·è¿”å›
    """
    if v is None:
        return []
    return v if isinstance(v, (list, tuple)) else [v]

def generate_combinations(config):
    """
    æ™ºèƒ½å‚æ•°ç»„åˆç”Ÿæˆå™¨ï¼Œæ”¯æŒå¤šç§ç»„åˆç­–ç•¥
    
    è®¾è®¡æ€è·¯ï¼š
    æœ¬å‡½æ•°å®ç°äº†çµæ´»çš„è¶…å‚æ•°ç»„åˆç”Ÿæˆç­–ç•¥ï¼Œæ ¸å¿ƒè®¾è®¡åŒ…æ‹¬ï¼š
    - åŒæ¨¡å¼æ”¯æŒï¼šæ ‡å‡†ç¬›å¡å°”ç§¯æ¨¡å¼å’Œç‰¹æ®Šé…å¯¹æ¨¡å¼
    - æ™ºèƒ½æ£€æµ‹ï¼šè‡ªåŠ¨è¯†åˆ«batch_sizeä¸modelé…å¯¹çš„åœºæ™¯
    - å‚æ•°åˆ†å±‚ï¼šåŒºåˆ†å›ºå®šå‚æ•°(fixed)å’Œæœç´¢å‚æ•°(grid)
    - ç±»å‹å®¹é”™ï¼šè‡ªåŠ¨å¤„ç†æ ‡é‡ã€åˆ—è¡¨ã€Noneç­‰ä¸åŒç±»å‹
    
    ç»„åˆç­–ç•¥ï¼š
    1. æ ‡å‡†æ¨¡å¼ï¼šæ‰€æœ‰å‚æ•°è¿›è¡Œç¬›å¡å°”ç§¯ç»„åˆ
    2. é…å¯¹æ¨¡å¼ï¼šå½“model.typeæ•°ç»„ä¸hp.batch_sizeæ•°ç»„é•¿åº¦ç›¸åŒæ—¶ï¼Œ
       æŒ‰å¯¹åº”ä½ç½®é…å¯¹ï¼Œé¿å…ä¸åˆç†çš„æ¨¡å‹-æ‰¹å¤§å°ç»„åˆ
    
    Args:
        config (dict): ç½‘æ ¼æœç´¢é…ç½®
            - grid_search.grid: æœç´¢å‚æ•°å­—å…¸
            - grid_search.fixed: å›ºå®šå‚æ•°å­—å…¸
            
    Returns:
        list[dict]: å‚æ•°ç»„åˆåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€ç»„å®éªŒå‚æ•°
    
    ç¤ºä¾‹ï¼š
        é…å¯¹æ¨¡å¼ï¼šmodel.type=["resnet", "vit"], hp.batch_size=[32, 16]
        â†’ ç”Ÿæˆ[("resnet", 32), ("vit", 16)]è€Œé4ç§ç»„åˆ
    """
    gs = (config or {}).get("grid_search", {}) or {}
    fixed = gs.get("fixed", {}) or {}
    grid = gs.get("grid", {}) or {}

    # è¾¹ç•Œæƒ…å†µï¼šæ— æœç´¢å‚æ•°æ—¶è¿”å›å›ºå®šå‚æ•°
    if not grid:
        return [fixed] if fixed else [{}]

    # === æ™ºèƒ½é…å¯¹æ¨¡å¼æ£€æµ‹ ===
    # æå–model.typeå’Œhp.batch_sizeå‚æ•°åˆ—è¡¨
    model_types = _as_list(grid.get("model.type", []))
    batch_sizes = _as_list(grid.get("hp.batch_size", []))
    
    # é…å¯¹æ¨¡å¼è§¦å‘æ¡ä»¶ï¼šä¸¤ä¸ªæ•°ç»„éƒ½æœ‰å¤šä¸ªå…ƒç´ ä¸”é•¿åº¦ç›¸åŒ
    # è®¾è®¡ç›®çš„ï¼šé¿å…å¤§æ¨¡å‹é…å°batch_sizeæˆ–å°æ¨¡å‹é…å¤§batch_sizeçš„ä¸åˆç†ç»„åˆ
    if (len(model_types) > 1 and len(batch_sizes) > 1 and 
        len(model_types) == len(batch_sizes)):
        
        # åˆ›å»ºmodel-batché…å¯¹ï¼šæŒ‰ä½ç½®ä¸€ä¸€å¯¹åº”
        model_batch_pairs = list(zip(model_types, batch_sizes))
        
        # åˆ†ç¦»å…¶ä»–éœ€è¦æœç´¢çš„å‚æ•°
        other_grid = {k: v for k, v in grid.items() 
                     if k not in ["model.type", "hp.batch_size"]}
        
        if not other_grid:
            # çº¯é…å¯¹æ¨¡å¼ï¼šåªæœ‰modelå’Œbatch_sizeéœ€è¦é…å¯¹
            return [{**fixed, "model.type": model_type, "hp.batch_size": batch_size}
                   for model_type, batch_size in model_batch_pairs]
        else:
            # æ··åˆæ¨¡å¼ï¼šé…å¯¹å‚æ•°ä¸å…¶ä»–å‚æ•°åšç¬›å¡å°”ç§¯
            other_valid_items = [(k, _as_list(v)) for k, v in other_grid.items() if _as_list(v)]
            if other_valid_items:
                other_keys, other_values_lists = zip(*other_valid_items)
                combinations = []
                # æ¯ä¸ªmodel-batché…å¯¹ä¸å…¶ä»–å‚æ•°çš„æ‰€æœ‰ç»„åˆé…å¯¹
                for model_type, batch_size in model_batch_pairs:
                    for other_combo in itertools.product(*other_values_lists):
                        combo = {**fixed, "model.type": model_type, "hp.batch_size": batch_size}
                        combo.update(dict(zip(other_keys, other_combo)))
                        combinations.append(combo)
                return combinations
            else:
                # å…¶ä»–å‚æ•°ä¸ºç©ºï¼Œå›é€€åˆ°çº¯é…å¯¹æ¨¡å¼
                return [{**fixed, "model.type": model_type, "hp.batch_size": batch_size}
                       for model_type, batch_size in model_batch_pairs]
    
    # === æ ‡å‡†ç¬›å¡å°”ç§¯æ¨¡å¼ ===
    # è¿‡æ»¤æ‰ç©ºå€¼å‚æ•°ï¼Œé¿å…ç”Ÿæˆæ— æ•ˆç»„åˆ
    valid_items = [(k, _as_list(v)) for k, v in grid.items() if _as_list(v)]
    
    # è¾¹ç•Œæƒ…å†µï¼šæ‰€æœ‰å‚æ•°éƒ½ä¸ºç©º
    if not valid_items:
        return [fixed] if fixed else [{}]

    # åˆ†ç¦»å‚æ•°åå’Œå‚æ•°å€¼åˆ—è¡¨
    keys, values_lists = zip(*valid_items)

    # ç”Ÿæˆæ‰€æœ‰å‚æ•°çš„ç¬›å¡å°”ç§¯ç»„åˆï¼Œå¹¶åˆå¹¶å›ºå®šå‚æ•°
    return [{**fixed, **dict(zip(keys, combo))} 
            for combo in itertools.product(*values_lists)]

def parse_result_from_files(exp_name):
    """ä»ç»“æ„åŒ–æ–‡ä»¶ä¸­è§£ææœ€ç»ˆç»“æœ
    
    è®¾è®¡æ€è·¯ï¼š
    å®ç°å¤šå±‚æ¬¡çš„ç»“æœè§£æç­–ç•¥ï¼Œç¡®ä¿åœ¨ä¸åŒæƒ…å†µä¸‹éƒ½èƒ½è·å–åˆ°æœ‰æ•ˆçš„è®­ç»ƒç»“æœã€‚
    é‡‡ç”¨ä¼˜å…ˆçº§å›é€€æœºåˆ¶ï¼Œæé«˜ç»“æœè§£æçš„é²æ£’æ€§ã€‚
    
    è§£æç­–ç•¥ï¼š
    1. ä¼˜å…ˆçº§1ï¼šresult.json - åŒ…å«å®Œæ•´çš„æœ€ç»ˆç»“æœæ‘˜è¦
    2. ä¼˜å…ˆçº§2ï¼šmetrics.jsonl - é€è¡Œè§£æè®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡
    3. å›é€€ï¼šè¿”å›é»˜è®¤å€¼(0.0, 0.0)
    
    Args:
        exp_name (str): å®éªŒåç§°ï¼Œç”¨äºæ„å»ºç»“æœæ–‡ä»¶è·¯å¾„
        
    Returns:
        tuple[float, float]: (æœ€ä½³å‡†ç¡®ç‡, æœ€ç»ˆå‡†ç¡®ç‡)
            - æœ€ä½³å‡†ç¡®ç‡ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­è¾¾åˆ°çš„æœ€é«˜éªŒè¯å‡†ç¡®ç‡
            - æœ€ç»ˆå‡†ç¡®ç‡ï¼šè®­ç»ƒç»“æŸæ—¶çš„éªŒè¯å‡†ç¡®ç‡
    
    æ–‡ä»¶æ ¼å¼ï¼š
        - result.json: {"best_accuracy": float, "final_accuracy": float}
        - metrics.jsonl: æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼ŒåŒ…å«"val_acc"å­—æ®µ
    """
    result_dir = os.path.join("runs", exp_name)
    final_json = os.path.join(result_dir, "result.json")
    metrics_path = os.path.join(result_dir, "metrics.jsonl")

    # ä¼˜å…ˆè¯»å– result.json
    try:
        if os.path.exists(final_json):
            with open(final_json, "r", encoding="utf-8") as f:
                data = json.load(f) or {}
                best_accuracy = float(data.get("best_accuracy", 0.0))
                final_accuracy = float(data.get("final_accuracy", best_accuracy))
                return best_accuracy, final_accuracy
    except Exception:
        pass

    # å›é€€ï¼šæ‰«æ metrics.jsonl
    try:
        if os.path.exists(metrics_path):
            last_val, best_val = None, 0.0
            with open(metrics_path, "r", encoding="utf-8") as f:
                for line in f:
                    try:
                        va = json.loads(line).get("val_acc")
                        if isinstance(va, (int, float)):
                            last_val = float(va)
                            best_val = max(best_val, last_val)
                    except Exception:
                        continue
            if last_val is not None:
                return best_val, last_val
    except Exception:
        pass

    return 0.0, 0.0


def save_results_to_csv(results, filename):
    """ä¿å­˜å®éªŒç»“æœåˆ°CSVæ–‡ä»¶
    
    è®¾è®¡æ€è·¯ï¼š
    å°†ç½‘æ ¼æœç´¢çš„æ‰€æœ‰å®éªŒç»“æœæ±‡æ€»åˆ°ä¸€ä¸ªCSVæ–‡ä»¶ä¸­ï¼Œä¾¿äºåç»­åˆ†æå’Œæ¯”è¾ƒã€‚
    é‡‡ç”¨æ ‡å‡†åŒ–çš„CSVæ ¼å¼ï¼Œç¡®ä¿æ•°æ®çš„å¯è¯»æ€§å’Œå¯å¤„ç†æ€§ã€‚
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    - è‡ªåŠ¨åˆ›å»ºrunsç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    - åŒ…å«å®Œæ•´çš„è¶…å‚æ•°ä¿¡æ¯å’Œè®­ç»ƒç»“æœ
    - ä½¿ç”¨UTF-8ç¼–ç ï¼Œæ”¯æŒä¸­æ–‡å­—ç¬¦
    - è‡ªåŠ¨å¤„ç†åµŒå¥—å‚æ•°çš„å±•å¹³
    
    Args:
        results (list[dict]): å®éªŒç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ï¼š
            - è¶…å‚æ•°å­—æ®µï¼ˆå¦‚model.type, hp.batch_sizeç­‰ï¼‰
            - best_accuracy: æœ€ä½³å‡†ç¡®ç‡
            - final_accuracy: æœ€ç»ˆå‡†ç¡®ç‡
            - experiment_name: å®éªŒåç§°
        filename (str): CSVæ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
        
    Returns:
        str|None: ä¿å­˜çš„å®Œæ•´æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœresultsä¸ºç©ºåˆ™è¿”å›None
    
    CSVæ ¼å¼ï¼š
        åŒ…å«æ‰€æœ‰è¶…å‚æ•°åˆ—å’Œç»“æœåˆ—ï¼Œä¾¿äºExcelç­‰å·¥å…·æ‰“å¼€åˆ†æ
    """
    if not results:
        return None

    results_dir = "runs"
    os.makedirs(results_dir, exist_ok=True)
    filepath = os.path.join(results_dir, filename)

    # æ”¶é›†æ‰€æœ‰å‡ºç°è¿‡çš„å‚æ•°å­—æ®µ
    param_keys = sorted({k for r in results for k in r.get("params", {}).keys()})

    fieldnames = [
        "experiment_id", "experiment_name", "success",
        "best_accuracy", "final_accuracy"
    ] + param_keys

    with open(filepath, "w", newline="", encoding="utf-8") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for i, r in enumerate(results, 1):
            row = {
                "experiment_id": f"{i:03d}",
                "experiment_name": r.get("exp_name"),
                "success": r.get("success"),
                "best_accuracy": r.get("best_accuracy"),
                "final_accuracy": r.get("final_accuracy"),
            }
            row.update(r.get("params", {}))
            writer.writerow(row)

    return filepath


# ================= å¤šå¡å­è¿›ç¨‹å¯åŠ¨è¾…åŠ©å‡½æ•° =================

def _clean_env_for_child():
    """
    æ¸…ç†çˆ¶è¿›ç¨‹çš„åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡
    
    è®¾è®¡æ€è·¯ï¼š
    åœ¨ç½‘æ ¼æœç´¢åœºæ™¯ä¸‹ï¼Œè°ƒåº¦å™¨è¿›ç¨‹å¯èƒ½å·²ç»è®¾ç½®äº†åˆ†å¸ƒå¼ç›¸å…³çš„ç¯å¢ƒå˜é‡ã€‚
    å¦‚æœå­è¿›ç¨‹ç»§æ‰¿è¿™äº›å˜é‡ï¼Œå¯èƒ½å¯¼è‡´åˆ†å¸ƒå¼è®­ç»ƒåˆå§‹åŒ–å¤±è´¥æˆ–è¿æ¥é”™è¯¯ã€‚
    å› æ­¤éœ€è¦ä¸ºæ¯ä¸ªå­å®éªŒæä¾›å¹²å‡€çš„ç¯å¢ƒã€‚
    
    æ¸…ç†çš„ç¯å¢ƒå˜é‡ï¼š
    - LOCAL_RANK: æœ¬åœ°è¿›ç¨‹æ’å
    - RANK: å…¨å±€è¿›ç¨‹æ’å  
    - WORLD_SIZE: æ€»è¿›ç¨‹æ•°
    - MASTER_ADDR: ä¸»èŠ‚ç‚¹åœ°å€
    - MASTER_PORT: ä¸»èŠ‚ç‚¹ç«¯å£
    
    Returns:
        dict: æ¸…ç†åçš„ç¯å¢ƒå˜é‡å­—å…¸ï¼Œå¯ç›´æ¥ç”¨äºsubprocess
    
    ä½¿ç”¨åœºæ™¯ï¼š
        æ¯æ¬¡å¯åŠ¨æ–°çš„è®­ç»ƒå­è¿›ç¨‹æ—¶è°ƒç”¨ï¼Œç¡®ä¿ç¯å¢ƒéš”ç¦»
    """
    env = os.environ.copy()
    for k in ["LOCAL_RANK", "RANK", "WORLD_SIZE", "MASTER_ADDR", "MASTER_PORT"]:
        env.pop(k, None)
    return env


def _unique_master_port(base=20000, span=10000):
    """ä¸ºæ¯ä¸ªå®éªŒåˆ†é…å”¯ä¸€ç«¯å£
    
    è®¾è®¡æ€è·¯ï¼š
    åœ¨å¹¶å‘æˆ–è¿ç»­è¿è¡Œå¤šä¸ªåˆ†å¸ƒå¼è®­ç»ƒå®éªŒæ—¶ï¼Œå¦‚æœä½¿ç”¨ç›¸åŒçš„MASTER_PORTï¼Œ
    ä¼šå¯¼è‡´NCCLè¿æ¥å†²çªå’Œé€šä¿¡å¼‚å¸¸ã€‚é€šè¿‡éšæœºåˆ†é…ç«¯å£é¿å…æ­¤é—®é¢˜ã€‚
    
    Args:
        base (int): ç«¯å£èŒƒå›´èµ·å§‹å€¼ï¼Œé»˜è®¤20000
        span (int): ç«¯å£èŒƒå›´å¤§å°ï¼Œé»˜è®¤10000
        
    Returns:
        str: éšæœºç”Ÿæˆçš„ç«¯å£å·å­—ç¬¦ä¸²
        
    ç«¯å£èŒƒå›´ï¼š
        [base, base+span)ï¼Œé»˜è®¤ä¸º[20000, 30000)
        é¿å¼€å¸¸ç”¨ç«¯å£ï¼Œå‡å°‘å†²çªæ¦‚ç‡
    """
    return str(base + random.randint(0, span))


def _infer_num_procs() -> int:
    env_ids = (os.environ.get("CUDA_VISIBLE_DEVICES") or "").strip()
    if env_ids:
        return max(1, len([x for x in env_ids.split(",") if x.strip() != ""]))
    try:
        import torch
        return max(1, torch.cuda.device_count())
    except Exception:
        return 1


def run_single_experiment(params, exp_id, use_multi_gpu=False, config_path="config/grid.yaml"): #, accelerate_args=""):
    """è¿è¡Œå•ä¸ªå®éªŒï¼ˆæ¯ä¸ªå®éªŒç‹¬ç«‹çš„è¿›ç¨‹/è¿›ç¨‹ç»„ï¼‰"""
    exp_name = f"grid_{exp_id}"

    # ç»„è£…åŸºç¡€å‘½ä»¤
    if use_multi_gpu:
        cmd = ["accelerate", "launch", "--multi_gpu", "--num_processes", str(torch.cuda.device_count())]
    else:
        cmd = [sys.executable, "-u"]
    
    # æ·»åŠ è®­ç»ƒè„šæœ¬å’ŒåŸºç¡€å‚æ•°
    cmd.extend(["scripts/train.py", "--config", config_path, "--experiment_name", exp_name])
    
    # æ·»åŠ å‚æ•°è¦†ç›–
    for k, v in (params or {}).items():
        cmd.extend([f"--{k}", str(v)])

    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹å®éªŒ {exp_id}: {exp_name}")
    print(f"ğŸ“‹ å‚æ•°: {params}")
    print(f"{'='*60}")

    # æ¸…ç†çˆ¶ç¯å¢ƒ + ä¸ºæœ¬å®éªŒè®¾ç½®å”¯ä¸€ç«¯å£
    env = _clean_env_for_child()
    env["MASTER_ADDR"] = env.get("MASTER_ADDR", "127.0.0.1")
    env["MASTER_PORT"] = _unique_master_port()

    # ç›´æ¥ç»§æ‰¿ TTYï¼Œä¿ç•™ tqdm ä¸€è¡Œåˆ·æ–°
    process = subprocess.Popen(cmd, env=env)
    try:
        # ç­‰å¾…å­è¿›ç¨‹ç»“æŸ
        rc = process.wait()
    except KeyboardInterrupt:
        # æ•è·åˆ° Ctrl+C (KeyboardInterrupt)
        print(f"\næ•è·åˆ°ä¸­æ–­ä¿¡å·(Ctrl+C)ï¼Œæ­£åœ¨ç»ˆæ­¢å­è¿›ç¨‹ {process.pid}...")
        process.terminate()  # å‘é€ SIGTERM ä¿¡å·ï¼Œè¯·æ±‚å­è¿›ç¨‹ç»ˆæ­¢
        process.wait()       # ç­‰å¾…å­è¿›ç¨‹å®Œå…¨é€€å‡º
        print("å­è¿›ç¨‹å·²ç»ˆæ­¢ã€‚")
        raise                # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä»¥ç¡®ä¿æ•´ä¸ªç½‘æ ¼æœç´¢è„šæœ¬åœæ­¢

    success = (rc == 0)

    # ä»æ–‡ä»¶è§£æç»“æœ
    best_accuracy, final_accuracy = parse_result_from_files(exp_name)
    if success:
        if best_accuracy == 0.0 and final_accuracy == 0.0:
            print(f"âš ï¸  {exp_name} ç»“æŸï¼Œä½†æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ã€‚è¯·æ£€æŸ¥ runs/{exp_name}/ã€‚")
        else:
            print(f"âœ… å®éªŒ {exp_name} å®Œæˆï¼Œæœ€ä½³: {best_accuracy:.2f}% | æœ€ç»ˆ: {final_accuracy:.2f}%")
    else:
        print(f"âŒ å®éªŒ {exp_name} å¤±è´¥ï¼ˆè¿”å›ç  {rc}ï¼‰ã€‚è¯·æŸ¥çœ‹æ§åˆ¶å°ä¸ runs/{exp_name}/ã€‚")

    return {
        "success": success,
        "exp_name": exp_name,
        "params": params,
        "best_accuracy": best_accuracy,
        "final_accuracy": final_accuracy,
    }


def run_grid_search(args):
    """è¿è¡Œç½‘æ ¼æœç´¢ï¼ˆä¸²è¡Œï¼Œç¡®ä¿èµ„æºå¹²å‡€é‡Šæ”¾ï¼‰"""
    config = load_grid_config(args.config)
    
    # å®éªŒå‚æ•°è¿›è¡Œç¬›å¡å°”ç§¯ç»„åˆ
    combinations = generate_combinations(config)

    # æˆªæ–­å®éªŒæ•°é‡
    if len(combinations) > args.max_experiments:
        combinations = combinations[:args.max_experiments]

    print(f"\nğŸš€ å¼€å§‹ç½‘æ ¼æœç´¢ï¼Œå…± {len(combinations)} ä¸ªå®éªŒ")
    print(f"ğŸ“Š ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
    print(f"ğŸ¯ å¤šå¡è®­ç»ƒ: {'æ˜¯' if args.multi_gpu else 'å¦'}")
    print("=" * 60)

    results = []
    successful = 0

    for i, params in enumerate(combinations, 1):
        print(f"\nğŸ“Š å‡†å¤‡å®éªŒ {i}/{len(combinations)}")

        result = run_single_experiment(
            params, f"{i:03d}",
            use_multi_gpu=args.multi_gpu,
            config_path=args.config, # è®­ç»ƒä½¿ç”¨çš„ç»Ÿä¸€é…ç½®
        )
        
        results.append(result)
        if result["success"]:
            successful += 1

        # é€‚å½“é—´éš”
        # time.sleep(1.0)

    # æ€»ç»“
    print("\n" + "=" * 60)
    print(f"ğŸ“ˆ ç½‘æ ¼æœç´¢å®Œæˆï¼")
    print(f"âœ… æˆåŠŸå®éªŒæ•°é‡: {successful}/{len(combinations)}")

    if successful > 0:
        # ç­›é€‰å‡ºæ‰€æœ‰æˆåŠŸå®Œæˆçš„å®éªŒç»“æœ
        successful_results = [r for r in results if r["success"]]
        # æ‰¾åˆ°â€œæœ€ä½³å‡†ç¡®ç‡â€æœ€é«˜çš„å®éªŒç»“æœ
        best_result = max(successful_results, key=lambda x: x["best_accuracy"])

        print(f"\nğŸ† æœ€ä½³å®éªŒç»“æœ:")
        print(f"å®éªŒåç§°: {best_result['exp_name']}, æœ€ä½³å‡†ç¡®ç‡: {best_result['best_accuracy']:.2f}%, æœ€ç»ˆå‡†ç¡®ç‡: {best_result['final_accuracy']:.2f}%")
        
        # æŒ‰æœ€ä½³ç²¾åº¦æ’åºå‰nç»„ç»“æœ
        top_results = sorted(successful_results, key=lambda x: x["best_accuracy"], reverse=True)[:args.top_n]
        
        print(f"\nğŸ“Š å‰{args.top_n}åå®éªŒç»“æœ:")
        for i, r in enumerate(top_results, 1):
            print(f"{i}. {r['exp_name']} - {r['best_accuracy']:.2f}% - {r['params']}")

    if args.save_results:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_filename = f"grid_search_results_{timestamp}.csv"
        saved_filepath = save_results_to_csv(results, results_filename)
        if saved_filepath:
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {saved_filepath}")

    return 0 if successful > 0 else 1


def main():
    """ä¸»å‡½æ•°ï¼šè°ƒåº¦å™¨å§‹ç»ˆå•è¿›ç¨‹ï¼Œä¸è¿›å…¥ Accelerate ç¯å¢ƒ"""
    args, _ = parse_arguments(mode="grid_search")
    return run_grid_search(args)


if __name__ == "__main__":
    sys.exit(main())